{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "import os                    \n",
    "import skimage               \n",
    "import numpy as np           \n",
    "from skimage import data,transform\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2gray     \n",
    "import matplotlib.pyplot as plt\n",
    "import random      \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_data(data_directory):\n",
    "    directories=[d for d in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory,d))]\n",
    "    #d is every classification file\n",
    "    labels=[]\n",
    "    images=[]\n",
    "    names=[]\n",
    "    for d in directories:\n",
    "        #get directions of each class\n",
    "        label_directory=os.path.join(data_directory,d)\n",
    "        file_names=[os.path.join(label_directory,f) for f in os.listdir(label_directory) if f.endswith(\".jpeg\") or f.endswith('.JPG') ]\n",
    "        for f in file_names:\n",
    "\n",
    "            img=skimage.data.imread(f, as_grey='True')\n",
    "#             img[img>color] = 1\n",
    "            images.append(img)  #read image\n",
    "            labels.append(d)                   #read label\n",
    "            names.append(f)\n",
    "    return images,labels,names\n",
    "\n",
    "#images and labels are list\n",
    "# change the root path\n",
    "ROOT_PATH=\"/Users/chenlingna/Desktop/Project/MelbourneCityTraining/StreetViewDownload/TensorFlowTrain\"\n",
    "color = 150/255\n",
    "#data_directory=\"/Users/chenlingna/Desktop/Project/StreetViewDownload/TensorFlowTrain/Training\"\n",
    "# train_data_directory=os.path.join(ROOT_PATH,\"Training\")\n",
    "# test_data_directory=os.path.join(ROOT_PATH,\"Testing\")\n",
    "data_directory=os.path.join(ROOT_PATH,\"Training\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data Set\n",
    "images_Total,labels_Total,names_Total=load_data(data_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images, test_images, labels, test_labels, names, test_names  = train_test_split(images_Total, labels_Total, names_Total, test_size=0.1, random_state=90051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Load Training Set\n",
    "# images,labels,names=load_data(train_data_directory)\n",
    "\n",
    "images28=[]\n",
    "for img in images:\n",
    "#     img[img>color]=1\n",
    "#     img[img<color]=0\n",
    "    images28.append(img)\n",
    "    \n",
    "# Rescale the images in the `images` array\n",
    "images28 = [transform.resize(image, (28, 28)) for image in images28]\n",
    "# Convert `images28` to an array\n",
    "images28 = np.array(images28)\n",
    "# # Convert `images` to grayscale\n",
    "# images28 = rgb2gray(images28)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Load Testing Set\n",
    "# test_images, test_labels, test_names = load_data(test_data_directory)\n",
    "\n",
    "test_images28=[]\n",
    "for img in test_images:\n",
    "#     img[img>color]=1\n",
    "#     img[img<color]=0\n",
    "    test_images28.append(img)\n",
    "\n",
    "# Transform the images to 28 by 28 pixels\n",
    "test_images28 = [transform.resize(image, (28, 28)) for image in test_images28]\n",
    "test_images28 = np.array(test_images28)\n",
    "# # Convert to grayscale\n",
    "# from skimage.color import rgb2gray\n",
    "\n",
    "# test_images28 = rgb2gray(np.array(test_images28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterator:\n",
    "    \"\"\"\n",
    "    An iterator that returns randomized batches from a data set (with features and labels)\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels, batch_size):\n",
    "        assert(features.shape[0]==labels.shape[0])\n",
    "        assert(batch_size > 0 and batch_size <= features.shape[0])\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.num_instances = features.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.num_instances//self.batch_size\n",
    "        if (self.num_instances%self.batch_size!=0):\n",
    "            self.num_batches += 1\n",
    "        self._i = 0\n",
    "        self._rand_ids = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._i = 0\n",
    "        self._rand_ids = np.random.permutation(self.num_instances)\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        self.__next__(self)\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.num_instances - self._i >= self.batch_size:\n",
    "            this_rand_ids = self._rand_ids[self._i:self._i + self.batch_size]\n",
    "            self._i += self.batch_size\n",
    "            return self.features[this_rand_ids], self.labels[this_rand_ids]\n",
    "        elif self.num_instances - self._i > 0:\n",
    "            this_rand_ids = self._rand_ids[self._i::]\n",
    "            self._i = self.num_instances\n",
    "            return self.features[this_rand_ids], self.labels[this_rand_ids]\n",
    "        else:\n",
    "            raise StopIteration()\n",
    "            \n",
    "batch_size = 100\n",
    "labels=np.array(labels)\n",
    "train_iterator = DatasetIterator(images28, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "import tensorflow as tf\n",
    "IM_WIDTH = images28.shape[1]      # width of an image in pixels\n",
    "IM_HEIGHT = images28.shape[2] \n",
    "NUM_CLASSES = 2\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='image')\n",
    "    Y = tf.placeholder(tf.int32, [None], name='label')\n",
    "    \n",
    "DEPTH_C1 = 8       # depth of convolutional layer #1\n",
    "DEPTH_C2 = 16      # depth of convolutional layer #2\n",
    "UNITS_D1 = 256     # number of neurons in dense layer #1\n",
    "with tf.variable_scope('cnn_model'):\n",
    "    # Boolean placeholder which is set to True for training, and False for inference.\n",
    "    # This is required to implement dropout. \n",
    "    training_mode = tf.placeholder(dtype=tf.bool, name='training_mode')\n",
    "    \n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(X, [-1, IM_WIDTH, IM_HEIGHT, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=DEPTH_C1, kernel_size=[5, 5], \n",
    "                             padding='same', activation=tf.nn.relu, use_bias=True, \n",
    "                             name='conv_layer_1')\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2, \n",
    "                                    name='pool_layer_1')\n",
    "\n",
    "    # Convolutional Layer #2 \n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=DEPTH_C2, kernel_size=[5, 5], \n",
    "                             padding='same', activation=tf.nn.relu, use_bias=True, \n",
    "                             name='conv_layer_2') # fill in\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2, \n",
    "                                    name='pool_layer_2') # fill in\n",
    "\n",
    "    # Dense Layer #1\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, 7*7*DEPTH_C2], name='pool_layer_2_flat')\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=UNITS_D1, activation=tf.nn.relu, \n",
    "                            name='dense_layer_1')\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.7, training=training_mode, name='dropout')\n",
    "\n",
    "    # Dense Layer #2 (Logits Layer)\n",
    "    logits = tf.layers.dense(inputs=dropout, units=NUM_CLASSES, use_bias=True,\n",
    "                             name='dense_layer_2')\n",
    "    \n",
    "    # Predicted labels\n",
    "    predictions = tf.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "with tf.variable_scope('train'):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_op = opt.minimize(loss=loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('evaluation'):\n",
    "    acc, acc_op = tf.metrics.accuracy(labels=Y, predictions=predictions, name='accuracy')\n",
    "    loss_summary = tf.summary.scalar('loss', loss)\n",
    "    acc_summary = tf.summary.scalar('accuracy', acc)\n",
    "    eval_summaries = tf.summary.merge([loss_summary, acc_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('cnn_model/conv_layer_1', reuse=True):\n",
    "    kernel = tf.get_variable('kernel')\n",
    "    with tf.variable_scope('visualization'):\n",
    "        # scale weights to [0 1]\n",
    "        x_min = tf.reduce_min(kernel)\n",
    "        x_max = tf.reduce_max(kernel)\n",
    "        kernel_0_to_1 = (kernel - x_min) / (x_max - x_min)\n",
    "\n",
    "        # to tf.summary.image format\n",
    "        kernel_transposed = tf.transpose(kernel_0_to_1, [3, 0, 1, 2])\n",
    "\n",
    "        # this will display 5 filters from the 8 in conv_layer_1\n",
    "        filter_summary = tf.summary.image('filters', kernel_transposed, max_outputs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0.\n",
      "Starting epoch 1.\n",
      "\tTraining accuracy at step 100: 0.7277555465698242.\n",
      "Starting epoch 2.\n",
      "Starting epoch 3.\n",
      "\tTraining accuracy at step 200: 0.7617389559745789.\n",
      "Starting epoch 4.\n",
      "\tTraining accuracy at step 300: 0.7911677360534668.\n",
      "Starting epoch 5.\n",
      "Starting epoch 6.\n",
      "\tTraining accuracy at step 400: 0.8138508200645447.\n",
      "Starting epoch 7.\n",
      "\tTraining accuracy at step 500: 0.8304445147514343.\n",
      "Starting epoch 8.\n",
      "Starting epoch 9.\n",
      "\tTraining accuracy at step 600: 0.8438856601715088.\n",
      "Starting epoch 10.\n",
      "\tTraining accuracy at step 700: 0.8538666367530823.\n",
      "Starting epoch 11.\n",
      "Starting epoch 12.\n",
      "\tTraining accuracy at step 800: 0.863868236541748.\n",
      "Starting epoch 13.\n",
      "\tTraining accuracy at step 900: 0.8718216419219971.\n",
      "Starting epoch 14.\n",
      "Starting epoch 15.\n",
      "\tTraining accuracy at step 1000: 0.8787989616394043.\n",
      "Starting epoch 16.\n",
      "\tTraining accuracy at step 1100: 0.8850611448287964.\n",
      "Starting epoch 17.\n",
      "Starting epoch 18.\n",
      "\tTraining accuracy at step 1200: 0.8906046152114868.\n",
      "Starting epoch 19.\n",
      "\tTraining accuracy at step 1300: 0.895021378993988.\n",
      "Starting epoch 20.\n",
      "Starting epoch 21.\n",
      "\tTraining accuracy at step 1400: 0.8990767002105713.\n",
      "Starting epoch 22.\n",
      "Starting epoch 23.\n",
      "\tTraining accuracy at step 1500: 0.9026138186454773.\n",
      "Starting epoch 24.\n",
      "\tTraining accuracy at step 1600: 0.9063565731048584.\n",
      "Starting epoch 25.\n",
      "Starting epoch 26.\n",
      "\tTraining accuracy at step 1700: 0.9097351431846619.\n",
      "Starting epoch 27.\n",
      "\tTraining accuracy at step 1800: 0.9127087593078613.\n",
      "Starting epoch 28.\n",
      "Starting epoch 29.\n",
      "\tTraining accuracy at step 1900: 0.9154030680656433.\n",
      "Starting epoch 30.\n",
      "\tTraining accuracy at step 2000: 0.9177834391593933.\n",
      "Starting epoch 31.\n",
      "Starting epoch 32.\n",
      "\tTraining accuracy at step 2100: 0.9199399948120117.\n",
      "Starting epoch 33.\n",
      "\tTraining accuracy at step 2200: 0.9216342568397522.\n",
      "Starting epoch 34.\n",
      "Starting epoch 35.\n",
      "\tTraining accuracy at step 2300: 0.9236797094345093.\n",
      "Starting epoch 36.\n",
      "\tTraining accuracy at step 2400: 0.925593912601471.\n",
      "Starting epoch 37.\n",
      "Starting epoch 38.\n",
      "\tTraining accuracy at step 2500: 0.9273955821990967.\n",
      "Starting epoch 39.\n",
      "\tTraining accuracy at step 2600: 0.9290724396705627.\n",
      "Starting epoch 40.\n",
      "Starting epoch 41.\n",
      "\tTraining accuracy at step 2700: 0.9306302666664124.\n",
      "Starting epoch 42.\n",
      "Starting epoch 43.\n",
      "\tTraining accuracy at step 2800: 0.9318965673446655.\n",
      "Starting epoch 44.\n",
      "\tTraining accuracy at step 2900: 0.9330854415893555.\n",
      "Starting epoch 45.\n",
      "Starting epoch 46.\n",
      "\tTraining accuracy at step 3000: 0.9343507885932922.\n",
      "Starting epoch 47.\n",
      "\tTraining accuracy at step 3100: 0.9355555176734924.\n",
      "Starting epoch 48.\n",
      "Starting epoch 49.\n",
      "\tTraining accuracy at step 3200: 0.936767041683197.\n",
      "Starting epoch 50.\n",
      "\tTraining accuracy at step 3300: 0.9375730156898499.\n",
      "Starting epoch 51.\n",
      "Starting epoch 52.\n",
      "\tTraining accuracy at step 3400: 0.9385871291160583.\n",
      "Starting epoch 53.\n",
      "\tTraining accuracy at step 3500: 0.9394597411155701.\n",
      "Starting epoch 54.\n",
      "Starting epoch 55.\n",
      "\tTraining accuracy at step 3600: 0.9403243660926819.\n",
      "Starting epoch 56.\n",
      "\tTraining accuracy at step 3700: 0.941173791885376.\n",
      "Starting epoch 57.\n",
      "Starting epoch 58.\n",
      "\tTraining accuracy at step 3800: 0.9420130252838135.\n",
      "Starting epoch 59.\n",
      "\tTraining accuracy at step 3900: 0.9427717328071594.\n",
      "Starting epoch 60.\n",
      "Starting epoch 61.\n",
      "\tTraining accuracy at step 4000: 0.9435197710990906.\n",
      "Starting epoch 62.\n",
      "Starting epoch 63.\n",
      "\tTraining accuracy at step 4100: 0.9442562460899353.\n",
      "Starting epoch 64.\n",
      "\tTraining accuracy at step 4200: 0.944875955581665.\n",
      "Starting epoch 65.\n",
      "Starting epoch 66.\n",
      "\tTraining accuracy at step 4300: 0.9454531669616699.\n",
      "Starting epoch 67.\n",
      "\tTraining accuracy at step 4400: 0.9460240006446838.\n",
      "Starting epoch 68.\n",
      "Starting epoch 69.\n",
      "\tTraining accuracy at step 4500: 0.9466457366943359.\n",
      "Starting epoch 70.\n",
      "\tTraining accuracy at step 4600: 0.9471816420555115.\n",
      "Starting epoch 71.\n",
      "Starting epoch 72.\n",
      "\tTraining accuracy at step 4700: 0.9477149248123169.\n",
      "Starting epoch 73.\n",
      "\tTraining accuracy at step 4800: 0.9482214450836182.\n",
      "Starting epoch 74.\n",
      "Starting epoch 75.\n",
      "\tTraining accuracy at step 4900: 0.9486610293388367.\n",
      "Starting epoch 76.\n",
      "\tTraining accuracy at step 5000: 0.949128270149231.\n",
      "Starting epoch 77.\n",
      "Starting epoch 78.\n",
      "\tTraining accuracy at step 5100: 0.9495257139205933.\n",
      "Starting epoch 79.\n",
      "\tTraining accuracy at step 5200: 0.9499653577804565.\n",
      "Starting epoch 80.\n",
      "Starting epoch 81.\n",
      "\tTraining accuracy at step 5300: 0.9503098726272583.\n",
      "Starting epoch 82.\n",
      "Starting epoch 83.\n",
      "\tTraining accuracy at step 5400: 0.9506497383117676.\n",
      "Starting epoch 84.\n",
      "\tTraining accuracy at step 5500: 0.9510542154312134.\n",
      "Starting epoch 85.\n",
      "Starting epoch 86.\n",
      "\tTraining accuracy at step 5600: 0.9513816833496094.\n",
      "Starting epoch 87.\n",
      "\tTraining accuracy at step 5700: 0.9517360329627991.\n",
      "Starting epoch 88.\n",
      "Starting epoch 89.\n",
      "\tTraining accuracy at step 5800: 0.952059268951416.\n",
      "Starting epoch 90.\n",
      "\tTraining accuracy at step 5900: 0.9524099230766296.\n",
      "Starting epoch 91.\n",
      "Starting epoch 92.\n",
      "\tTraining accuracy at step 6000: 0.9527257680892944.\n",
      "Starting epoch 93.\n",
      "\tTraining accuracy at step 6100: 0.9530348181724548.\n",
      "Starting epoch 94.\n",
      "Starting epoch 95.\n",
      "\tTraining accuracy at step 6200: 0.9533138871192932.\n",
      "Starting epoch 96.\n",
      "\tTraining accuracy at step 6300: 0.953600287437439.\n",
      "Starting epoch 97.\n",
      "Starting epoch 98.\n",
      "\tTraining accuracy at step 6400: 0.9538994431495667.\n",
      "Starting epoch 99.\n",
      "\tTraining accuracy at step 6500: 0.9541343450546265.\n",
      "Starting epoch 100.\n",
      "Starting epoch 101.\n",
      "\tTraining accuracy at step 6600: 0.9543167948722839.\n",
      "Starting epoch 102.\n",
      "Starting epoch 103.\n",
      "\tTraining accuracy at step 6700: 0.9545765519142151.\n",
      "Starting epoch 104.\n",
      "\tTraining accuracy at step 6800: 0.9548018574714661.\n",
      "Starting epoch 105.\n",
      "Starting epoch 106.\n",
      "\tTraining accuracy at step 6900: 0.9549687504768372.\n",
      "Starting epoch 107.\n",
      "\tTraining accuracy at step 7000: 0.9552383422851562.\n",
      "Starting epoch 108.\n",
      "Starting epoch 109.\n",
      "\tTraining accuracy at step 7100: 0.9554941058158875.\n",
      "Starting epoch 110.\n",
      "\tTraining accuracy at step 7200: 0.9557204842567444.\n",
      "Starting epoch 111.\n",
      "Starting epoch 112.\n",
      "\tTraining accuracy at step 7300: 0.9559276103973389.\n",
      "Starting epoch 113.\n",
      "\tTraining accuracy at step 7400: 0.9561498761177063.\n",
      "Starting epoch 114.\n",
      "Starting epoch 115.\n",
      "\tTraining accuracy at step 7500: 0.9563740491867065.\n",
      "Starting epoch 116.\n",
      "\tTraining accuracy at step 7600: 0.9565480947494507.\n",
      "Starting epoch 117.\n",
      "Starting epoch 118.\n",
      "\tTraining accuracy at step 7700: 0.9567934274673462.\n",
      "Starting epoch 119.\n",
      "\tTraining accuracy at step 7800: 0.9570146799087524.\n",
      "Starting epoch 120.\n",
      "Starting epoch 121.\n",
      "\tTraining accuracy at step 7900: 0.9571813941001892.\n",
      "Starting epoch 122.\n",
      "Starting epoch 123.\n",
      "\tTraining accuracy at step 8000: 0.9573804140090942.\n",
      "Starting epoch 124.\n",
      "\tTraining accuracy at step 8100: 0.9575412273406982.\n",
      "Starting epoch 125.\n",
      "Starting epoch 126.\n",
      "\tTraining accuracy at step 8200: 0.9576864838600159.\n",
      "Starting epoch 127.\n",
      "\tTraining accuracy at step 8300: 0.9578273892402649.\n",
      "Starting epoch 128.\n",
      "Starting epoch 129.\n",
      "\tTraining accuracy at step 8400: 0.957991898059845.\n",
      "Starting epoch 130.\n",
      "\tTraining accuracy at step 8500: 0.9581447839736938.\n",
      "Starting epoch 131.\n",
      "Starting epoch 132.\n",
      "\tTraining accuracy at step 8600: 0.9582644104957581.\n",
      "Starting epoch 133.\n",
      "\tTraining accuracy at step 8700: 0.9583863019943237.\n",
      "Starting epoch 134.\n",
      "Starting epoch 135.\n",
      "\tTraining accuracy at step 8800: 0.9585452675819397.\n",
      "Starting epoch 136.\n",
      "\tTraining accuracy at step 8900: 0.9587169885635376.\n",
      "Starting epoch 137.\n",
      "Starting epoch 138.\n",
      "\tTraining accuracy at step 9000: 0.9589124917984009.\n",
      "Starting epoch 139.\n",
      "\tTraining accuracy at step 9100: 0.9590981006622314.\n",
      "Starting epoch 140.\n",
      "Starting epoch 141.\n",
      "\tTraining accuracy at step 9200: 0.9592946767807007.\n",
      "Starting epoch 142.\n",
      "Starting epoch 143.\n",
      "\tTraining accuracy at step 9300: 0.959476113319397.\n",
      "Starting epoch 144.\n",
      "\tTraining accuracy at step 9400: 0.9596264958381653.\n",
      "Starting epoch 145.\n",
      "Starting epoch 146.\n",
      "\tTraining accuracy at step 9500: 0.9597537517547607.\n",
      "Starting epoch 147.\n",
      "\tTraining accuracy at step 9600: 0.959826648235321.\n",
      "Starting epoch 148.\n",
      "Starting epoch 149.\n",
      "\tTraining accuracy at step 9700: 0.9599589705467224.\n",
      "Starting epoch 150.\n",
      "\tTraining accuracy at step 9800: 0.9601213335990906.\n",
      "Starting epoch 151.\n",
      "Starting epoch 152.\n",
      "\tTraining accuracy at step 9900: 0.9602752923965454.\n",
      "Starting epoch 153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining accuracy at step 10000: 0.9604049921035767.\n",
      "Starting epoch 154.\n",
      "Starting epoch 155.\n",
      "\tTraining accuracy at step 10100: 0.9605162143707275.\n",
      "Starting epoch 156.\n",
      "\tTraining accuracy at step 10200: 0.9606317281723022.\n",
      "Starting epoch 157.\n",
      "Starting epoch 158.\n",
      "\tTraining accuracy at step 10300: 0.9607322216033936.\n",
      "Starting epoch 159.\n",
      "\tTraining accuracy at step 10400: 0.96084064245224.\n",
      "Starting epoch 160.\n",
      "Starting epoch 161.\n",
      "\tTraining accuracy at step 10500: 0.9609351754188538.\n",
      "Starting epoch 162.\n",
      "Starting epoch 163.\n",
      "\tTraining accuracy at step 10600: 0.9610258340835571.\n",
      "Starting epoch 164.\n",
      "\tTraining accuracy at step 10700: 0.9611318111419678.\n",
      "Starting epoch 165.\n",
      "Starting epoch 166.\n",
      "\tTraining accuracy at step 10800: 0.961266279220581.\n",
      "Starting epoch 167.\n",
      "\tTraining accuracy at step 10900: 0.9613815546035767.\n",
      "Starting epoch 168.\n",
      "Starting epoch 169.\n",
      "\tTraining accuracy at step 11000: 0.9615006446838379.\n",
      "Starting epoch 170.\n",
      "\tTraining accuracy at step 11100: 0.961602509021759.\n",
      "Starting epoch 171.\n",
      "Starting epoch 172.\n",
      "\tTraining accuracy at step 11200: 0.9616947174072266.\n",
      "Starting epoch 173.\n",
      "\tTraining accuracy at step 11300: 0.9617853164672852.\n",
      "Starting epoch 174.\n",
      "Starting epoch 175.\n",
      "\tTraining accuracy at step 11400: 0.961738646030426.\n",
      "Starting epoch 176.\n",
      "\tTraining accuracy at step 11500: 0.9617987275123596.\n",
      "Starting epoch 177.\n",
      "Starting epoch 178.\n",
      "\tTraining accuracy at step 11600: 0.9619030952453613.\n",
      "Starting epoch 179.\n",
      "\tTraining accuracy at step 11700: 0.9619894027709961.\n",
      "Starting epoch 180.\n",
      "Starting epoch 181.\n",
      "\tTraining accuracy at step 11800: 0.962087869644165.\n",
      "Starting epoch 182.\n",
      "Starting epoch 183.\n",
      "\tTraining accuracy at step 11900: 0.9621601700782776.\n",
      "Starting epoch 184.\n",
      "\tTraining accuracy at step 12000: 0.962255597114563.\n",
      "Starting epoch 185.\n",
      "Starting epoch 186.\n",
      "\tTraining accuracy at step 12100: 0.9623644948005676.\n",
      "Starting epoch 187.\n",
      "\tTraining accuracy at step 12200: 0.9624608159065247.\n",
      "Starting epoch 188.\n",
      "Starting epoch 189.\n",
      "\tTraining accuracy at step 12300: 0.9625342488288879.\n",
      "Starting epoch 190.\n",
      "\tTraining accuracy at step 12400: 0.9626259207725525.\n",
      "Starting epoch 191.\n",
      "Starting epoch 192.\n",
      "\tTraining accuracy at step 12500: 0.9627236723899841.\n",
      "Starting epoch 193.\n",
      "\tTraining accuracy at step 12600: 0.9628459811210632.\n",
      "Starting epoch 194.\n",
      "Starting epoch 195.\n",
      "\tTraining accuracy at step 12700: 0.9629680514335632.\n",
      "Starting epoch 196.\n",
      "\tTraining accuracy at step 12800: 0.9630699753761292.\n",
      "Starting epoch 197.\n",
      "Starting epoch 198.\n",
      "\tTraining accuracy at step 12900: 0.9631233811378479.\n",
      "Starting epoch 199.\n",
      "\tTraining accuracy at step 13000: 0.9632248282432556.\n",
      "Starting epoch 200.\n",
      "Starting epoch 201.\n",
      "\tTraining accuracy at step 13100: 0.9632890224456787.\n",
      "Starting epoch 202.\n",
      "Starting epoch 203.\n",
      "\tTraining accuracy at step 13200: 0.9633727073669434.\n",
      "Starting epoch 204.\n",
      "\tTraining accuracy at step 13300: 0.9634299278259277.\n",
      "Starting epoch 205.\n",
      "Starting epoch 206.\n",
      "\tTraining accuracy at step 13400: 0.9635124206542969.\n",
      "Starting epoch 207.\n",
      "\tTraining accuracy at step 13500: 0.963587760925293.\n",
      "Starting epoch 208.\n",
      "Starting epoch 209.\n",
      "\tTraining accuracy at step 13600: 0.9636657238006592.\n",
      "Starting epoch 210.\n",
      "\tTraining accuracy at step 13700: 0.9637520909309387.\n",
      "Starting epoch 211.\n",
      "Starting epoch 212.\n",
      "\tTraining accuracy at step 13800: 0.9638521075248718.\n",
      "Starting epoch 213.\n",
      "\tTraining accuracy at step 13900: 0.9639474749565125.\n",
      "Starting epoch 214.\n",
      "Starting epoch 215.\n",
      "\tTraining accuracy at step 14000: 0.9639966487884521.\n",
      "Starting epoch 216.\n",
      "\tTraining accuracy at step 14100: 0.964020311832428.\n",
      "Starting epoch 217.\n",
      "Starting epoch 218.\n",
      "\tTraining accuracy at step 14200: 0.964066743850708.\n",
      "Starting epoch 219.\n",
      "\tTraining accuracy at step 14300: 0.9641304016113281.\n",
      "Starting epoch 220.\n",
      "Starting epoch 221.\n",
      "\tTraining accuracy at step 14400: 0.9642078876495361.\n",
      "Starting epoch 222.\n",
      "Starting epoch 223.\n",
      "\tTraining accuracy at step 14500: 0.9642736911773682.\n",
      "Starting epoch 224.\n",
      "\tTraining accuracy at step 14600: 0.9643446207046509.\n",
      "Starting epoch 225.\n",
      "Starting epoch 226.\n",
      "\tTraining accuracy at step 14700: 0.9643986821174622.\n",
      "Starting epoch 227.\n",
      "\tTraining accuracy at step 14800: 0.9644584655761719.\n",
      "Starting epoch 228.\n",
      "Starting epoch 229.\n",
      "\tTraining accuracy at step 14900: 0.9645051956176758.\n",
      "Starting epoch 230.\n",
      "\tTraining accuracy at step 15000: 0.9645386338233948.\n",
      "Starting epoch 231.\n",
      "Starting epoch 232.\n",
      "\tTraining accuracy at step 15100: 0.964591920375824.\n",
      "Starting epoch 233.\n",
      "\tTraining accuracy at step 15200: 0.9646444916725159.\n",
      "Starting epoch 234.\n",
      "Starting epoch 235.\n",
      "\tTraining accuracy at step 15300: 0.9646930694580078.\n",
      "Starting epoch 236.\n",
      "\tTraining accuracy at step 15400: 0.9647514224052429.\n",
      "Starting epoch 237.\n",
      "Starting epoch 238.\n",
      "\tTraining accuracy at step 15500: 0.9648094773292542.\n",
      "Starting epoch 239.\n",
      "\tTraining accuracy at step 15600: 0.9648293852806091.\n",
      "Starting epoch 240.\n",
      "Starting epoch 241.\n",
      "\tTraining accuracy at step 15700: 0.9648718237876892.\n",
      "Starting epoch 242.\n",
      "Starting epoch 243.\n",
      "\tTraining accuracy at step 15800: 0.9649280309677124.\n",
      "Starting epoch 244.\n",
      "\tTraining accuracy at step 15900: 0.9650023579597473.\n",
      "Starting epoch 245.\n",
      "Starting epoch 246.\n",
      "\tTraining accuracy at step 16000: 0.9650529623031616.\n",
      "Starting epoch 247.\n",
      "\tTraining accuracy at step 16100: 0.9651060700416565.\n",
      "Starting epoch 248.\n",
      "Starting epoch 249.\n",
      "\tTraining accuracy at step 16200: 0.9651472568511963.\n",
      "Starting epoch 250.\n",
      "\tTraining accuracy at step 16300: 0.9652255773544312.\n",
      "Starting epoch 251.\n",
      "Starting epoch 252.\n",
      "\tTraining accuracy at step 16400: 0.9652771353721619.\n",
      "Starting epoch 253.\n",
      "\tTraining accuracy at step 16500: 0.9653492569923401.\n",
      "Starting epoch 254.\n",
      "Starting epoch 255.\n",
      "\tTraining accuracy at step 16600: 0.9654157161712646.\n",
      "Starting epoch 256.\n",
      "\tTraining accuracy at step 16700: 0.9654931426048279.\n",
      "Starting epoch 257.\n",
      "Starting epoch 258.\n",
      "\tTraining accuracy at step 16800: 0.9655627012252808.\n",
      "Starting epoch 259.\n",
      "\tTraining accuracy at step 16900: 0.9656262993812561.\n",
      "Starting epoch 260.\n",
      "Starting epoch 261.\n",
      "\tTraining accuracy at step 17000: 0.965656042098999.\n",
      "Starting epoch 262.\n",
      "Starting epoch 263.\n",
      "\tTraining accuracy at step 17100: 0.965701699256897.\n",
      "Starting epoch 264.\n",
      "\tTraining accuracy at step 17200: 0.9657765030860901.\n",
      "Starting epoch 265.\n",
      "Starting epoch 266.\n",
      "\tTraining accuracy at step 17300: 0.9658516645431519.\n",
      "Starting epoch 267.\n",
      "\tTraining accuracy at step 17400: 0.9659150838851929.\n",
      "Starting epoch 268.\n",
      "Starting epoch 269.\n",
      "\tTraining accuracy at step 17500: 0.9659731984138489.\n",
      "Starting epoch 270.\n",
      "\tTraining accuracy at step 17600: 0.9660369157791138.\n",
      "Starting epoch 271.\n",
      "Starting epoch 272.\n",
      "\tTraining accuracy at step 17700: 0.9660565853118896.\n",
      "Starting epoch 273.\n",
      "\tTraining accuracy at step 17800: 0.9661129117012024.\n",
      "Starting epoch 274.\n",
      "Starting epoch 275.\n",
      "\tTraining accuracy at step 17900: 0.9661649465560913.\n",
      "Starting epoch 276.\n",
      "\tTraining accuracy at step 18000: 0.9662034511566162.\n",
      "Starting epoch 277.\n",
      "Starting epoch 278.\n",
      "\tTraining accuracy at step 18100: 0.9662202000617981.\n",
      "Starting epoch 279.\n",
      "\tTraining accuracy at step 18200: 0.9662535786628723.\n",
      "Starting epoch 280.\n",
      "Starting epoch 281.\n",
      "\tTraining accuracy at step 18300: 0.9662913680076599.\n",
      "Starting epoch 282.\n",
      "Starting epoch 283.\n",
      "\tTraining accuracy at step 18400: 0.9663342833518982.\n",
      "Starting epoch 284.\n",
      "\tTraining accuracy at step 18500: 0.9663838148117065.\n",
      "Starting epoch 285.\n",
      "Starting epoch 286.\n",
      "\tTraining accuracy at step 18600: 0.9664363861083984.\n",
      "Starting epoch 287.\n",
      "\tTraining accuracy at step 18700: 0.9664700031280518.\n",
      "Starting epoch 288.\n",
      "Starting epoch 289.\n",
      "\tTraining accuracy at step 18800: 0.966497540473938.\n",
      "Starting epoch 290.\n",
      "\tTraining accuracy at step 18900: 0.9665173888206482.\n",
      "Starting epoch 291.\n",
      "Starting epoch 292.\n",
      "\tTraining accuracy at step 19000: 0.9665573835372925.\n",
      "Starting epoch 293.\n",
      "\tTraining accuracy at step 19100: 0.9665904641151428.\n",
      "Starting epoch 294.\n",
      "Starting epoch 295.\n",
      "\tTraining accuracy at step 19200: 0.9666182398796082.\n",
      "Starting epoch 296.\n",
      "\tTraining accuracy at step 19300: 0.9666321277618408.\n",
      "Starting epoch 297.\n",
      "Starting epoch 298.\n",
      "\tTraining accuracy at step 19400: 0.9666613340377808.\n",
      "Starting epoch 299.\n",
      "\tTraining accuracy at step 19500: 0.9666991829872131.\n",
      "Starting epoch 300.\n",
      "Starting epoch 301.\n",
      "\tTraining accuracy at step 19600: 0.9667463302612305.\n",
      "Starting epoch 302.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 303.\n",
      "\tTraining accuracy at step 19700: 0.9667774438858032.\n",
      "Starting epoch 304.\n",
      "\tTraining accuracy at step 19800: 0.9668096899986267.\n",
      "Starting epoch 305.\n",
      "Starting epoch 306.\n",
      "\tTraining accuracy at step 19900: 0.9668369293212891.\n",
      "Starting epoch 307.\n",
      "\tTraining accuracy at step 20000: 0.9668532609939575.\n",
      "Starting epoch 308.\n",
      "Starting epoch 309.\n",
      "\tTraining accuracy at step 20100: 0.9668799638748169.\n",
      "Starting epoch 310.\n",
      "\tTraining accuracy at step 20200: 0.9668883085250854.\n",
      "Starting epoch 311.\n",
      "Starting epoch 312.\n",
      "\tTraining accuracy at step 20300: 0.9669138789176941.\n",
      "Starting epoch 313.\n",
      "\tTraining accuracy at step 20400: 0.9669448733329773.\n",
      "Starting epoch 314.\n",
      "Starting epoch 315.\n",
      "\tTraining accuracy at step 20500: 0.9669720530509949.\n",
      "Starting epoch 316.\n",
      "\tTraining accuracy at step 20600: 0.966992199420929.\n",
      "Starting epoch 317.\n",
      "Starting epoch 318.\n",
      "\tTraining accuracy at step 20700: 0.9670054912567139.\n",
      "Starting epoch 319.\n",
      "\tTraining accuracy at step 20800: 0.9670473337173462.\n",
      "Starting epoch 320.\n",
      "Starting epoch 321.\n",
      "\tTraining accuracy at step 20900: 0.967096209526062.\n",
      "Starting epoch 322.\n",
      "Starting epoch 323.\n",
      "\tTraining accuracy at step 21000: 0.9671216011047363.\n",
      "Starting epoch 324.\n",
      "\tTraining accuracy at step 21100: 0.9671540856361389.\n",
      "Starting epoch 325.\n",
      "Starting epoch 326.\n",
      "\tTraining accuracy at step 21200: 0.9671951532363892.\n",
      "Starting epoch 327.\n",
      "\tTraining accuracy at step 21300: 0.9672502875328064.\n",
      "Starting epoch 328.\n",
      "Starting epoch 329.\n",
      "\tTraining accuracy at step 21400: 0.9672755599021912.\n",
      "Starting epoch 330.\n",
      "\tTraining accuracy at step 21500: 0.9673060178756714.\n",
      "Starting epoch 331.\n",
      "Starting epoch 332.\n",
      "\tTraining accuracy at step 21600: 0.9673351645469666.\n",
      "Starting epoch 333.\n",
      "\tTraining accuracy at step 21700: 0.9673563241958618.\n",
      "Starting epoch 334.\n",
      "Starting epoch 335.\n",
      "\tTraining accuracy at step 21800: 0.9673870205879211.\n",
      "Starting epoch 336.\n",
      "\tTraining accuracy at step 21900: 0.9673940539360046.\n",
      "Starting epoch 337.\n",
      "Starting epoch 338.\n",
      "\tTraining accuracy at step 22000: 0.9674242734909058.\n",
      "Starting epoch 339.\n",
      "\tTraining accuracy at step 22100: 0.9674476385116577.\n",
      "Starting epoch 340.\n",
      "Starting epoch 341.\n",
      "\tTraining accuracy at step 22200: 0.9674707651138306.\n",
      "Starting epoch 342.\n",
      "Starting epoch 343.\n",
      "\tTraining accuracy at step 22300: 0.9674913883209229.\n",
      "Starting epoch 344.\n",
      "\tTraining accuracy at step 22400: 0.9675137996673584.\n",
      "Starting epoch 345.\n",
      "Starting epoch 346.\n",
      "\tTraining accuracy at step 22500: 0.9675178527832031.\n",
      "Starting epoch 347.\n",
      "\tTraining accuracy at step 22600: 0.967548668384552.\n",
      "Starting epoch 348.\n",
      "Starting epoch 349.\n",
      "\tTraining accuracy at step 22700: 0.9675866365432739.\n",
      "Starting epoch 350.\n",
      "\tTraining accuracy at step 22800: 0.9676149487495422.\n",
      "Starting epoch 351.\n",
      "Starting epoch 352.\n",
      "\tTraining accuracy at step 22900: 0.9676458835601807.\n",
      "Starting epoch 353.\n",
      "\tTraining accuracy at step 23000: 0.9676806330680847.\n",
      "Starting epoch 354.\n",
      "Starting epoch 355.\n",
      "\tTraining accuracy at step 23100: 0.9677233695983887.\n",
      "Starting epoch 356.\n",
      "\tTraining accuracy at step 23200: 0.9677496552467346.\n",
      "Starting epoch 357.\n",
      "Starting epoch 358.\n",
      "\tTraining accuracy at step 23300: 0.9677663445472717.\n",
      "Starting epoch 359.\n",
      "\tTraining accuracy at step 23400: 0.9677850604057312.\n",
      "Starting epoch 360.\n",
      "Starting epoch 361.\n",
      "\tTraining accuracy at step 23500: 0.9677971005439758.\n",
      "Starting epoch 362.\n",
      "Starting epoch 363.\n",
      "\tTraining accuracy at step 23600: 0.9678155183792114.\n",
      "Starting epoch 364.\n",
      "\tTraining accuracy at step 23700: 0.9678374528884888.\n",
      "Starting epoch 365.\n",
      "Starting epoch 366.\n",
      "\tTraining accuracy at step 23800: 0.967872142791748.\n",
      "Starting epoch 367.\n",
      "\tTraining accuracy at step 23900: 0.9679083228111267.\n",
      "Starting epoch 368.\n",
      "Starting epoch 369.\n",
      "\tTraining accuracy at step 24000: 0.9679381251335144.\n",
      "Starting epoch 370.\n",
      "\tTraining accuracy at step 24100: 0.9679552912712097.\n",
      "Starting epoch 371.\n",
      "Starting epoch 372.\n",
      "\tTraining accuracy at step 24200: 0.9679620862007141.\n",
      "Starting epoch 373.\n",
      "\tTraining accuracy at step 24300: 0.9679780602455139.\n",
      "Starting epoch 374.\n",
      "Starting epoch 375.\n",
      "\tTraining accuracy at step 24400: 0.9679978489875793.\n",
      "Starting epoch 376.\n",
      "\tTraining accuracy at step 24500: 0.968018651008606.\n",
      "Starting epoch 377.\n",
      "Starting epoch 378.\n",
      "\tTraining accuracy at step 24600: 0.968047559261322.\n",
      "Starting epoch 379.\n",
      "\tTraining accuracy at step 24700: 0.9680635929107666.\n",
      "Starting epoch 380.\n",
      "Starting epoch 381.\n",
      "\tTraining accuracy at step 24800: 0.968086838722229.\n",
      "Starting epoch 382.\n",
      "Starting epoch 383.\n",
      "\tTraining accuracy at step 24900: 0.9681054353713989.\n",
      "Starting epoch 384.\n",
      "\tTraining accuracy at step 25000: 0.968130350112915.\n",
      "Starting epoch 385.\n",
      "Starting epoch 386.\n",
      "\tTraining accuracy at step 25100: 0.9681493043899536.\n",
      "Starting epoch 387.\n",
      "\tTraining accuracy at step 25200: 0.9681689143180847.\n",
      "Starting epoch 388.\n",
      "Starting epoch 389.\n",
      "\tTraining accuracy at step 25300: 0.9681918025016785.\n",
      "Starting epoch 390.\n",
      "\tTraining accuracy at step 25400: 0.9681812524795532.\n",
      "Starting epoch 391.\n",
      "Starting epoch 392.\n",
      "\tTraining accuracy at step 25500: 0.9681828022003174.\n",
      "Starting epoch 393.\n",
      "\tTraining accuracy at step 25600: 0.9681974053382874.\n",
      "Starting epoch 394.\n",
      "Starting epoch 395.\n",
      "\tTraining accuracy at step 25700: 0.9682190418243408.\n",
      "Starting epoch 396.\n",
      "\tTraining accuracy at step 25800: 0.9682461023330688.\n",
      "Starting epoch 397.\n",
      "Starting epoch 398.\n",
      "\tTraining accuracy at step 25900: 0.968271017074585.\n",
      "Starting epoch 399.\n",
      "\tTraining accuracy at step 26000: 0.9682834148406982.\n",
      "Starting epoch 400.\n",
      "Starting epoch 401.\n",
      "\tTraining accuracy at step 26100: 0.9683015942573547.\n",
      "Starting epoch 402.\n",
      "Starting epoch 403.\n",
      "\tTraining accuracy at step 26200: 0.9683170914649963.\n",
      "Starting epoch 404.\n",
      "\tTraining accuracy at step 26300: 0.9683269262313843.\n",
      "Starting epoch 405.\n",
      "Starting epoch 406.\n",
      "\tTraining accuracy at step 26400: 0.9683455228805542.\n",
      "Starting epoch 407.\n",
      "\tTraining accuracy at step 26500: 0.9683634638786316.\n",
      "Starting epoch 408.\n",
      "Starting epoch 409.\n",
      "\tTraining accuracy at step 26600: 0.9683752059936523.\n",
      "Starting epoch 410.\n",
      "\tTraining accuracy at step 26700: 0.9683955907821655.\n",
      "Starting epoch 411.\n",
      "Starting epoch 412.\n",
      "\tTraining accuracy at step 26800: 0.9684158563613892.\n",
      "Starting epoch 413.\n",
      "\tTraining accuracy at step 26900: 0.9684248566627502.\n",
      "Starting epoch 414.\n",
      "Starting epoch 415.\n",
      "\tTraining accuracy at step 27000: 0.9684373140335083.\n",
      "Starting epoch 416.\n",
      "\tTraining accuracy at step 27100: 0.968467116355896.\n",
      "Starting epoch 417.\n",
      "Starting epoch 418.\n",
      "\tTraining accuracy at step 27200: 0.9684919118881226.\n",
      "Starting epoch 419.\n",
      "\tTraining accuracy at step 27300: 0.9685156941413879.\n",
      "Starting epoch 420.\n",
      "Starting epoch 421.\n",
      "\tTraining accuracy at step 27400: 0.9685196280479431.\n",
      "Starting epoch 422.\n",
      "Starting epoch 423.\n",
      "\tTraining accuracy at step 27500: 0.9685474038124084.\n",
      "Starting epoch 424.\n",
      "\tTraining accuracy at step 27600: 0.9685641527175903.\n",
      "Starting epoch 425.\n",
      "Starting epoch 426.\n",
      "\tTraining accuracy at step 27700: 0.9685912728309631.\n",
      "Starting epoch 427.\n",
      "\tTraining accuracy at step 27800: 0.9686114192008972.\n",
      "Starting epoch 428.\n",
      "Starting epoch 429.\n",
      "\tTraining accuracy at step 27900: 0.9686285257339478.\n",
      "Starting epoch 430.\n",
      "\tTraining accuracy at step 28000: 0.9686424136161804.\n",
      "Starting epoch 431.\n",
      "Starting epoch 432.\n",
      "\tTraining accuracy at step 28100: 0.96867436170578.\n",
      "Starting epoch 433.\n",
      "\tTraining accuracy at step 28200: 0.9686918258666992.\n",
      "Starting epoch 434.\n",
      "Starting epoch 435.\n",
      "\tTraining accuracy at step 28300: 0.9687076210975647.\n",
      "Starting epoch 436.\n",
      "\tTraining accuracy at step 28400: 0.9687253832817078.\n",
      "Starting epoch 437.\n",
      "Starting epoch 438.\n",
      "\tTraining accuracy at step 28500: 0.9687453508377075.\n",
      "Starting epoch 439.\n",
      "\tTraining accuracy at step 28600: 0.9687677025794983.\n",
      "Starting epoch 440.\n",
      "Starting epoch 441.\n",
      "\tTraining accuracy at step 28700: 0.9687929153442383.\n",
      "Starting epoch 442.\n",
      "Starting epoch 443.\n",
      "\tTraining accuracy at step 28800: 0.9688209891319275.\n",
      "Starting epoch 444.\n",
      "\tTraining accuracy at step 28900: 0.9688377976417542.\n",
      "Starting epoch 445.\n",
      "Starting epoch 446.\n",
      "\tTraining accuracy at step 29000: 0.9688534736633301.\n",
      "Starting epoch 447.\n",
      "\tTraining accuracy at step 29100: 0.9688811302185059.\n",
      "Starting epoch 448.\n",
      "Starting epoch 449.\n",
      "\tTraining accuracy at step 29200: 0.9688962697982788.\n",
      "Starting epoch 450.\n",
      "\tTraining accuracy at step 29300: 0.9689185619354248.\n",
      "Starting epoch 451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 452.\n",
      "\tTraining accuracy at step 29400: 0.9689342379570007.\n",
      "Starting epoch 453.\n",
      "\tTraining accuracy at step 29500: 0.9689610004425049.\n",
      "Starting epoch 454.\n",
      "Starting epoch 455.\n",
      "\tTraining accuracy at step 29600: 0.9689882397651672.\n",
      "Starting epoch 456.\n",
      "\tTraining accuracy at step 29700: 0.9689939618110657.\n",
      "Starting epoch 457.\n",
      "Starting epoch 458.\n",
      "\tTraining accuracy at step 29800: 0.9690026044845581.\n",
      "Starting epoch 459.\n",
      "\tTraining accuracy at step 29900: 0.9690079689025879.\n",
      "Starting epoch 460.\n",
      "Starting epoch 461.\n",
      "\tTraining accuracy at step 30000: 0.969031810760498.\n",
      "Starting epoch 462.\n",
      "Starting epoch 463.\n",
      "\tTraining accuracy at step 30100: 0.9690583944320679.\n",
      "Starting epoch 464.\n",
      "\tTraining accuracy at step 30200: 0.969078004360199.\n",
      "Starting epoch 465.\n",
      "Starting epoch 466.\n",
      "\tTraining accuracy at step 30300: 0.9690934419631958.\n",
      "Starting epoch 467.\n",
      "\tTraining accuracy at step 30400: 0.9691092371940613.\n",
      "Starting epoch 468.\n",
      "Starting epoch 469.\n",
      "\tTraining accuracy at step 30500: 0.9691246747970581.\n",
      "Starting epoch 470.\n",
      "\tTraining accuracy at step 30600: 0.9691421985626221.\n",
      "Starting epoch 471.\n",
      "Starting epoch 472.\n",
      "\tTraining accuracy at step 30700: 0.9691555500030518.\n",
      "Starting epoch 473.\n",
      "\tTraining accuracy at step 30800: 0.9691747426986694.\n",
      "Starting epoch 474.\n",
      "Starting epoch 475.\n",
      "\tTraining accuracy at step 30900: 0.9691932797431946.\n",
      "Starting epoch 476.\n",
      "\tTraining accuracy at step 31000: 0.9692032933235168.\n",
      "Starting epoch 477.\n",
      "Starting epoch 478.\n",
      "\tTraining accuracy at step 31100: 0.9692094922065735.\n",
      "Starting epoch 479.\n",
      "\tTraining accuracy at step 31200: 0.969214916229248.\n",
      "Starting epoch 480.\n",
      "Starting epoch 481.\n",
      "\tTraining accuracy at step 31300: 0.9692354798316956.\n",
      "Starting epoch 482.\n",
      "Starting epoch 483.\n",
      "\tTraining accuracy at step 31400: 0.9692563414573669.\n",
      "Starting epoch 484.\n",
      "\tTraining accuracy at step 31500: 0.9692803621292114.\n",
      "Starting epoch 485.\n",
      "Starting epoch 486.\n",
      "\tTraining accuracy at step 31600: 0.9693048596382141.\n",
      "Starting epoch 487.\n",
      "\tTraining accuracy at step 31700: 0.9693251252174377.\n",
      "Starting epoch 488.\n",
      "Starting epoch 489.\n",
      "\tTraining accuracy at step 31800: 0.9693489074707031.\n",
      "Starting epoch 490.\n",
      "\tTraining accuracy at step 31900: 0.969367504119873.\n",
      "Starting epoch 491.\n",
      "Starting epoch 492.\n",
      "\tTraining accuracy at step 32000: 0.9693816304206848.\n",
      "Starting epoch 493.\n",
      "\tTraining accuracy at step 32100: 0.9694022536277771.\n",
      "Starting epoch 494.\n",
      "Starting epoch 495.\n",
      "\tTraining accuracy at step 32200: 0.9694046974182129.\n",
      "Starting epoch 496.\n",
      "\tTraining accuracy at step 32300: 0.969417929649353.\n",
      "Starting epoch 497.\n",
      "Starting epoch 498.\n",
      "\tTraining accuracy at step 32400: 0.9694409370422363.\n",
      "Starting epoch 499.\n",
      "\tTraining accuracy at step 32500: 0.969456672668457.\n",
      "Starting epoch 500.\n",
      "Starting epoch 501.\n",
      "\tTraining accuracy at step 32600: 0.9694796800613403.\n",
      "Starting epoch 502.\n",
      "Starting epoch 503.\n",
      "\tTraining accuracy at step 32700: 0.9694988131523132.\n",
      "Starting epoch 504.\n",
      "\tTraining accuracy at step 32800: 0.969519317150116.\n",
      "Starting epoch 505.\n",
      "Starting epoch 506.\n",
      "\tTraining accuracy at step 32900: 0.9695417284965515.\n",
      "Starting epoch 507.\n",
      "\tTraining accuracy at step 33000: 0.9695533514022827.\n",
      "Starting epoch 508.\n",
      "Starting epoch 509.\n",
      "\tTraining accuracy at step 33100: 0.9695667028427124.\n",
      "Starting epoch 510.\n",
      "\tTraining accuracy at step 33200: 0.9695825576782227.\n",
      "Starting epoch 511.\n",
      "Starting epoch 512.\n",
      "\tTraining accuracy at step 33300: 0.9696016907691956.\n",
      "Starting epoch 513.\n",
      "\tTraining accuracy at step 33400: 0.9696121215820312.\n",
      "Starting epoch 514.\n",
      "Starting epoch 515.\n",
      "\tTraining accuracy at step 33500: 0.9696196913719177.\n",
      "Starting epoch 516.\n",
      "\tTraining accuracy at step 33600: 0.9696322083473206.\n",
      "Starting epoch 517.\n",
      "Starting epoch 518.\n",
      "\tTraining accuracy at step 33700: 0.9696431159973145.\n",
      "Starting epoch 519.\n",
      "\tTraining accuracy at step 33800: 0.969661295413971.\n",
      "Starting epoch 520.\n",
      "Starting epoch 521.\n",
      "\tTraining accuracy at step 33900: 0.9696822166442871.\n",
      "Starting epoch 522.\n",
      "Starting epoch 523.\n",
      "\tTraining accuracy at step 34000: 0.9696922302246094.\n",
      "Starting epoch 524.\n",
      "\tTraining accuracy at step 34100: 0.9697005152702332.\n",
      "Starting epoch 525.\n",
      "Starting epoch 526.\n",
      "\tTraining accuracy at step 34200: 0.9697132110595703.\n",
      "Starting epoch 527.\n",
      "\tTraining accuracy at step 34300: 0.9697262048721313.\n",
      "Starting epoch 528.\n",
      "Starting epoch 529.\n",
      "\tTraining accuracy at step 34400: 0.9697402715682983.\n",
      "Starting epoch 530.\n",
      "\tTraining accuracy at step 34500: 0.9697542190551758.\n",
      "Starting epoch 531.\n",
      "Starting epoch 532.\n",
      "\tTraining accuracy at step 34600: 0.9697607159614563.\n",
      "Starting epoch 533.\n",
      "\tTraining accuracy at step 34700: 0.969785213470459.\n",
      "Starting epoch 534.\n",
      "Starting epoch 535.\n",
      "\tTraining accuracy at step 34800: 0.969807505607605.\n",
      "Starting epoch 536.\n",
      "\tTraining accuracy at step 34900: 0.9698277711868286.\n",
      "Starting epoch 537.\n",
      "Starting epoch 538.\n",
      "\tTraining accuracy at step 35000: 0.9698477387428284.\n",
      "Starting epoch 539.\n",
      "\tTraining accuracy at step 35100: 0.9698482751846313.\n",
      "Starting epoch 540.\n",
      "Starting epoch 541.\n",
      "\tTraining accuracy at step 35200: 0.9698494076728821.\n",
      "Starting epoch 542.\n",
      "Starting epoch 543.\n",
      "\tTraining accuracy at step 35300: 0.969860851764679.\n",
      "Starting epoch 544.\n",
      "\tTraining accuracy at step 35400: 0.9698764085769653.\n",
      "Starting epoch 545.\n",
      "Starting epoch 546.\n",
      "\tTraining accuracy at step 35500: 0.9698899984359741.\n",
      "Starting epoch 547.\n",
      "\tTraining accuracy at step 35600: 0.9699018597602844.\n",
      "Starting epoch 548.\n",
      "Starting epoch 549.\n",
      "\tTraining accuracy at step 35700: 0.9699083566665649.\n",
      "Starting epoch 550.\n",
      "\tTraining accuracy at step 35800: 0.9699123501777649.\n",
      "Starting epoch 551.\n",
      "Starting epoch 552.\n",
      "\tTraining accuracy at step 35900: 0.9699183702468872.\n",
      "Starting epoch 553.\n",
      "\tTraining accuracy at step 36000: 0.9699364900588989.\n",
      "Starting epoch 554.\n",
      "Starting epoch 555.\n",
      "\tTraining accuracy at step 36100: 0.9699569344520569.\n",
      "Starting epoch 556.\n",
      "\tTraining accuracy at step 36200: 0.9699795246124268.\n",
      "Starting epoch 557.\n",
      "Starting epoch 558.\n",
      "\tTraining accuracy at step 36300: 0.9700047969818115.\n",
      "Starting epoch 559.\n",
      "\tTraining accuracy at step 36400: 0.9700264930725098.\n",
      "Starting epoch 560.\n",
      "Starting epoch 561.\n",
      "\tTraining accuracy at step 36500: 0.9700399041175842.\n",
      "Starting epoch 562.\n",
      "Starting epoch 563.\n",
      "\tTraining accuracy at step 36600: 0.9700531959533691.\n",
      "Starting epoch 564.\n",
      "\tTraining accuracy at step 36700: 0.9700650572776794.\n",
      "Starting epoch 565.\n",
      "Starting epoch 566.\n",
      "\tTraining accuracy at step 36800: 0.9700859785079956.\n",
      "Starting epoch 567.\n",
      "\tTraining accuracy at step 36900: 0.9700902104377747.\n",
      "Starting epoch 568.\n",
      "Starting epoch 569.\n",
      "\tTraining accuracy at step 37000: 0.9701014757156372.\n",
      "Starting epoch 570.\n",
      "\tTraining accuracy at step 37100: 0.9701075553894043.\n",
      "Starting epoch 571.\n",
      "Starting epoch 572.\n",
      "\tTraining accuracy at step 37200: 0.9701101183891296.\n",
      "Starting epoch 573.\n",
      "\tTraining accuracy at step 37300: 0.9701210260391235.\n",
      "Starting epoch 574.\n",
      "Starting epoch 575.\n",
      "\tTraining accuracy at step 37400: 0.9701399207115173.\n",
      "Starting epoch 576.\n",
      "\tTraining accuracy at step 37500: 0.9701565504074097.\n",
      "Starting epoch 577.\n",
      "Starting epoch 578.\n",
      "\tTraining accuracy at step 37600: 0.9701709151268005.\n",
      "Starting epoch 579.\n",
      "\tTraining accuracy at step 37700: 0.9701947569847107.\n",
      "Starting epoch 580.\n",
      "Starting epoch 581.\n",
      "\tTraining accuracy at step 37800: 0.9702134132385254.\n",
      "Starting epoch 582.\n",
      "Starting epoch 583.\n",
      "\tTraining accuracy at step 37900: 0.9702296853065491.\n",
      "Starting epoch 584.\n",
      "\tTraining accuracy at step 38000: 0.9702370166778564.\n",
      "Starting epoch 585.\n",
      "Starting epoch 586.\n",
      "\tTraining accuracy at step 38100: 0.9702611565589905.\n",
      "Starting epoch 587.\n",
      "\tTraining accuracy at step 38200: 0.9702842235565186.\n",
      "Starting epoch 588.\n",
      "Starting epoch 589.\n",
      "\tTraining accuracy at step 38300: 0.9703088998794556.\n",
      "Starting epoch 590.\n",
      "\tTraining accuracy at step 38400: 0.9703168869018555.\n",
      "Starting epoch 591.\n",
      "Starting epoch 592.\n",
      "\tTraining accuracy at step 38500: 0.9703387022018433.\n",
      "Starting epoch 593.\n",
      "\tTraining accuracy at step 38600: 0.9703531861305237.\n",
      "Starting epoch 594.\n",
      "Starting epoch 595.\n",
      "\tTraining accuracy at step 38700: 0.9703685641288757.\n",
      "Starting epoch 596.\n",
      "\tTraining accuracy at step 38800: 0.9703791737556458.\n",
      "Starting epoch 597.\n",
      "Starting epoch 598.\n",
      "\tTraining accuracy at step 38900: 0.9703949689865112.\n",
      "Starting epoch 599.\n",
      "\tTraining accuracy at step 39000: 0.9704123735427856.\n",
      "Starting epoch 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 601.\n",
      "\tTraining accuracy at step 39100: 0.9704235196113586.\n",
      "Starting epoch 602.\n",
      "Starting epoch 603.\n",
      "\tTraining accuracy at step 39200: 0.9704403281211853.\n",
      "Starting epoch 604.\n",
      "\tTraining accuracy at step 39300: 0.9704489707946777.\n",
      "Starting epoch 605.\n",
      "Starting epoch 606.\n",
      "\tTraining accuracy at step 39400: 0.9704703092575073.\n",
      "Starting epoch 607.\n",
      "\tTraining accuracy at step 39500: 0.9704933762550354.\n",
      "Starting epoch 608.\n",
      "Starting epoch 609.\n",
      "\tTraining accuracy at step 39600: 0.9705222249031067.\n",
      "Starting epoch 610.\n",
      "\tTraining accuracy at step 39700: 0.9705469012260437.\n",
      "Starting epoch 611.\n",
      "Starting epoch 612.\n",
      "\tTraining accuracy at step 39800: 0.9705615043640137.\n",
      "Starting epoch 613.\n",
      "\tTraining accuracy at step 39900: 0.970572829246521.\n",
      "Starting epoch 614.\n",
      "Starting epoch 615.\n",
      "\tTraining accuracy at step 40000: 0.9705847501754761.\n",
      "Starting epoch 616.\n",
      "\tTraining accuracy at step 40100: 0.9705997705459595.\n",
      "Starting epoch 617.\n",
      "Starting epoch 618.\n",
      "\tTraining accuracy at step 40200: 0.970610499382019.\n",
      "Starting epoch 619.\n",
      "\tTraining accuracy at step 40300: 0.9706273078918457.\n",
      "Starting epoch 620.\n",
      "Starting epoch 621.\n",
      "\tTraining accuracy at step 40400: 0.9706498384475708.\n",
      "Starting epoch 622.\n",
      "Starting epoch 623.\n",
      "\tTraining accuracy at step 40500: 0.9706634283065796.\n",
      "Starting epoch 624.\n",
      "\tTraining accuracy at step 40600: 0.9706669449806213.\n",
      "Starting epoch 625.\n",
      "Starting epoch 626.\n",
      "\tTraining accuracy at step 40700: 0.9706640839576721.\n",
      "Starting epoch 627.\n",
      "\tTraining accuracy at step 40800: 0.9706750512123108.\n",
      "Starting epoch 628.\n",
      "Starting epoch 629.\n",
      "\tTraining accuracy at step 40900: 0.9706902503967285.\n",
      "Starting epoch 630.\n",
      "\tTraining accuracy at step 41000: 0.9706893563270569.\n",
      "Starting epoch 631.\n",
      "Starting epoch 632.\n",
      "\tTraining accuracy at step 41100: 0.9706984162330627.\n",
      "Starting epoch 633.\n",
      "\tTraining accuracy at step 41200: 0.9707086086273193.\n",
      "Starting epoch 634.\n",
      "Starting epoch 635.\n",
      "\tTraining accuracy at step 41300: 0.9707207679748535.\n",
      "Starting epoch 636.\n",
      "\tTraining accuracy at step 41400: 0.9707345962524414.\n",
      "Starting epoch 637.\n",
      "Starting epoch 638.\n",
      "\tTraining accuracy at step 41500: 0.9707481861114502.\n",
      "Starting epoch 639.\n",
      "\tTraining accuracy at step 41600: 0.9707629680633545.\n",
      "Starting epoch 640.\n",
      "Starting epoch 641.\n",
      "\tTraining accuracy at step 41700: 0.97076815366745.\n",
      "Starting epoch 642.\n",
      "Starting epoch 643.\n",
      "\tTraining accuracy at step 41800: 0.9707638025283813.\n",
      "Starting epoch 644.\n",
      "\tTraining accuracy at step 41900: 0.9707653522491455.\n",
      "Starting epoch 645.\n",
      "Starting epoch 646.\n",
      "\tTraining accuracy at step 42000: 0.9707712531089783.\n",
      "Starting epoch 647.\n",
      "\tTraining accuracy at step 42100: 0.9707849025726318.\n",
      "Starting epoch 648.\n",
      "Starting epoch 649.\n",
      "\tTraining accuracy at step 42200: 0.970795214176178.\n",
      "Starting epoch 650.\n",
      "\tTraining accuracy at step 42300: 0.970805287361145.\n",
      "Starting epoch 651.\n",
      "Starting epoch 652.\n",
      "\tTraining accuracy at step 42400: 0.9708124399185181.\n",
      "Starting epoch 653.\n",
      "\tTraining accuracy at step 42500: 0.9708220958709717.\n",
      "Starting epoch 654.\n",
      "Starting epoch 655.\n",
      "\tTraining accuracy at step 42600: 0.9708311557769775.\n",
      "Starting epoch 656.\n",
      "\tTraining accuracy at step 42700: 0.9708445072174072.\n",
      "Starting epoch 657.\n",
      "Starting epoch 658.\n",
      "\tTraining accuracy at step 42800: 0.9708620309829712.\n",
      "Starting epoch 659.\n",
      "\tTraining accuracy at step 42900: 0.9708572030067444.\n",
      "Starting epoch 660.\n",
      "Starting epoch 661.\n",
      "\tTraining accuracy at step 43000: 0.9708627462387085.\n",
      "Starting epoch 662.\n",
      "Starting epoch 663.\n",
      "\tTraining accuracy at step 43100: 0.9708731770515442.\n",
      "Starting epoch 664.\n",
      "\tTraining accuracy at step 43200: 0.9708811640739441.\n",
      "Starting epoch 665.\n",
      "Starting epoch 666.\n",
      "\tTraining accuracy at step 43300: 0.9708916544914246.\n",
      "Starting epoch 667.\n",
      "\tTraining accuracy at step 43400: 0.9708977341651917.\n",
      "Starting epoch 668.\n",
      "Starting epoch 669.\n",
      "\tTraining accuracy at step 43500: 0.970906138420105.\n",
      "Starting epoch 670.\n",
      "\tTraining accuracy at step 43600: 0.970907986164093.\n",
      "Starting epoch 671.\n",
      "Starting epoch 672.\n",
      "\tTraining accuracy at step 43700: 0.9709104895591736.\n",
      "Starting epoch 673.\n",
      "\tTraining accuracy at step 43800: 0.970923125743866.\n",
      "Starting epoch 674.\n",
      "Starting epoch 675.\n",
      "\tTraining accuracy at step 43900: 0.9709285497665405.\n",
      "Starting epoch 676.\n",
      "\tTraining accuracy at step 44000: 0.9709277153015137.\n",
      "Starting epoch 677.\n",
      "Starting epoch 678.\n",
      "\tTraining accuracy at step 44100: 0.9709327816963196.\n",
      "Starting epoch 679.\n",
      "\tTraining accuracy at step 44200: 0.9709409475326538.\n",
      "Starting epoch 680.\n",
      "Starting epoch 681.\n",
      "\tTraining accuracy at step 44300: 0.9709479212760925.\n",
      "Starting epoch 682.\n",
      "Starting epoch 683.\n",
      "\tTraining accuracy at step 44400: 0.9709590077400208.\n",
      "Starting epoch 684.\n",
      "\tTraining accuracy at step 44500: 0.9709677696228027.\n",
      "Starting epoch 685.\n",
      "Starting epoch 686.\n",
      "\tTraining accuracy at step 44600: 0.9709761142730713.\n",
      "Starting epoch 687.\n",
      "\tTraining accuracy at step 44700: 0.9709883332252502.\n",
      "Starting epoch 688.\n",
      "Starting epoch 689.\n",
      "\tTraining accuracy at step 44800: 0.97100430727005.\n",
      "Starting epoch 690.\n",
      "\tTraining accuracy at step 44900: 0.971019983291626.\n",
      "Starting epoch 691.\n",
      "Starting epoch 692.\n",
      "\tTraining accuracy at step 45000: 0.9710279703140259.\n",
      "Starting epoch 693.\n",
      "\tTraining accuracy at step 45100: 0.9710409641265869.\n",
      "Starting epoch 694.\n",
      "Starting epoch 695.\n",
      "\tTraining accuracy at step 45200: 0.9710458517074585.\n",
      "Starting epoch 696.\n",
      "\tTraining accuracy at step 45300: 0.971045196056366.\n",
      "Starting epoch 697.\n",
      "Starting epoch 698.\n",
      "\tTraining accuracy at step 45400: 0.9710425138473511.\n",
      "Starting epoch 699.\n",
      "\tTraining accuracy at step 45500: 0.9710511565208435.\n",
      "Starting epoch 700.\n",
      "Starting epoch 701.\n",
      "\tTraining accuracy at step 45600: 0.9710604548454285.\n",
      "Starting epoch 702.\n",
      "Starting epoch 703.\n",
      "\tTraining accuracy at step 45700: 0.9710689187049866.\n",
      "Starting epoch 704.\n",
      "\tTraining accuracy at step 45800: 0.9710812568664551.\n",
      "Starting epoch 705.\n",
      "Starting epoch 706.\n",
      "\tTraining accuracy at step 45900: 0.9710923433303833.\n",
      "Starting epoch 707.\n",
      "\tTraining accuracy at step 46000: 0.9710988998413086.\n",
      "Starting epoch 708.\n",
      "Starting epoch 709.\n",
      "\tTraining accuracy at step 46100: 0.9711090922355652.\n",
      "Starting epoch 710.\n",
      "\tTraining accuracy at step 46200: 0.9711197018623352.\n",
      "Starting epoch 711.\n",
      "Starting epoch 712.\n",
      "\tTraining accuracy at step 46300: 0.9711251854896545.\n",
      "Starting epoch 713.\n",
      "\tTraining accuracy at step 46400: 0.9711320996284485.\n",
      "Starting epoch 714.\n",
      "Starting epoch 715.\n",
      "\tTraining accuracy at step 46500: 0.9711452722549438.\n",
      "Starting epoch 716.\n",
      "\tTraining accuracy at step 46600: 0.9711529016494751.\n",
      "Starting epoch 717.\n",
      "Starting epoch 718.\n",
      "\tTraining accuracy at step 46700: 0.9711669087409973.\n",
      "Starting epoch 719.\n",
      "\tTraining accuracy at step 46800: 0.9711776971817017.\n",
      "Starting epoch 720.\n",
      "Starting epoch 721.\n",
      "\tTraining accuracy at step 46900: 0.9711883068084717.\n",
      "Starting epoch 722.\n",
      "Starting epoch 723.\n",
      "\tTraining accuracy at step 47000: 0.9711936116218567.\n",
      "Starting epoch 724.\n",
      "\tTraining accuracy at step 47100: 0.971194863319397.\n",
      "Starting epoch 725.\n",
      "Starting epoch 726.\n",
      "\tTraining accuracy at step 47200: 0.9711947441101074.\n",
      "Starting epoch 727.\n",
      "\tTraining accuracy at step 47300: 0.9712010622024536.\n",
      "Starting epoch 728.\n",
      "Starting epoch 729.\n",
      "\tTraining accuracy at step 47400: 0.9711981415748596.\n",
      "Starting epoch 730.\n",
      "\tTraining accuracy at step 47500: 0.9712072014808655.\n",
      "Starting epoch 731.\n",
      "Starting epoch 732.\n",
      "\tTraining accuracy at step 47600: 0.9712173938751221.\n",
      "Starting epoch 733.\n",
      "\tTraining accuracy at step 47700: 0.9712255001068115.\n",
      "Starting epoch 734.\n",
      "Starting epoch 735.\n",
      "\tTraining accuracy at step 47800: 0.9712278842926025.\n",
      "Starting epoch 736.\n",
      "\tTraining accuracy at step 47900: 0.9712294936180115.\n",
      "Starting epoch 737.\n",
      "Starting epoch 738.\n",
      "\tTraining accuracy at step 48000: 0.971238374710083.\n",
      "Starting epoch 739.\n",
      "\tTraining accuracy at step 48100: 0.9712531566619873.\n",
      "Starting epoch 740.\n",
      "Starting epoch 741.\n",
      "\tTraining accuracy at step 48200: 0.9712687730789185.\n",
      "Starting epoch 742.\n",
      "Starting epoch 743.\n",
      "\tTraining accuracy at step 48300: 0.9712834358215332.\n",
      "Starting epoch 744.\n",
      "\tTraining accuracy at step 48400: 0.9712850451469421.\n",
      "Starting epoch 745.\n",
      "Starting epoch 746.\n",
      "\tTraining accuracy at step 48500: 0.971286952495575.\n",
      "Starting epoch 747.\n",
      "\tTraining accuracy at step 48600: 0.9712897539138794.\n",
      "Starting epoch 748.\n",
      "Starting epoch 749.\n",
      "\tTraining accuracy at step 48700: 0.9712979793548584.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 750.\n",
      "\tTraining accuracy at step 48800: 0.971305251121521.\n",
      "Starting epoch 751.\n",
      "Starting epoch 752.\n",
      "\tTraining accuracy at step 48900: 0.9713190197944641.\n",
      "Starting epoch 753.\n",
      "\tTraining accuracy at step 49000: 0.9713354706764221.\n",
      "Starting epoch 754.\n",
      "Starting epoch 755.\n",
      "\tTraining accuracy at step 49100: 0.9713501930236816.\n",
      "Starting epoch 756.\n",
      "\tTraining accuracy at step 49200: 0.971363365650177.\n",
      "Starting epoch 757.\n",
      "Starting epoch 758.\n",
      "\tTraining accuracy at step 49300: 0.9713746905326843.\n",
      "Starting epoch 759.\n",
      "\tTraining accuracy at step 49400: 0.9713819026947021.\n",
      "Starting epoch 760.\n",
      "Starting epoch 761.\n",
      "\tTraining accuracy at step 49500: 0.9713847637176514.\n",
      "Starting epoch 762.\n",
      "Starting epoch 763.\n",
      "\tTraining accuracy at step 49600: 0.9713956713676453.\n",
      "Starting epoch 764.\n",
      "\tTraining accuracy at step 49700: 0.971400260925293.\n",
      "Starting epoch 765.\n",
      "Starting epoch 766.\n",
      "\tTraining accuracy at step 49800: 0.9714086651802063.\n",
      "Starting epoch 767.\n",
      "\tTraining accuracy at step 49900: 0.9714165329933167.\n",
      "Starting epoch 768.\n",
      "Starting epoch 769.\n",
      "\tTraining accuracy at step 50000: 0.9714261889457703.\n",
      "Starting epoch 770.\n",
      "\tTraining accuracy at step 50100: 0.9714308381080627.\n",
      "Starting epoch 771.\n",
      "Starting epoch 772.\n",
      "\tTraining accuracy at step 50200: 0.9714399576187134.\n",
      "Starting epoch 773.\n",
      "\tTraining accuracy at step 50300: 0.9714519381523132.\n",
      "Starting epoch 774.\n",
      "Starting epoch 775.\n",
      "\tTraining accuracy at step 50400: 0.9714569449424744.\n",
      "Starting epoch 776.\n",
      "\tTraining accuracy at step 50500: 0.971461296081543.\n",
      "Starting epoch 777.\n",
      "Starting epoch 778.\n",
      "\tTraining accuracy at step 50600: 0.9714613556861877.\n",
      "Starting epoch 779.\n",
      "\tTraining accuracy at step 50700: 0.9714686274528503.\n",
      "Starting epoch 780.\n",
      "Starting epoch 781.\n",
      "\tTraining accuracy at step 50800: 0.9714807271957397.\n",
      "Starting epoch 782.\n",
      "Starting epoch 783.\n",
      "\tTraining accuracy at step 50900: 0.9714929461479187.\n",
      "Starting epoch 784.\n",
      "\tTraining accuracy at step 51000: 0.9715042114257812.\n",
      "Starting epoch 785.\n",
      "Starting epoch 786.\n",
      "\tTraining accuracy at step 51100: 0.9715200066566467.\n",
      "Starting epoch 787.\n",
      "\tTraining accuracy at step 51200: 0.9715390205383301.\n",
      "Starting epoch 788.\n",
      "Starting epoch 789.\n",
      "\tTraining accuracy at step 51300: 0.9715479016304016.\n",
      "Starting epoch 790.\n",
      "\tTraining accuracy at step 51400: 0.9715632796287537.\n",
      "Starting epoch 791.\n",
      "Starting epoch 792.\n",
      "\tTraining accuracy at step 51500: 0.9715777039527893.\n",
      "Starting epoch 793.\n",
      "\tTraining accuracy at step 51600: 0.9715865850448608.\n",
      "Starting epoch 794.\n",
      "Starting epoch 795.\n",
      "\tTraining accuracy at step 51700: 0.9715949892997742.\n",
      "Starting epoch 796.\n",
      "\tTraining accuracy at step 51800: 0.971603512763977.\n",
      "Starting epoch 797.\n",
      "Starting epoch 798.\n",
      "\tTraining accuracy at step 51900: 0.9716079235076904.\n",
      "Starting epoch 799.\n",
      "\tTraining accuracy at step 52000: 0.9716155529022217.\n",
      "Starting epoch 800.\n",
      "Starting epoch 801.\n",
      "\tTraining accuracy at step 52100: 0.9716256856918335.\n",
      "Starting epoch 802.\n",
      "Starting epoch 803.\n",
      "\tTraining accuracy at step 52200: 0.9716425538063049.\n",
      "Starting epoch 804.\n",
      "\tTraining accuracy at step 52300: 0.9716581702232361.\n",
      "Starting epoch 805.\n",
      "Starting epoch 806.\n",
      "\tTraining accuracy at step 52400: 0.971670925617218.\n",
      "Starting epoch 807.\n",
      "\tTraining accuracy at step 52500: 0.9716851711273193.\n",
      "Starting epoch 808.\n",
      "Starting epoch 809.\n",
      "\tTraining accuracy at step 52600: 0.9716911911964417.\n",
      "Starting epoch 810.\n",
      "\tTraining accuracy at step 52700: 0.9716901183128357.\n",
      "Starting epoch 811.\n",
      "Starting epoch 812.\n",
      "\tTraining accuracy at step 52800: 0.9716964960098267.\n",
      "Starting epoch 813.\n",
      "\tTraining accuracy at step 52900: 0.9716963768005371.\n",
      "Starting epoch 814.\n",
      "Starting epoch 815.\n",
      "\tTraining accuracy at step 53000: 0.9717049598693848.\n",
      "Starting epoch 816.\n",
      "\tTraining accuracy at step 53100: 0.9717128872871399.\n",
      "Starting epoch 817.\n",
      "Starting epoch 818.\n",
      "\tTraining accuracy at step 53200: 0.9717196226119995.\n",
      "Starting epoch 819.\n",
      "\tTraining accuracy at step 53300: 0.9717240929603577.\n",
      "Starting epoch 820.\n",
      "Starting epoch 821.\n",
      "\tTraining accuracy at step 53400: 0.9717322587966919.\n",
      "Starting epoch 822.\n",
      "Starting epoch 823.\n",
      "\tTraining accuracy at step 53500: 0.9717379212379456.\n",
      "Starting epoch 824.\n",
      "\tTraining accuracy at step 53600: 0.9717563986778259.\n",
      "Starting epoch 825.\n",
      "Starting epoch 826.\n",
      "\tTraining accuracy at step 53700: 0.9717758297920227.\n",
      "Starting epoch 827.\n",
      "\tTraining accuracy at step 53800: 0.9717929363250732.\n",
      "Starting epoch 828.\n",
      "Starting epoch 829.\n",
      "\tTraining accuracy at step 53900: 0.9718009233474731.\n",
      "Starting epoch 830.\n",
      "\tTraining accuracy at step 54000: 0.9718111157417297.\n",
      "Starting epoch 831.\n",
      "Starting epoch 832.\n",
      "\tTraining accuracy at step 54100: 0.9718217253684998.\n",
      "Starting epoch 833.\n",
      "\tTraining accuracy at step 54200: 0.971831738948822.\n",
      "Starting epoch 834.\n",
      "Starting epoch 835.\n",
      "\tTraining accuracy at step 54300: 0.9718409180641174.\n",
      "Starting epoch 836.\n",
      "\tTraining accuracy at step 54400: 0.9718591570854187.\n",
      "Starting epoch 837.\n",
      "Starting epoch 838.\n",
      "\tTraining accuracy at step 54500: 0.9718737602233887.\n",
      "Starting epoch 839.\n",
      "\tTraining accuracy at step 54600: 0.9718853235244751.\n",
      "Starting epoch 840.\n",
      "Starting epoch 841.\n",
      "\tTraining accuracy at step 54700: 0.9718909859657288.\n",
      "Starting epoch 842.\n",
      "Starting epoch 843.\n",
      "\tTraining accuracy at step 54800: 0.9718990325927734.\n",
      "Starting epoch 844.\n",
      "\tTraining accuracy at step 54900: 0.9719058871269226.\n",
      "Starting epoch 845.\n",
      "Starting epoch 846.\n",
      "\tTraining accuracy at step 55000: 0.9719129204750061.\n",
      "Starting epoch 847.\n",
      "\tTraining accuracy at step 55100: 0.9719186425209045.\n",
      "Starting epoch 848.\n",
      "Starting epoch 849.\n",
      "\tTraining accuracy at step 55200: 0.9719234108924866.\n",
      "Starting epoch 850.\n",
      "\tTraining accuracy at step 55300: 0.9719341397285461.\n",
      "Starting epoch 851.\n",
      "Starting epoch 852.\n",
      "\tTraining accuracy at step 55400: 0.9719380736351013.\n",
      "Starting epoch 853.\n",
      "\tTraining accuracy at step 55500: 0.9719423651695251.\n",
      "Starting epoch 854.\n",
      "Starting epoch 855.\n",
      "\tTraining accuracy at step 55600: 0.9719512462615967.\n",
      "Starting epoch 856.\n",
      "\tTraining accuracy at step 55700: 0.9719601273536682.\n",
      "Starting epoch 857.\n",
      "Starting epoch 858.\n",
      "\tTraining accuracy at step 55800: 0.9719676375389099.\n",
      "Starting epoch 859.\n",
      "\tTraining accuracy at step 55900: 0.9719719886779785.\n",
      "Starting epoch 860.\n",
      "Starting epoch 861.\n",
      "\tTraining accuracy at step 56000: 0.9719792008399963.\n",
      "Starting epoch 862.\n",
      "Starting epoch 863.\n",
      "\tTraining accuracy at step 56100: 0.9719873070716858.\n",
      "Starting epoch 864.\n",
      "\tTraining accuracy at step 56200: 0.9719926118850708.\n",
      "Starting epoch 865.\n",
      "Starting epoch 866.\n",
      "\tTraining accuracy at step 56300: 0.971992015838623.\n",
      "Starting epoch 867.\n",
      "\tTraining accuracy at step 56400: 0.9719988703727722.\n",
      "Starting epoch 868.\n",
      "Starting epoch 869.\n",
      "\tTraining accuracy at step 56500: 0.9720102548599243.\n",
      "Starting epoch 870.\n",
      "\tTraining accuracy at step 56600: 0.9720211625099182.\n",
      "Starting epoch 871.\n",
      "Starting epoch 872.\n",
      "\tTraining accuracy at step 56700: 0.9720330834388733.\n",
      "Starting epoch 873.\n",
      "\tTraining accuracy at step 56800: 0.972041130065918.\n",
      "Starting epoch 874.\n",
      "Starting epoch 875.\n",
      "\tTraining accuracy at step 56900: 0.9720457792282104.\n",
      "Starting epoch 876.\n",
      "\tTraining accuracy at step 57000: 0.9720532298088074.\n",
      "Starting epoch 877.\n",
      "Starting epoch 878.\n",
      "\tTraining accuracy at step 57100: 0.9720604419708252.\n",
      "Starting epoch 879.\n",
      "\tTraining accuracy at step 57200: 0.9720709323883057.\n",
      "Starting epoch 880.\n",
      "Starting epoch 881.\n",
      "\tTraining accuracy at step 57300: 0.9720780253410339.\n",
      "Starting epoch 882.\n",
      "Starting epoch 883.\n",
      "\tTraining accuracy at step 57400: 0.972089946269989.\n",
      "Starting epoch 884.\n",
      "\tTraining accuracy at step 57500: 0.9720985889434814.\n",
      "Starting epoch 885.\n",
      "Starting epoch 886.\n",
      "\tTraining accuracy at step 57600: 0.9721067547798157.\n",
      "Starting epoch 887.\n",
      "\tTraining accuracy at step 57700: 0.972120463848114.\n",
      "Starting epoch 888.\n",
      "Starting epoch 889.\n",
      "\tTraining accuracy at step 57800: 0.972133994102478.\n",
      "Starting epoch 890.\n",
      "\tTraining accuracy at step 57900: 0.972137451171875.\n",
      "Starting epoch 891.\n",
      "Starting epoch 892.\n",
      "\tTraining accuracy at step 58000: 0.9721370935440063.\n",
      "Starting epoch 893.\n",
      "\tTraining accuracy at step 58100: 0.9721471071243286.\n",
      "Starting epoch 894.\n",
      "Starting epoch 895.\n",
      "\tTraining accuracy at step 58200: 0.9721553921699524.\n",
      "Starting epoch 896.\n",
      "\tTraining accuracy at step 58300: 0.9721603989601135.\n",
      "Starting epoch 897.\n",
      "Starting epoch 898.\n",
      "\tTraining accuracy at step 58400: 0.9721618294715881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 899.\n",
      "\tTraining accuracy at step 58500: 0.9721707701683044.\n",
      "Starting epoch 900.\n",
      "Starting epoch 901.\n",
      "\tTraining accuracy at step 58600: 0.9721766114234924.\n",
      "Starting epoch 902.\n",
      "Starting epoch 903.\n",
      "\tTraining accuracy at step 58700: 0.9721810221672058.\n",
      "Starting epoch 904.\n",
      "\tTraining accuracy at step 58800: 0.9721927642822266.\n",
      "Starting epoch 905.\n",
      "Starting epoch 906.\n",
      "\tTraining accuracy at step 58900: 0.9721965193748474.\n",
      "Starting epoch 907.\n",
      "\tTraining accuracy at step 59000: 0.9722025990486145.\n",
      "Starting epoch 908.\n",
      "Starting epoch 909.\n",
      "\tTraining accuracy at step 59100: 0.9722132086753845.\n",
      "Starting epoch 910.\n",
      "\tTraining accuracy at step 59200: 0.9722165465354919.\n",
      "Starting epoch 911.\n",
      "Starting epoch 912.\n",
      "\tTraining accuracy at step 59300: 0.9722224473953247.\n",
      "Starting epoch 913.\n",
      "\tTraining accuracy at step 59400: 0.9722324013710022.\n",
      "Starting epoch 914.\n",
      "Starting epoch 915.\n",
      "\tTraining accuracy at step 59500: 0.9722415804862976.\n",
      "Starting epoch 916.\n",
      "\tTraining accuracy at step 59600: 0.9722461700439453.\n",
      "Starting epoch 917.\n",
      "Starting epoch 918.\n",
      "\tTraining accuracy at step 59700: 0.97225421667099.\n",
      "Starting epoch 919.\n",
      "\tTraining accuracy at step 59800: 0.9722602367401123.\n",
      "Starting epoch 920.\n",
      "Starting epoch 921.\n",
      "\tTraining accuracy at step 59900: 0.9722673296928406.\n",
      "Starting epoch 922.\n",
      "Starting epoch 923.\n",
      "\tTraining accuracy at step 60000: 0.9722744226455688.\n",
      "Starting epoch 924.\n",
      "\tTraining accuracy at step 60100: 0.9722779989242554.\n",
      "Starting epoch 925.\n",
      "Starting epoch 926.\n",
      "\tTraining accuracy at step 60200: 0.9722822308540344.\n",
      "Starting epoch 927.\n",
      "\tTraining accuracy at step 60300: 0.9722834825515747.\n",
      "Starting epoch 928.\n",
      "Starting epoch 929.\n",
      "\tTraining accuracy at step 60400: 0.972281813621521.\n",
      "Starting epoch 930.\n",
      "\tTraining accuracy at step 60500: 0.9722861647605896.\n",
      "Starting epoch 931.\n",
      "Starting epoch 932.\n",
      "\tTraining accuracy at step 60600: 0.9722852110862732.\n",
      "Starting epoch 933.\n",
      "\tTraining accuracy at step 60700: 0.9722880721092224.\n",
      "Starting epoch 934.\n",
      "Starting epoch 935.\n",
      "\tTraining accuracy at step 60800: 0.9722884297370911.\n",
      "Starting epoch 936.\n",
      "\tTraining accuracy at step 60900: 0.9722903966903687.\n",
      "Starting epoch 937.\n",
      "Starting epoch 938.\n",
      "\tTraining accuracy at step 61000: 0.9722912311553955.\n",
      "Starting epoch 939.\n",
      "\tTraining accuracy at step 61100: 0.9722915887832642.\n",
      "Starting epoch 940.\n",
      "Starting epoch 941.\n",
      "\tTraining accuracy at step 61200: 0.9722949266433716.\n",
      "Starting epoch 942.\n",
      "Starting epoch 943.\n",
      "\tTraining accuracy at step 61300: 0.9723063111305237.\n",
      "Starting epoch 944.\n",
      "\tTraining accuracy at step 61400: 0.972313404083252.\n",
      "Starting epoch 945.\n",
      "Starting epoch 946.\n",
      "\tTraining accuracy at step 61500: 0.9723191857337952.\n",
      "Starting epoch 947.\n",
      "\tTraining accuracy at step 61600: 0.9723185300827026.\n",
      "Starting epoch 948.\n",
      "Starting epoch 949.\n",
      "\tTraining accuracy at step 61700: 0.9723186492919922.\n",
      "Starting epoch 950.\n",
      "\tTraining accuracy at step 61800: 0.9723213911056519.\n",
      "Starting epoch 951.\n",
      "Starting epoch 952.\n",
      "\tTraining accuracy at step 61900: 0.9723201990127563.\n",
      "Starting epoch 953.\n",
      "\tTraining accuracy at step 62000: 0.9723248481750488.\n",
      "Starting epoch 954.\n",
      "Starting epoch 955.\n",
      "\tTraining accuracy at step 62100: 0.9723266959190369.\n",
      "Starting epoch 956.\n",
      "\tTraining accuracy at step 62200: 0.9723271727561951.\n",
      "Starting epoch 957.\n",
      "Starting epoch 958.\n",
      "\tTraining accuracy at step 62300: 0.9723286628723145.\n",
      "Starting epoch 959.\n",
      "\tTraining accuracy at step 62400: 0.9723305702209473.\n",
      "Starting epoch 960.\n",
      "Starting epoch 961.\n",
      "\tTraining accuracy at step 62500: 0.9723359942436218.\n",
      "Starting epoch 962.\n",
      "Starting epoch 963.\n",
      "\tTraining accuracy at step 62600: 0.9723437428474426.\n",
      "Starting epoch 964.\n",
      "\tTraining accuracy at step 62700: 0.9723527431488037.\n",
      "Starting epoch 965.\n",
      "Starting epoch 966.\n",
      "\tTraining accuracy at step 62800: 0.9723554253578186.\n",
      "Starting epoch 967.\n",
      "\tTraining accuracy at step 62900: 0.9723594784736633.\n",
      "Starting epoch 968.\n",
      "Starting epoch 969.\n",
      "\tTraining accuracy at step 63000: 0.9723589420318604.\n",
      "Starting epoch 970.\n",
      "\tTraining accuracy at step 63100: 0.9723573327064514.\n",
      "Starting epoch 971.\n",
      "Starting epoch 972.\n",
      "\tTraining accuracy at step 63200: 0.972355842590332.\n",
      "Starting epoch 973.\n",
      "\tTraining accuracy at step 63300: 0.9723587036132812.\n",
      "Starting epoch 974.\n",
      "Starting epoch 975.\n",
      "\tTraining accuracy at step 63400: 0.9723660945892334.\n",
      "Starting epoch 976.\n",
      "\tTraining accuracy at step 63500: 0.9723713397979736.\n",
      "Starting epoch 977.\n",
      "Starting epoch 978.\n",
      "\tTraining accuracy at step 63600: 0.9723790287971497.\n",
      "Starting epoch 979.\n",
      "\tTraining accuracy at step 63700: 0.972384512424469.\n",
      "Starting epoch 980.\n",
      "Starting epoch 981.\n",
      "\tTraining accuracy at step 63800: 0.9723823070526123.\n",
      "Starting epoch 982.\n",
      "Starting epoch 983.\n",
      "\tTraining accuracy at step 63900: 0.9723886847496033.\n",
      "Starting epoch 984.\n",
      "\tTraining accuracy at step 64000: 0.9723917245864868.\n",
      "Starting epoch 985.\n",
      "Starting epoch 986.\n",
      "\tTraining accuracy at step 64100: 0.9723991751670837.\n",
      "Starting epoch 987.\n",
      "\tTraining accuracy at step 64200: 0.9724006056785583.\n",
      "Starting epoch 988.\n",
      "Starting epoch 989.\n",
      "\tTraining accuracy at step 64300: 0.9724026918411255.\n",
      "Starting epoch 990.\n",
      "\tTraining accuracy at step 64400: 0.9724057912826538.\n",
      "Starting epoch 991.\n",
      "Starting epoch 992.\n",
      "\tTraining accuracy at step 64500: 0.9724118113517761.\n",
      "Starting epoch 993.\n",
      "\tTraining accuracy at step 64600: 0.9724155068397522.\n",
      "Starting epoch 994.\n",
      "Starting epoch 995.\n",
      "\tTraining accuracy at step 64700: 0.9724162817001343.\n",
      "Starting epoch 996.\n",
      "\tTraining accuracy at step 64800: 0.9724220633506775.\n",
      "Starting epoch 997.\n",
      "Starting epoch 998.\n",
      "\tTraining accuracy at step 64900: 0.9724298715591431.\n",
      "Starting epoch 999.\n",
      "\tTraining accuracy at step 65000: 0.9724358320236206.\n",
      "Starting epoch 1000.\n",
      "Starting epoch 1001.\n",
      "\tTraining accuracy at step 65100: 0.9724422097206116.\n",
      "Starting epoch 1002.\n",
      "Starting epoch 1003.\n",
      "\tTraining accuracy at step 65200: 0.9724481105804443.\n",
      "Starting epoch 1004.\n",
      "\tTraining accuracy at step 65300: 0.9724549055099487.\n",
      "Starting epoch 1005.\n",
      "Starting epoch 1006.\n",
      "\tTraining accuracy at step 65400: 0.972460925579071.\n",
      "Starting epoch 1007.\n",
      "\tTraining accuracy at step 65500: 0.972470223903656.\n",
      "Starting epoch 1008.\n",
      "Starting epoch 1009.\n",
      "\tTraining accuracy at step 65600: 0.9724811911582947.\n",
      "Starting epoch 1010.\n",
      "\tTraining accuracy at step 65700: 0.9724888801574707.\n",
      "Starting epoch 1011.\n",
      "Starting epoch 1012.\n",
      "\tTraining accuracy at step 65800: 0.9724991321563721.\n",
      "Starting epoch 1013.\n",
      "\tTraining accuracy at step 65900: 0.9725075364112854.\n",
      "Starting epoch 1014.\n",
      "Starting epoch 1015.\n",
      "\tTraining accuracy at step 66000: 0.9725159406661987.\n",
      "Starting epoch 1016.\n",
      "\tTraining accuracy at step 66100: 0.9725255370140076.\n",
      "Starting epoch 1017.\n",
      "Starting epoch 1018.\n",
      "\tTraining accuracy at step 66200: 0.9725319743156433.\n",
      "Starting epoch 1019.\n",
      "\tTraining accuracy at step 66300: 0.9725274443626404.\n",
      "Starting epoch 1020.\n",
      "Starting epoch 1021.\n",
      "\tTraining accuracy at step 66400: 0.9725234508514404.\n",
      "Starting epoch 1022.\n",
      "Starting epoch 1023.\n",
      "\tTraining accuracy at step 66500: 0.9725252985954285.\n",
      "Starting epoch 1024.\n",
      "\tTraining accuracy at step 66600: 0.9725267291069031.\n",
      "Starting epoch 1025.\n",
      "Starting epoch 1026.\n",
      "\tTraining accuracy at step 66700: 0.9725296497344971.\n",
      "Starting epoch 1027.\n",
      "\tTraining accuracy at step 66800: 0.9725340008735657.\n",
      "Starting epoch 1028.\n",
      "Starting epoch 1029.\n",
      "\tTraining accuracy at step 66900: 0.9725381731987.\n",
      "Starting epoch 1030.\n",
      "\tTraining accuracy at step 67000: 0.9725427031517029.\n",
      "Starting epoch 1031.\n",
      "Starting epoch 1032.\n",
      "\tTraining accuracy at step 67100: 0.9725501537322998.\n",
      "Starting epoch 1033.\n",
      "\tTraining accuracy at step 67200: 0.9725545644760132.\n",
      "Starting epoch 1034.\n",
      "Starting epoch 1035.\n",
      "\tTraining accuracy at step 67300: 0.9725589752197266.\n",
      "Starting epoch 1036.\n",
      "\tTraining accuracy at step 67400: 0.9725669622421265.\n",
      "Starting epoch 1037.\n",
      "Starting epoch 1038.\n",
      "\tTraining accuracy at step 67500: 0.9725670218467712.\n",
      "Starting epoch 1039.\n",
      "\tTraining accuracy at step 67600: 0.9725689888000488.\n",
      "Starting epoch 1040.\n",
      "Starting epoch 1041.\n",
      "\tTraining accuracy at step 67700: 0.9725679159164429.\n",
      "Starting epoch 1042.\n",
      "Starting epoch 1043.\n",
      "\tTraining accuracy at step 67800: 0.9725745916366577.\n",
      "Starting epoch 1044.\n",
      "\tTraining accuracy at step 67900: 0.9725784063339233.\n",
      "Starting epoch 1045.\n",
      "Starting epoch 1046.\n",
      "\tTraining accuracy at step 68000: 0.9725819230079651.\n",
      "Starting epoch 1047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining accuracy at step 68100: 0.9725875854492188.\n",
      "Starting epoch 1048.\n",
      "Starting epoch 1049.\n",
      "\tTraining accuracy at step 68200: 0.9725902676582336.\n",
      "Starting epoch 1050.\n",
      "\tTraining accuracy at step 68300: 0.9725950360298157.\n",
      "Starting epoch 1051.\n",
      "Starting epoch 1052.\n",
      "\tTraining accuracy at step 68400: 0.9726039171218872.\n",
      "Starting epoch 1053.\n",
      "\tTraining accuracy at step 68500: 0.9726117253303528.\n",
      "Starting epoch 1054.\n",
      "Starting epoch 1055.\n",
      "\tTraining accuracy at step 68600: 0.9726219177246094.\n",
      "Starting epoch 1056.\n",
      "\tTraining accuracy at step 68700: 0.9726343750953674.\n",
      "Starting epoch 1057.\n",
      "Starting epoch 1058.\n",
      "\tTraining accuracy at step 68800: 0.9726423621177673.\n",
      "Starting epoch 1059.\n",
      "\tTraining accuracy at step 68900: 0.9726523160934448.\n",
      "Starting epoch 1060.\n",
      "Starting epoch 1061.\n",
      "\tTraining accuracy at step 69000: 0.9726572036743164.\n",
      "Starting epoch 1062.\n",
      "Starting epoch 1063.\n",
      "\tTraining accuracy at step 69100: 0.9726645946502686.\n",
      "Starting epoch 1064.\n",
      "\tTraining accuracy at step 69200: 0.9726731181144714.\n",
      "Starting epoch 1065.\n",
      "Starting epoch 1066.\n",
      "\tTraining accuracy at step 69300: 0.9726837277412415.\n",
      "Starting epoch 1067.\n",
      "\tTraining accuracy at step 69400: 0.9726916551589966.\n",
      "Starting epoch 1068.\n",
      "Starting epoch 1069.\n",
      "\tTraining accuracy at step 69500: 0.972686231136322.\n",
      "Starting epoch 1070.\n",
      "\tTraining accuracy at step 69600: 0.972688615322113.\n",
      "Starting epoch 1071.\n",
      "Starting epoch 1072.\n",
      "\tTraining accuracy at step 69700: 0.9726924300193787.\n",
      "Starting epoch 1073.\n",
      "\tTraining accuracy at step 69800: 0.9727005362510681.\n",
      "Starting epoch 1074.\n",
      "Starting epoch 1075.\n",
      "\tTraining accuracy at step 69900: 0.9727049469947815.\n",
      "Starting epoch 1076.\n",
      "\tTraining accuracy at step 70000: 0.9727075695991516.\n",
      "Starting epoch 1077.\n",
      "Starting epoch 1078.\n",
      "\tTraining accuracy at step 70100: 0.9727086424827576.\n",
      "Starting epoch 1079.\n",
      "\tTraining accuracy at step 70200: 0.9727151393890381.\n",
      "Starting epoch 1080.\n",
      "Starting epoch 1081.\n",
      "\tTraining accuracy at step 70300: 0.9727253317832947.\n",
      "Starting epoch 1082.\n",
      "Starting epoch 1083.\n",
      "\tTraining accuracy at step 70400: 0.9727336168289185.\n",
      "Starting epoch 1084.\n",
      "\tTraining accuracy at step 70500: 0.9727358818054199.\n",
      "Starting epoch 1085.\n",
      "Starting epoch 1086.\n",
      "\tTraining accuracy at step 70600: 0.9727349281311035.\n",
      "Starting epoch 1087.\n",
      "\tTraining accuracy at step 70700: 0.9727311134338379.\n",
      "Starting epoch 1088.\n",
      "Starting epoch 1089.\n",
      "\tTraining accuracy at step 70800: 0.9727301001548767.\n",
      "Starting epoch 1090.\n",
      "\tTraining accuracy at step 70900: 0.9727325439453125.\n",
      "Starting epoch 1091.\n",
      "Starting epoch 1092.\n",
      "\tTraining accuracy at step 71000: 0.972730815410614.\n",
      "Starting epoch 1093.\n",
      "\tTraining accuracy at step 71100: 0.9727312922477722.\n",
      "Starting epoch 1094.\n",
      "Starting epoch 1095.\n",
      "\tTraining accuracy at step 71200: 0.9727331399917603.\n",
      "Starting epoch 1096.\n",
      "\tTraining accuracy at step 71300: 0.9727368950843811.\n",
      "Starting epoch 1097.\n",
      "Starting epoch 1098.\n",
      "\tTraining accuracy at step 71400: 0.9727382063865662.\n",
      "Starting epoch 1099.\n",
      "\tTraining accuracy at step 71500: 0.9727416634559631.\n",
      "Starting epoch 1100.\n",
      "Starting epoch 1101.\n",
      "\tTraining accuracy at step 71600: 0.9727488160133362.\n",
      "Starting epoch 1102.\n",
      "Starting epoch 1103.\n",
      "\tTraining accuracy at step 71700: 0.9727534651756287.\n",
      "Starting epoch 1104.\n",
      "\tTraining accuracy at step 71800: 0.9727499485015869.\n",
      "Starting epoch 1105.\n",
      "Starting epoch 1106.\n",
      "\tTraining accuracy at step 71900: 0.9727485179901123.\n",
      "Starting epoch 1107.\n",
      "\tTraining accuracy at step 72000: 0.9727504253387451.\n",
      "Starting epoch 1108.\n",
      "Starting epoch 1109.\n",
      "\tTraining accuracy at step 72100: 0.9727522730827332.\n",
      "Starting epoch 1110.\n",
      "\tTraining accuracy at step 72200: 0.9727523922920227.\n",
      "Starting epoch 1111.\n",
      "Starting epoch 1112.\n",
      "\tTraining accuracy at step 72300: 0.9727485775947571.\n",
      "Starting epoch 1113.\n",
      "\tTraining accuracy at step 72400: 0.9727498888969421.\n",
      "Starting epoch 1114.\n",
      "Starting epoch 1115.\n",
      "\tTraining accuracy at step 72500: 0.9727540612220764.\n",
      "Starting epoch 1116.\n",
      "\tTraining accuracy at step 72600: 0.972756028175354.\n",
      "Starting epoch 1117.\n",
      "Starting epoch 1118.\n",
      "\tTraining accuracy at step 72700: 0.9727582335472107.\n",
      "Starting epoch 1119.\n",
      "\tTraining accuracy at step 72800: 0.9727609753608704.\n",
      "Starting epoch 1120.\n",
      "Starting epoch 1121.\n",
      "\tTraining accuracy at step 72900: 0.9727654457092285.\n",
      "Starting epoch 1122.\n",
      "Starting epoch 1123.\n",
      "\tTraining accuracy at step 73000: 0.9727715849876404.\n",
      "Starting epoch 1124.\n",
      "\tTraining accuracy at step 73100: 0.9727780818939209.\n",
      "Starting epoch 1125.\n",
      "Starting epoch 1126.\n",
      "\tTraining accuracy at step 73200: 0.9727858304977417.\n",
      "Starting epoch 1127.\n",
      "\tTraining accuracy at step 73300: 0.9727914929389954.\n",
      "Starting epoch 1128.\n",
      "Starting epoch 1129.\n",
      "\tTraining accuracy at step 73400: 0.9727962017059326.\n",
      "Starting epoch 1130.\n",
      "\tTraining accuracy at step 73500: 0.9728004336357117.\n",
      "Starting epoch 1131.\n",
      "Starting epoch 1132.\n",
      "\tTraining accuracy at step 73600: 0.9728055000305176.\n",
      "Starting epoch 1133.\n",
      "\tTraining accuracy at step 73700: 0.9728137254714966.\n",
      "Starting epoch 1134.\n",
      "Starting epoch 1135.\n",
      "\tTraining accuracy at step 73800: 0.9728197455406189.\n",
      "Starting epoch 1136.\n",
      "\tTraining accuracy at step 73900: 0.9728232622146606.\n",
      "Starting epoch 1137.\n",
      "Starting epoch 1138.\n",
      "\tTraining accuracy at step 74000: 0.9728237390518188.\n",
      "Starting epoch 1139.\n",
      "\tTraining accuracy at step 74100: 0.9728278517723083.\n",
      "Starting epoch 1140.\n",
      "Starting epoch 1141.\n",
      "\tTraining accuracy at step 74200: 0.9728325009346008.\n",
      "Starting epoch 1142.\n",
      "Starting epoch 1143.\n",
      "\tTraining accuracy at step 74300: 0.972838819026947.\n",
      "Starting epoch 1144.\n",
      "\tTraining accuracy at step 74400: 0.9728400707244873.\n",
      "Starting epoch 1145.\n",
      "Starting epoch 1146.\n",
      "\tTraining accuracy at step 74500: 0.9728460907936096.\n",
      "Starting epoch 1147.\n",
      "\tTraining accuracy at step 74600: 0.9728533625602722.\n",
      "Starting epoch 1148.\n",
      "Starting epoch 1149.\n",
      "\tTraining accuracy at step 74700: 0.9728617072105408.\n",
      "Starting epoch 1150.\n",
      "\tTraining accuracy at step 74800: 0.9728719592094421.\n",
      "Starting epoch 1151.\n",
      "Starting epoch 1152.\n",
      "\tTraining accuracy at step 74900: 0.9728792309761047.\n",
      "Starting epoch 1153.\n",
      "\tTraining accuracy at step 75000: 0.9728882908821106.\n",
      "Starting epoch 1154.\n",
      "Starting epoch 1155.\n",
      "\tTraining accuracy at step 75100: 0.9728989601135254.\n",
      "Starting epoch 1156.\n",
      "\tTraining accuracy at step 75200: 0.9729076623916626.\n",
      "Starting epoch 1157.\n",
      "Starting epoch 1158.\n",
      "\tTraining accuracy at step 75300: 0.9729003310203552.\n",
      "Starting epoch 1159.\n",
      "\tTraining accuracy at step 75400: 0.972896158695221.\n",
      "Starting epoch 1160.\n",
      "Starting epoch 1161.\n",
      "\tTraining accuracy at step 75500: 0.9728987216949463.\n",
      "Starting epoch 1162.\n",
      "Starting epoch 1163.\n",
      "\tTraining accuracy at step 75600: 0.9729058146476746.\n",
      "Starting epoch 1164.\n",
      "\tTraining accuracy at step 75700: 0.9729097485542297.\n",
      "Starting epoch 1165.\n",
      "Starting epoch 1166.\n",
      "\tTraining accuracy at step 75800: 0.9729138016700745.\n",
      "Starting epoch 1167.\n",
      "\tTraining accuracy at step 75900: 0.9729174971580505.\n",
      "Starting epoch 1168.\n",
      "Starting epoch 1169.\n",
      "\tTraining accuracy at step 76000: 0.9729210138320923.\n",
      "Starting epoch 1170.\n",
      "\tTraining accuracy at step 76100: 0.972926676273346.\n",
      "Starting epoch 1171.\n",
      "Starting epoch 1172.\n",
      "\tTraining accuracy at step 76200: 0.9729310274124146.\n",
      "Starting epoch 1173.\n",
      "\tTraining accuracy at step 76300: 0.9729357361793518.\n",
      "Starting epoch 1174.\n",
      "Starting epoch 1175.\n",
      "\tTraining accuracy at step 76400: 0.9729393124580383.\n",
      "Starting epoch 1176.\n",
      "\tTraining accuracy at step 76500: 0.9729428291320801.\n",
      "Starting epoch 1177.\n",
      "Starting epoch 1178.\n",
      "\tTraining accuracy at step 76600: 0.9729495048522949.\n",
      "Starting epoch 1179.\n",
      "\tTraining accuracy at step 76700: 0.97295081615448.\n",
      "Starting epoch 1180.\n",
      "Starting epoch 1181.\n",
      "\tTraining accuracy at step 76800: 0.9729578495025635.\n",
      "Starting epoch 1182.\n",
      "Starting epoch 1183.\n",
      "\tTraining accuracy at step 76900: 0.9729641675949097.\n",
      "Starting epoch 1184.\n",
      "\tTraining accuracy at step 77000: 0.9729692935943604.\n",
      "Starting epoch 1185.\n",
      "Starting epoch 1186.\n",
      "\tTraining accuracy at step 77100: 0.9729779362678528.\n",
      "Starting epoch 1187.\n",
      "\tTraining accuracy at step 77200: 0.9729794263839722.\n",
      "Starting epoch 1188.\n",
      "Starting epoch 1189.\n",
      "\tTraining accuracy at step 77300: 0.9729803204536438.\n",
      "Starting epoch 1190.\n",
      "\tTraining accuracy at step 77400: 0.9729835987091064.\n",
      "Starting epoch 1191.\n",
      "Starting epoch 1192.\n",
      "\tTraining accuracy at step 77500: 0.9729876518249512.\n",
      "Starting epoch 1193.\n",
      "\tTraining accuracy at step 77600: 0.9729970097541809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1194.\n",
      "Starting epoch 1195.\n",
      "\tTraining accuracy at step 77700: 0.9730038046836853.\n",
      "Starting epoch 1196.\n",
      "\tTraining accuracy at step 77800: 0.9730096459388733.\n",
      "Starting epoch 1197.\n",
      "Starting epoch 1198.\n",
      "\tTraining accuracy at step 77900: 0.973017156124115.\n",
      "Starting epoch 1199.\n",
      "\tTraining accuracy at step 78000: 0.9730197787284851.\n",
      "Starting epoch 1200.\n",
      "Starting epoch 1201.\n",
      "\tTraining accuracy at step 78100: 0.9730241298675537.\n",
      "Starting epoch 1202.\n",
      "Starting epoch 1203.\n",
      "\tTraining accuracy at step 78200: 0.9730269312858582.\n",
      "Starting epoch 1204.\n",
      "\tTraining accuracy at step 78300: 0.9730270504951477.\n",
      "Starting epoch 1205.\n",
      "Starting epoch 1206.\n",
      "\tTraining accuracy at step 78400: 0.9730269312858582.\n",
      "Starting epoch 1207.\n",
      "\tTraining accuracy at step 78500: 0.9730304479598999.\n",
      "Starting epoch 1208.\n",
      "Starting epoch 1209.\n",
      "\tTraining accuracy at step 78600: 0.973034143447876.\n",
      "Starting epoch 1210.\n",
      "\tTraining accuracy at step 78700: 0.9730373024940491.\n",
      "Starting epoch 1211.\n",
      "Starting epoch 1212.\n",
      "\tTraining accuracy at step 78800: 0.9730406999588013.\n",
      "Starting epoch 1213.\n",
      "\tTraining accuracy at step 78900: 0.9730476140975952.\n",
      "Starting epoch 1214.\n",
      "Starting epoch 1215.\n",
      "\tTraining accuracy at step 79000: 0.9730521440505981.\n",
      "Starting epoch 1216.\n",
      "\tTraining accuracy at step 79100: 0.9730566143989563.\n",
      "Starting epoch 1217.\n",
      "Starting epoch 1218.\n",
      "\tTraining accuracy at step 79200: 0.9730629324913025.\n",
      "Starting epoch 1219.\n",
      "\tTraining accuracy at step 79300: 0.9730672240257263.\n",
      "Starting epoch 1220.\n",
      "Starting epoch 1221.\n",
      "\tTraining accuracy at step 79400: 0.9730700850486755.\n",
      "Starting epoch 1222.\n",
      "Starting epoch 1223.\n",
      "\tTraining accuracy at step 79500: 0.9730737209320068.\n",
      "Starting epoch 1224.\n",
      "\tTraining accuracy at step 79600: 0.9730781316757202.\n",
      "Starting epoch 1225.\n",
      "Starting epoch 1226.\n",
      "\tTraining accuracy at step 79700: 0.9730847477912903.\n",
      "Starting epoch 1227.\n",
      "\tTraining accuracy at step 79800: 0.9730886816978455.\n",
      "Starting epoch 1228.\n",
      "Starting epoch 1229.\n",
      "\tTraining accuracy at step 79900: 0.9730886816978455.\n",
      "Starting epoch 1230.\n",
      "\tTraining accuracy at step 80000: 0.9730848670005798.\n",
      "Starting epoch 1231.\n",
      "Starting epoch 1232.\n",
      "\tTraining accuracy at step 80100: 0.973084568977356.\n",
      "Starting epoch 1233.\n",
      "\tTraining accuracy at step 80200: 0.9730861783027649.\n",
      "Starting epoch 1234.\n",
      "Starting epoch 1235.\n",
      "\tTraining accuracy at step 80300: 0.9730913639068604.\n",
      "Starting epoch 1236.\n",
      "\tTraining accuracy at step 80400: 0.9730948805809021.\n",
      "Starting epoch 1237.\n",
      "Starting epoch 1238.\n",
      "\tTraining accuracy at step 80500: 0.9730995893478394.\n",
      "Starting epoch 1239.\n",
      "\tTraining accuracy at step 80600: 0.9731045365333557.\n",
      "Starting epoch 1240.\n",
      "Starting epoch 1241.\n",
      "\tTraining accuracy at step 80700: 0.9731084108352661.\n",
      "Starting epoch 1242.\n",
      "Starting epoch 1243.\n",
      "\tTraining accuracy at step 80800: 0.9731128215789795.\n",
      "Starting epoch 1244.\n",
      "\tTraining accuracy at step 80900: 0.9731109738349915.\n",
      "Starting epoch 1245.\n",
      "Starting epoch 1246.\n",
      "\tTraining accuracy at step 81000: 0.9731062054634094.\n",
      "Starting epoch 1247.\n",
      "\tTraining accuracy at step 81100: 0.9731102585792542.\n",
      "Starting epoch 1248.\n",
      "Starting epoch 1249.\n",
      "\tTraining accuracy at step 81200: 0.9731137156486511.\n",
      "Starting epoch 1250.\n",
      "\tTraining accuracy at step 81300: 0.9731121063232422.\n",
      "Starting epoch 1251.\n",
      "Starting epoch 1252.\n",
      "\tTraining accuracy at step 81400: 0.9731103777885437.\n",
      "Starting epoch 1253.\n",
      "\tTraining accuracy at step 81500: 0.9731147885322571.\n",
      "Starting epoch 1254.\n",
      "Starting epoch 1255.\n",
      "\tTraining accuracy at step 81600: 0.9731189608573914.\n",
      "Starting epoch 1256.\n",
      "\tTraining accuracy at step 81700: 0.9731231331825256.\n",
      "Starting epoch 1257.\n",
      "Starting epoch 1258.\n",
      "\tTraining accuracy at step 81800: 0.9731274843215942.\n",
      "Starting epoch 1259.\n",
      "\tTraining accuracy at step 81900: 0.9731311798095703.\n",
      "Starting epoch 1260.\n",
      "Starting epoch 1261.\n",
      "\tTraining accuracy at step 82000: 0.9731352925300598.\n",
      "Starting epoch 1262.\n",
      "Starting epoch 1263.\n",
      "\tTraining accuracy at step 82100: 0.9731410145759583.\n",
      "Starting epoch 1264.\n",
      "\tTraining accuracy at step 82200: 0.9731417894363403.\n",
      "Starting epoch 1265.\n",
      "Starting epoch 1266.\n",
      "\tTraining accuracy at step 82300: 0.9731481075286865.\n",
      "Starting epoch 1267.\n",
      "\tTraining accuracy at step 82400: 0.9731470346450806.\n",
      "Starting epoch 1268.\n",
      "Starting epoch 1269.\n",
      "\tTraining accuracy at step 82500: 0.9731496572494507.\n",
      "Starting epoch 1270.\n",
      "\tTraining accuracy at step 82600: 0.9731540083885193.\n",
      "Starting epoch 1271.\n",
      "Starting epoch 1272.\n",
      "\tTraining accuracy at step 82700: 0.9731565713882446.\n",
      "Starting epoch 1273.\n",
      "\tTraining accuracy at step 82800: 0.9731584191322327.\n",
      "Starting epoch 1274.\n",
      "Starting epoch 1275.\n",
      "\tTraining accuracy at step 82900: 0.9731637239456177.\n",
      "Starting epoch 1276.\n",
      "\tTraining accuracy at step 83000: 0.9731698632240295.\n",
      "Starting epoch 1277.\n",
      "Starting epoch 1278.\n",
      "\tTraining accuracy at step 83100: 0.9731727242469788.\n",
      "Starting epoch 1279.\n",
      "\tTraining accuracy at step 83200: 0.9731773734092712.\n",
      "Starting epoch 1280.\n",
      "Starting epoch 1281.\n",
      "\tTraining accuracy at step 83300: 0.9731812477111816.\n",
      "Starting epoch 1282.\n",
      "Starting epoch 1283.\n",
      "\tTraining accuracy at step 83400: 0.9731886982917786.\n",
      "Starting epoch 1284.\n",
      "\tTraining accuracy at step 83500: 0.9731932282447815.\n",
      "Starting epoch 1285.\n",
      "Starting epoch 1286.\n",
      "\tTraining accuracy at step 83600: 0.9731940627098083.\n",
      "Starting epoch 1287.\n",
      "\tTraining accuracy at step 83700: 0.9731935262680054.\n",
      "Starting epoch 1288.\n",
      "Starting epoch 1289.\n",
      "\tTraining accuracy at step 83800: 0.9731972217559814.\n",
      "Starting epoch 1290.\n",
      "\tTraining accuracy at step 83900: 0.9731980562210083.\n",
      "Starting epoch 1291.\n",
      "Starting epoch 1292.\n",
      "\tTraining accuracy at step 84000: 0.9732004404067993.\n",
      "Starting epoch 1293.\n",
      "\tTraining accuracy at step 84100: 0.9732024669647217.\n",
      "Starting epoch 1294.\n",
      "Starting epoch 1295.\n",
      "\tTraining accuracy at step 84200: 0.9732046723365784.\n",
      "Starting epoch 1296.\n",
      "\tTraining accuracy at step 84300: 0.9732090830802917.\n",
      "Starting epoch 1297.\n",
      "Starting epoch 1298.\n",
      "\tTraining accuracy at step 84400: 0.97321617603302.\n",
      "Starting epoch 1299.\n",
      "\tTraining accuracy at step 84500: 0.9732199907302856.\n",
      "Starting epoch 1300.\n",
      "Starting epoch 1301.\n",
      "\tTraining accuracy at step 84600: 0.9732258915901184.\n",
      "Starting epoch 1302.\n",
      "Starting epoch 1303.\n",
      "\tTraining accuracy at step 84700: 0.9732334017753601.\n",
      "Starting epoch 1304.\n",
      "\tTraining accuracy at step 84800: 0.973242461681366.\n",
      "Starting epoch 1305.\n",
      "Starting epoch 1306.\n",
      "\tTraining accuracy at step 84900: 0.9732500910758972.\n",
      "Starting epoch 1307.\n",
      "\tTraining accuracy at step 85000: 0.9732517004013062.\n",
      "Starting epoch 1308.\n",
      "Starting epoch 1309.\n",
      "\tTraining accuracy at step 85100: 0.9732525944709778.\n",
      "Starting epoch 1310.\n",
      "\tTraining accuracy at step 85200: 0.9732563495635986.\n",
      "Starting epoch 1311.\n",
      "Starting epoch 1312.\n",
      "\tTraining accuracy at step 85300: 0.9732599258422852.\n",
      "Starting epoch 1313.\n",
      "\tTraining accuracy at step 85400: 0.9732625484466553.\n",
      "Starting epoch 1314.\n",
      "Starting epoch 1315.\n",
      "\tTraining accuracy at step 85500: 0.9732663035392761.\n",
      "Starting epoch 1316.\n",
      "\tTraining accuracy at step 85600: 0.9732702374458313.\n",
      "Starting epoch 1317.\n",
      "Starting epoch 1318.\n",
      "\tTraining accuracy at step 85700: 0.9732773900032043.\n",
      "Starting epoch 1319.\n",
      "\tTraining accuracy at step 85800: 0.9732849597930908.\n",
      "Starting epoch 1320.\n",
      "Starting epoch 1321.\n",
      "\tTraining accuracy at step 85900: 0.9732900857925415.\n",
      "Starting epoch 1322.\n",
      "Starting epoch 1323.\n",
      "\tTraining accuracy at step 86000: 0.9732966423034668.\n",
      "Starting epoch 1324.\n",
      "\tTraining accuracy at step 86100: 0.9733031392097473.\n",
      "Starting epoch 1325.\n",
      "Starting epoch 1326.\n",
      "\tTraining accuracy at step 86200: 0.9733110070228577.\n",
      "Starting epoch 1327.\n",
      "\tTraining accuracy at step 86300: 0.9733173847198486.\n",
      "Starting epoch 1328.\n",
      "Starting epoch 1329.\n",
      "\tTraining accuracy at step 86400: 0.9733215570449829.\n",
      "Starting epoch 1330.\n",
      "\tTraining accuracy at step 86500: 0.9733273386955261.\n",
      "Starting epoch 1331.\n",
      "Starting epoch 1332.\n",
      "\tTraining accuracy at step 86600: 0.9733367562294006.\n",
      "Starting epoch 1333.\n",
      "\tTraining accuracy at step 86700: 0.973342776298523.\n",
      "Starting epoch 1334.\n",
      "Starting epoch 1335.\n",
      "\tTraining accuracy at step 86800: 0.9733511805534363.\n",
      "Starting epoch 1336.\n",
      "\tTraining accuracy at step 86900: 0.9733548760414124.\n",
      "Starting epoch 1337.\n",
      "Starting epoch 1338.\n",
      "\tTraining accuracy at step 87000: 0.9733597040176392.\n",
      "Starting epoch 1339.\n",
      "\tTraining accuracy at step 87100: 0.9733657836914062.\n",
      "Starting epoch 1340.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1341.\n",
      "\tTraining accuracy at step 87200: 0.9733725786209106.\n",
      "Starting epoch 1342.\n",
      "Starting epoch 1343.\n",
      "\tTraining accuracy at step 87300: 0.9733818173408508.\n",
      "Starting epoch 1344.\n",
      "\tTraining accuracy at step 87400: 0.9733880758285522.\n",
      "Starting epoch 1345.\n",
      "Starting epoch 1346.\n",
      "\tTraining accuracy at step 87500: 0.973391592502594.\n",
      "Starting epoch 1347.\n",
      "\tTraining accuracy at step 87600: 0.9733980894088745.\n",
      "Starting epoch 1348.\n",
      "Starting epoch 1349.\n",
      "\tTraining accuracy at step 87700: 0.9734019041061401.\n",
      "Starting epoch 1350.\n",
      "\tTraining accuracy at step 87800: 0.9734077453613281.\n",
      "Starting epoch 1351.\n",
      "Starting epoch 1352.\n",
      "\tTraining accuracy at step 87900: 0.9734084010124207.\n",
      "Starting epoch 1353.\n",
      "\tTraining accuracy at step 88000: 0.9734150767326355.\n",
      "Starting epoch 1354.\n",
      "Starting epoch 1355.\n",
      "\tTraining accuracy at step 88100: 0.9734230637550354.\n",
      "Starting epoch 1356.\n",
      "\tTraining accuracy at step 88200: 0.9734280705451965.\n",
      "Starting epoch 1357.\n",
      "Starting epoch 1358.\n",
      "\tTraining accuracy at step 88300: 0.973435640335083.\n",
      "Starting epoch 1359.\n",
      "\tTraining accuracy at step 88400: 0.9734402894973755.\n",
      "Starting epoch 1360.\n",
      "Starting epoch 1361.\n",
      "\tTraining accuracy at step 88500: 0.9734469056129456.\n",
      "Starting epoch 1362.\n",
      "Starting epoch 1363.\n",
      "\tTraining accuracy at step 88600: 0.9734529852867126.\n",
      "Starting epoch 1364.\n",
      "\tTraining accuracy at step 88700: 0.9734564423561096.\n",
      "Starting epoch 1365.\n",
      "Starting epoch 1366.\n",
      "\tTraining accuracy at step 88800: 0.9734616875648499.\n",
      "Starting epoch 1367.\n",
      "\tTraining accuracy at step 88900: 0.9734673500061035.\n",
      "Starting epoch 1368.\n",
      "Starting epoch 1369.\n",
      "\tTraining accuracy at step 89000: 0.9734723567962646.\n",
      "Starting epoch 1370.\n",
      "\tTraining accuracy at step 89100: 0.9734798073768616.\n",
      "Starting epoch 1371.\n",
      "Starting epoch 1372.\n",
      "\tTraining accuracy at step 89200: 0.9734870195388794.\n",
      "Starting epoch 1373.\n",
      "\tTraining accuracy at step 89300: 0.9734908938407898.\n",
      "Starting epoch 1374.\n",
      "Starting epoch 1375.\n",
      "\tTraining accuracy at step 89400: 0.973490297794342.\n",
      "Starting epoch 1376.\n",
      "\tTraining accuracy at step 89500: 0.9734965562820435.\n",
      "Starting epoch 1377.\n",
      "Starting epoch 1378.\n",
      "\tTraining accuracy at step 89600: 0.9735038876533508.\n",
      "Starting epoch 1379.\n",
      "\tTraining accuracy at step 89700: 0.973505973815918.\n",
      "Starting epoch 1380.\n",
      "Starting epoch 1381.\n",
      "\tTraining accuracy at step 89800: 0.973504364490509.\n",
      "Starting epoch 1382.\n",
      "Starting epoch 1383.\n",
      "\tTraining accuracy at step 89900: 0.9735069870948792.\n",
      "Starting epoch 1384.\n",
      "\tTraining accuracy at step 90000: 0.9735113978385925.\n",
      "Starting epoch 1385.\n",
      "Starting epoch 1386.\n",
      "\tTraining accuracy at step 90100: 0.9735164642333984.\n",
      "Starting epoch 1387.\n",
      "\tTraining accuracy at step 90200: 0.9735214710235596.\n",
      "Starting epoch 1388.\n",
      "Starting epoch 1389.\n",
      "\tTraining accuracy at step 90300: 0.9735275506973267.\n",
      "Starting epoch 1390.\n",
      "\tTraining accuracy at step 90400: 0.9735337495803833.\n",
      "Starting epoch 1391.\n",
      "Starting epoch 1392.\n",
      "\tTraining accuracy at step 90500: 0.9735390543937683.\n",
      "Starting epoch 1393.\n",
      "\tTraining accuracy at step 90600: 0.9735399484634399.\n",
      "Starting epoch 1394.\n",
      "Starting epoch 1395.\n",
      "\tTraining accuracy at step 90700: 0.973542332649231.\n",
      "Starting epoch 1396.\n",
      "\tTraining accuracy at step 90800: 0.973543643951416.\n",
      "Starting epoch 1397.\n",
      "Starting epoch 1398.\n",
      "\tTraining accuracy at step 90900: 0.9735463857650757.\n",
      "Starting epoch 1399.\n",
      "\tTraining accuracy at step 91000: 0.9735514521598816.\n",
      "Starting epoch 1400.\n",
      "Starting epoch 1401.\n",
      "\tTraining accuracy at step 91100: 0.9735536575317383.\n",
      "Starting epoch 1402.\n",
      "Starting epoch 1403.\n",
      "\tTraining accuracy at step 91200: 0.9735525846481323.\n",
      "Starting epoch 1404.\n",
      "\tTraining accuracy at step 91300: 0.9735541939735413.\n",
      "Starting epoch 1405.\n",
      "Starting epoch 1406.\n",
      "\tTraining accuracy at step 91400: 0.9735585451126099.\n",
      "Starting epoch 1407.\n",
      "\tTraining accuracy at step 91500: 0.9735620617866516.\n",
      "Starting epoch 1408.\n",
      "Starting epoch 1409.\n",
      "\tTraining accuracy at step 91600: 0.9735642671585083.\n",
      "Starting epoch 1410.\n",
      "\tTraining accuracy at step 91700: 0.9735686779022217.\n",
      "Starting epoch 1411.\n",
      "Starting epoch 1412.\n",
      "\tTraining accuracy at step 91800: 0.973572313785553.\n",
      "Starting epoch 1413.\n",
      "\tTraining accuracy at step 91900: 0.9735748767852783.\n",
      "Starting epoch 1414.\n",
      "Starting epoch 1415.\n",
      "\tTraining accuracy at step 92000: 0.973578155040741.\n",
      "Starting epoch 1416.\n",
      "\tTraining accuracy at step 92100: 0.9735830426216125.\n",
      "Starting epoch 1417.\n",
      "Starting epoch 1418.\n",
      "\tTraining accuracy at step 92200: 0.9735873937606812.\n",
      "Starting epoch 1419.\n",
      "\tTraining accuracy at step 92300: 0.9735918641090393.\n",
      "Starting epoch 1420.\n",
      "Starting epoch 1421.\n",
      "\tTraining accuracy at step 92400: 0.9735965132713318.\n",
      "Starting epoch 1422.\n",
      "Starting epoch 1423.\n",
      "\tTraining accuracy at step 92500: 0.9735990166664124.\n",
      "Starting epoch 1424.\n",
      "\tTraining accuracy at step 92600: 0.973599910736084.\n",
      "Starting epoch 1425.\n",
      "Starting epoch 1426.\n",
      "\tTraining accuracy at step 92700: 0.9735988974571228.\n",
      "Starting epoch 1427.\n",
      "\tTraining accuracy at step 92800: 0.973602294921875.\n",
      "Starting epoch 1428.\n",
      "Starting epoch 1429.\n",
      "\tTraining accuracy at step 92900: 0.9736065864562988.\n",
      "Starting epoch 1430.\n",
      "\tTraining accuracy at step 93000: 0.9736098647117615.\n",
      "Starting epoch 1431.\n",
      "Starting epoch 1432.\n",
      "\tTraining accuracy at step 93100: 0.9736133217811584.\n",
      "Starting epoch 1433.\n",
      "\tTraining accuracy at step 93200: 0.9736197590827942.\n",
      "Starting epoch 1434.\n",
      "Starting epoch 1435.\n",
      "\tTraining accuracy at step 93300: 0.9736234545707703.\n",
      "Starting epoch 1436.\n",
      "\tTraining accuracy at step 93400: 0.9736279845237732.\n",
      "Starting epoch 1437.\n",
      "Starting epoch 1438.\n",
      "\tTraining accuracy at step 93500: 0.973631739616394.\n",
      "Starting epoch 1439.\n",
      "\tTraining accuracy at step 93600: 0.9736355543136597.\n",
      "Starting epoch 1440.\n",
      "Starting epoch 1441.\n",
      "\tTraining accuracy at step 93700: 0.973639190196991.\n",
      "Starting epoch 1442.\n",
      "Starting epoch 1443.\n",
      "\tTraining accuracy at step 93800: 0.9736426472663879.\n",
      "Starting epoch 1444.\n",
      "\tTraining accuracy at step 93900: 0.9736431241035461.\n",
      "Starting epoch 1445.\n",
      "Starting epoch 1446.\n",
      "\tTraining accuracy at step 94000: 0.9736440181732178.\n",
      "Starting epoch 1447.\n",
      "\tTraining accuracy at step 94100: 0.9736467003822327.\n",
      "Starting epoch 1448.\n",
      "Starting epoch 1449.\n",
      "\tTraining accuracy at step 94200: 0.973649799823761.\n",
      "Starting epoch 1450.\n",
      "\tTraining accuracy at step 94300: 0.9736553430557251.\n",
      "Starting epoch 1451.\n",
      "Starting epoch 1452.\n",
      "\tTraining accuracy at step 94400: 0.973661482334137.\n",
      "Starting epoch 1453.\n",
      "\tTraining accuracy at step 94500: 0.9736599922180176.\n",
      "Starting epoch 1454.\n",
      "Starting epoch 1455.\n",
      "\tTraining accuracy at step 94600: 0.973659873008728.\n",
      "Starting epoch 1456.\n",
      "\tTraining accuracy at step 94700: 0.9736592769622803.\n",
      "Starting epoch 1457.\n",
      "Starting epoch 1458.\n",
      "\tTraining accuracy at step 94800: 0.9736617803573608.\n",
      "Starting epoch 1459.\n",
      "\tTraining accuracy at step 94900: 0.9736648797988892.\n",
      "Starting epoch 1460.\n",
      "Starting epoch 1461.\n",
      "\tTraining accuracy at step 95000: 0.9736663103103638.\n",
      "Starting epoch 1462.\n",
      "Starting epoch 1463.\n",
      "\tTraining accuracy at step 95100: 0.9736686944961548.\n",
      "Starting epoch 1464.\n",
      "\tTraining accuracy at step 95200: 0.9736721515655518.\n",
      "Starting epoch 1465.\n",
      "Starting epoch 1466.\n",
      "\tTraining accuracy at step 95300: 0.9736724495887756.\n",
      "Starting epoch 1467.\n",
      "\tTraining accuracy at step 95400: 0.9736718535423279.\n",
      "Starting epoch 1468.\n",
      "Starting epoch 1469.\n",
      "\tTraining accuracy at step 95500: 0.9736747145652771.\n",
      "Starting epoch 1470.\n",
      "\tTraining accuracy at step 95600: 0.973676860332489.\n",
      "Starting epoch 1471.\n",
      "Starting epoch 1472.\n",
      "\tTraining accuracy at step 95700: 0.9736804962158203.\n",
      "Starting epoch 1473.\n",
      "\tTraining accuracy at step 95800: 0.973683774471283.\n",
      "Starting epoch 1474.\n",
      "Starting epoch 1475.\n",
      "\tTraining accuracy at step 95900: 0.973689615726471.\n",
      "Starting epoch 1476.\n",
      "\tTraining accuracy at step 96000: 0.973695695400238.\n",
      "Starting epoch 1477.\n",
      "Starting epoch 1478.\n",
      "\tTraining accuracy at step 96100: 0.9736984372138977.\n",
      "Starting epoch 1479.\n",
      "\tTraining accuracy at step 96200: 0.9736998081207275.\n",
      "Starting epoch 1480.\n",
      "Starting epoch 1481.\n",
      "\tTraining accuracy at step 96300: 0.9736998081207275.\n",
      "Starting epoch 1482.\n",
      "Starting epoch 1483.\n",
      "\tTraining accuracy at step 96400: 0.9736976623535156.\n",
      "Starting epoch 1484.\n",
      "\tTraining accuracy at step 96500: 0.9737022519111633.\n",
      "Starting epoch 1485.\n",
      "Starting epoch 1486.\n",
      "\tTraining accuracy at step 96600: 0.973704993724823.\n",
      "Starting epoch 1487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining accuracy at step 96700: 0.9737059473991394.\n",
      "Starting epoch 1488.\n",
      "Starting epoch 1489.\n",
      "\tTraining accuracy at step 96800: 0.973708987236023.\n",
      "Starting epoch 1490.\n",
      "\tTraining accuracy at step 96900: 0.9737131595611572.\n",
      "Starting epoch 1491.\n",
      "Starting epoch 1492.\n",
      "\tTraining accuracy at step 97000: 0.9737167358398438.\n",
      "Starting epoch 1493.\n",
      "\tTraining accuracy at step 97100: 0.9737219214439392.\n",
      "Starting epoch 1494.\n",
      "Starting epoch 1495.\n",
      "\tTraining accuracy at step 97200: 0.9737234115600586.\n",
      "Starting epoch 1496.\n",
      "\tTraining accuracy at step 97300: 0.9737253189086914.\n",
      "Starting epoch 1497.\n",
      "Starting epoch 1498.\n",
      "\tTraining accuracy at step 97400: 0.9737290740013123.\n",
      "Starting epoch 1499.\n",
      "\tTraining accuracy at step 97500: 0.9737312197685242.\n",
      "Starting epoch 1500.\n",
      "Starting epoch 1501.\n",
      "\tTraining accuracy at step 97600: 0.9737347364425659.\n",
      "Starting epoch 1502.\n",
      "Starting epoch 1503.\n",
      "\tTraining accuracy at step 97700: 0.9737396836280823.\n",
      "Starting epoch 1504.\n",
      "\tTraining accuracy at step 97800: 0.9737420678138733.\n",
      "Starting epoch 1505.\n",
      "Starting epoch 1506.\n",
      "\tTraining accuracy at step 97900: 0.9737368226051331.\n",
      "Starting epoch 1507.\n",
      "\tTraining accuracy at step 98000: 0.9737368822097778.\n",
      "Starting epoch 1508.\n",
      "Starting epoch 1509.\n",
      "\tTraining accuracy at step 98100: 0.9737371206283569.\n",
      "Starting epoch 1510.\n",
      "\tTraining accuracy at step 98200: 0.9737392067909241.\n",
      "Starting epoch 1511.\n",
      "Starting epoch 1512.\n",
      "\tTraining accuracy at step 98300: 0.9737418293952942.\n",
      "Starting epoch 1513.\n",
      "\tTraining accuracy at step 98400: 0.9737437963485718.\n",
      "Starting epoch 1514.\n",
      "Starting epoch 1515.\n",
      "\tTraining accuracy at step 98500: 0.9737481474876404.\n",
      "Starting epoch 1516.\n",
      "\tTraining accuracy at step 98600: 0.9737515449523926.\n",
      "Starting epoch 1517.\n",
      "Starting epoch 1518.\n",
      "\tTraining accuracy at step 98700: 0.9737540483474731.\n",
      "Starting epoch 1519.\n",
      "\tTraining accuracy at step 98800: 0.9737583994865417.\n",
      "Starting epoch 1520.\n",
      "Starting epoch 1521.\n",
      "\tTraining accuracy at step 98900: 0.973761796951294.\n",
      "Starting epoch 1522.\n",
      "Starting epoch 1523.\n",
      "\tTraining accuracy at step 99000: 0.9737650752067566.\n",
      "Starting epoch 1524.\n",
      "\tTraining accuracy at step 99100: 0.9737676978111267.\n",
      "Starting epoch 1525.\n",
      "Starting epoch 1526.\n",
      "\tTraining accuracy at step 99200: 0.9737706184387207.\n",
      "Starting epoch 1527.\n",
      "\tTraining accuracy at step 99300: 0.9737743735313416.\n",
      "Starting epoch 1528.\n",
      "Starting epoch 1529.\n",
      "\tTraining accuracy at step 99400: 0.9737791419029236.\n",
      "Starting epoch 1530.\n",
      "\tTraining accuracy at step 99500: 0.9737815856933594.\n",
      "Starting epoch 1531.\n",
      "Starting epoch 1532.\n",
      "\tTraining accuracy at step 99600: 0.9737805128097534.\n",
      "Starting epoch 1533.\n",
      "\tTraining accuracy at step 99700: 0.9737815856933594.\n",
      "Starting epoch 1534.\n",
      "Starting epoch 1535.\n",
      "\tTraining accuracy at step 99800: 0.9737837314605713.\n",
      "Starting epoch 1536.\n",
      "\tTraining accuracy at step 99900: 0.9737846255302429.\n",
      "Starting epoch 1537.\n",
      "Starting epoch 1538.\n",
      "\tTraining accuracy at step 100000: 0.9737892150878906.\n",
      "Starting epoch 1539.\n",
      "\tTraining accuracy at step 100100: 0.973789393901825.\n",
      "Starting epoch 1540.\n",
      "Starting epoch 1541.\n",
      "\tTraining accuracy at step 100200: 0.9737911820411682.\n",
      "Starting epoch 1542.\n",
      "Starting epoch 1543.\n",
      "\tTraining accuracy at step 100300: 0.9737937450408936.\n",
      "Starting epoch 1544.\n",
      "\tTraining accuracy at step 100400: 0.9737985730171204.\n",
      "Starting epoch 1545.\n",
      "Starting epoch 1546.\n",
      "\tTraining accuracy at step 100500: 0.9738039374351501.\n",
      "Starting epoch 1547.\n",
      "\tTraining accuracy at step 100600: 0.9738102555274963.\n",
      "Starting epoch 1548.\n",
      "Starting epoch 1549.\n",
      "\tTraining accuracy at step 100700: 0.9738147258758545.\n",
      "Starting epoch 1550.\n",
      "\tTraining accuracy at step 100800: 0.9738184809684753.\n",
      "Starting epoch 1551.\n",
      "Starting epoch 1552.\n",
      "\tTraining accuracy at step 100900: 0.9738250970840454.\n",
      "Starting epoch 1553.\n",
      "\tTraining accuracy at step 101000: 0.9738327264785767.\n",
      "Starting epoch 1554.\n",
      "Starting epoch 1555.\n",
      "\tTraining accuracy at step 101100: 0.9738383293151855.\n",
      "Starting epoch 1556.\n",
      "\tTraining accuracy at step 101200: 0.9738449454307556.\n",
      "Starting epoch 1557.\n",
      "Starting epoch 1558.\n",
      "\tTraining accuracy at step 101300: 0.9738490581512451.\n",
      "Starting epoch 1559.\n",
      "\tTraining accuracy at step 101400: 0.9738537073135376.\n",
      "Starting epoch 1560.\n",
      "Starting epoch 1561.\n",
      "\tTraining accuracy at step 101500: 0.9738553762435913.\n",
      "Starting epoch 1562.\n",
      "Starting epoch 1563.\n",
      "\tTraining accuracy at step 101600: 0.9738550782203674.\n",
      "Starting epoch 1564.\n",
      "\tTraining accuracy at step 101700: 0.9738576412200928.\n",
      "Starting epoch 1565.\n",
      "Starting epoch 1566.\n",
      "\tTraining accuracy at step 101800: 0.9738596081733704.\n",
      "Starting epoch 1567.\n",
      "\tTraining accuracy at step 101900: 0.9738636016845703.\n",
      "Starting epoch 1568.\n",
      "Starting epoch 1569.\n",
      "\tTraining accuracy at step 102000: 0.973868727684021.\n",
      "Starting epoch 1570.\n",
      "\tTraining accuracy at step 102100: 0.973872721195221.\n",
      "Starting epoch 1571.\n",
      "Starting epoch 1572.\n",
      "\tTraining accuracy at step 102200: 0.9738760590553284.\n",
      "Starting epoch 1573.\n",
      "\tTraining accuracy at step 102300: 0.973879873752594.\n",
      "Starting epoch 1574.\n",
      "Starting epoch 1575.\n",
      "\tTraining accuracy at step 102400: 0.9738857746124268.\n",
      "Starting epoch 1576.\n",
      "\tTraining accuracy at step 102500: 0.9738901257514954.\n",
      "Starting epoch 1577.\n",
      "Starting epoch 1578.\n",
      "\tTraining accuracy at step 102600: 0.9738948941230774.\n",
      "Starting epoch 1579.\n",
      "\tTraining accuracy at step 102700: 0.973899781703949.\n",
      "Starting epoch 1580.\n",
      "Starting epoch 1581.\n",
      "\tTraining accuracy at step 102800: 0.9739031791687012.\n",
      "Starting epoch 1582.\n",
      "Starting epoch 1583.\n",
      "\tTraining accuracy at step 102900: 0.9739039540290833.\n",
      "Starting epoch 1584.\n",
      "\tTraining accuracy at step 103000: 0.9739087224006653.\n",
      "Starting epoch 1585.\n",
      "Starting epoch 1586.\n",
      "\tTraining accuracy at step 103100: 0.9739099144935608.\n",
      "Starting epoch 1587.\n",
      "\tTraining accuracy at step 103200: 0.9739102125167847.\n",
      "Starting epoch 1588.\n",
      "Starting epoch 1589.\n",
      "\tTraining accuracy at step 103300: 0.9739099740982056.\n",
      "Starting epoch 1590.\n",
      "\tTraining accuracy at step 103400: 0.9739096760749817.\n",
      "Starting epoch 1591.\n",
      "Starting epoch 1592.\n",
      "\tTraining accuracy at step 103500: 0.9739104509353638.\n",
      "Starting epoch 1593.\n",
      "\tTraining accuracy at step 103600: 0.9739121198654175.\n",
      "Starting epoch 1594.\n",
      "Starting epoch 1595.\n",
      "\tTraining accuracy at step 103700: 0.9739137887954712.\n",
      "Starting epoch 1596.\n",
      "\tTraining accuracy at step 103800: 0.9739171266555786.\n",
      "Starting epoch 1597.\n",
      "Starting epoch 1598.\n",
      "\tTraining accuracy at step 103900: 0.9739197492599487.\n",
      "Starting epoch 1599.\n",
      "\tTraining accuracy at step 104000: 0.9739190936088562.\n",
      "Starting epoch 1600.\n",
      "Starting epoch 1601.\n",
      "\tTraining accuracy at step 104100: 0.973921000957489.\n",
      "Starting epoch 1602.\n",
      "Starting epoch 1603.\n",
      "\tTraining accuracy at step 104200: 0.9739229679107666.\n",
      "Starting epoch 1604.\n",
      "\tTraining accuracy at step 104300: 0.9739257097244263.\n",
      "Starting epoch 1605.\n",
      "Starting epoch 1606.\n",
      "\tTraining accuracy at step 104400: 0.973927915096283.\n",
      "Starting epoch 1607.\n",
      "\tTraining accuracy at step 104500: 0.9739271998405457.\n",
      "Starting epoch 1608.\n",
      "Starting epoch 1609.\n",
      "\tTraining accuracy at step 104600: 0.9739305973052979.\n",
      "Starting epoch 1610.\n",
      "\tTraining accuracy at step 104700: 0.9739314317703247.\n",
      "Starting epoch 1611.\n",
      "Starting epoch 1612.\n",
      "\tTraining accuracy at step 104800: 0.9739307761192322.\n",
      "Starting epoch 1613.\n",
      "\tTraining accuracy at step 104900: 0.9739319086074829.\n",
      "Starting epoch 1614.\n",
      "Starting epoch 1615.\n",
      "\tTraining accuracy at step 105000: 0.9739338159561157.\n",
      "Starting epoch 1616.\n",
      "\tTraining accuracy at step 105100: 0.9739343523979187.\n",
      "Starting epoch 1617.\n",
      "Starting epoch 1618.\n",
      "\tTraining accuracy at step 105200: 0.9739376306533813.\n",
      "Starting epoch 1619.\n",
      "\tTraining accuracy at step 105300: 0.9739418625831604.\n",
      "Starting epoch 1620.\n",
      "Starting epoch 1621.\n",
      "\tTraining accuracy at step 105400: 0.9739444851875305.\n",
      "Starting epoch 1622.\n",
      "Starting epoch 1623.\n",
      "\tTraining accuracy at step 105500: 0.973948061466217.\n",
      "Starting epoch 1624.\n",
      "\tTraining accuracy at step 105600: 0.9739540219306946.\n",
      "Starting epoch 1625.\n",
      "Starting epoch 1626.\n",
      "\tTraining accuracy at step 105700: 0.973960280418396.\n",
      "Starting epoch 1627.\n",
      "\tTraining accuracy at step 105800: 0.9739619493484497.\n",
      "Starting epoch 1628.\n",
      "Starting epoch 1629.\n",
      "\tTraining accuracy at step 105900: 0.9739630818367004.\n",
      "Starting epoch 1630.\n",
      "\tTraining accuracy at step 106000: 0.9739641547203064.\n",
      "Starting epoch 1631.\n",
      "Starting epoch 1632.\n",
      "\tTraining accuracy at step 106100: 0.9739661812782288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1633.\n",
      "\tTraining accuracy at step 106200: 0.9739669561386108.\n",
      "Starting epoch 1634.\n",
      "Starting epoch 1635.\n",
      "\tTraining accuracy at step 106300: 0.9739661812782288.\n",
      "Starting epoch 1636.\n",
      "\tTraining accuracy at step 106400: 0.9739676117897034.\n",
      "Starting epoch 1637.\n",
      "Starting epoch 1638.\n",
      "\tTraining accuracy at step 106500: 0.9739722013473511.\n",
      "Starting epoch 1639.\n",
      "\tTraining accuracy at step 106600: 0.973973274230957.\n",
      "Starting epoch 1640.\n",
      "Starting epoch 1641.\n",
      "\tTraining accuracy at step 106700: 0.9739750027656555.\n",
      "Starting epoch 1642.\n",
      "Starting epoch 1643.\n",
      "\tTraining accuracy at step 106800: 0.9739792943000793.\n",
      "Starting epoch 1644.\n",
      "\tTraining accuracy at step 106900: 0.9739817380905151.\n",
      "Starting epoch 1645.\n",
      "Starting epoch 1646.\n",
      "\tTraining accuracy at step 107000: 0.9739810824394226.\n",
      "Starting epoch 1647.\n",
      "\tTraining accuracy at step 107100: 0.9739802479743958.\n",
      "Starting epoch 1648.\n",
      "Starting epoch 1649.\n",
      "\tTraining accuracy at step 107200: 0.9739829897880554.\n",
      "Starting epoch 1650.\n",
      "\tTraining accuracy at step 107300: 0.9739859104156494.\n",
      "Starting epoch 1651.\n",
      "Starting epoch 1652.\n",
      "\tTraining accuracy at step 107400: 0.9739892482757568.\n",
      "Starting epoch 1653.\n",
      "\tTraining accuracy at step 107500: 0.9739927649497986.\n",
      "Starting epoch 1654.\n",
      "Starting epoch 1655.\n",
      "\tTraining accuracy at step 107600: 0.9739962220191956.\n",
      "Starting epoch 1656.\n",
      "\tTraining accuracy at step 107700: 0.9739956259727478.\n",
      "Starting epoch 1657.\n",
      "Starting epoch 1658.\n",
      "\tTraining accuracy at step 107800: 0.9739990234375.\n",
      "Starting epoch 1659.\n",
      "\tTraining accuracy at step 107900: 0.9740015268325806.\n",
      "Starting epoch 1660.\n",
      "Starting epoch 1661.\n",
      "\tTraining accuracy at step 108000: 0.9739984273910522.\n",
      "Starting epoch 1662.\n",
      "Starting epoch 1663.\n",
      "\tTraining accuracy at step 108100: 0.9739998579025269.\n",
      "Starting epoch 1664.\n",
      "\tTraining accuracy at step 108200: 0.9740009903907776.\n",
      "Starting epoch 1665.\n",
      "Starting epoch 1666.\n",
      "\tTraining accuracy at step 108300: 0.9740049242973328.\n",
      "Starting epoch 1667.\n",
      "\tTraining accuracy at step 108400: 0.9740069508552551.\n",
      "Starting epoch 1668.\n",
      "Starting epoch 1669.\n",
      "\tTraining accuracy at step 108500: 0.9740101099014282.\n",
      "Starting epoch 1670.\n",
      "\tTraining accuracy at step 108600: 0.9740103483200073.\n",
      "Starting epoch 1671.\n",
      "Starting epoch 1672.\n",
      "\tTraining accuracy at step 108700: 0.9740122556686401.\n",
      "Starting epoch 1673.\n",
      "\tTraining accuracy at step 108800: 0.9740180373191833.\n",
      "Starting epoch 1674.\n",
      "Starting epoch 1675.\n",
      "\tTraining accuracy at step 108900: 0.9740219116210938.\n",
      "Starting epoch 1676.\n",
      "\tTraining accuracy at step 109000: 0.9740267395973206.\n",
      "Starting epoch 1677.\n",
      "Starting epoch 1678.\n",
      "\tTraining accuracy at step 109100: 0.9740303158760071.\n",
      "Starting epoch 1679.\n",
      "\tTraining accuracy at step 109200: 0.9740355610847473.\n",
      "Starting epoch 1680.\n",
      "Starting epoch 1681.\n",
      "\tTraining accuracy at step 109300: 0.9740360975265503.\n",
      "Starting epoch 1682.\n",
      "Starting epoch 1683.\n",
      "\tTraining accuracy at step 109400: 0.974031388759613.\n",
      "Starting epoch 1684.\n",
      "\tTraining accuracy at step 109500: 0.9740286469459534.\n",
      "Starting epoch 1685.\n",
      "Starting epoch 1686.\n",
      "\tTraining accuracy at step 109600: 0.9740307927131653.\n",
      "Starting epoch 1687.\n",
      "\tTraining accuracy at step 109700: 0.9740314483642578.\n",
      "Starting epoch 1688.\n",
      "Starting epoch 1689.\n",
      "\tTraining accuracy at step 109800: 0.9740341901779175.\n",
      "Starting epoch 1690.\n",
      "\tTraining accuracy at step 109900: 0.9740374088287354.\n",
      "Starting epoch 1691.\n",
      "Starting epoch 1692.\n",
      "\tTraining accuracy at step 110000: 0.974041759967804.\n",
      "Starting epoch 1693.\n",
      "\tTraining accuracy at step 110100: 0.9740450382232666.\n",
      "Starting epoch 1694.\n",
      "Starting epoch 1695.\n",
      "\tTraining accuracy at step 110200: 0.9740450382232666.\n",
      "Starting epoch 1696.\n",
      "\tTraining accuracy at step 110300: 0.9740490913391113.\n",
      "Starting epoch 1697.\n",
      "Starting epoch 1698.\n",
      "\tTraining accuracy at step 110400: 0.9740546345710754.\n",
      "Starting epoch 1699.\n",
      "\tTraining accuracy at step 110500: 0.9740567803382874.\n",
      "Starting epoch 1700.\n",
      "Starting epoch 1701.\n",
      "\tTraining accuracy at step 110600: 0.9740611910820007.\n",
      "Starting epoch 1702.\n",
      "Starting epoch 1703.\n",
      "\tTraining accuracy at step 110700: 0.9740645885467529.\n",
      "Starting epoch 1704.\n",
      "\tTraining accuracy at step 110800: 0.9740679264068604.\n",
      "Starting epoch 1705.\n",
      "Starting epoch 1706.\n",
      "\tTraining accuracy at step 110900: 0.9740707874298096.\n",
      "Starting epoch 1707.\n",
      "\tTraining accuracy at step 111000: 0.9740725159645081.\n",
      "Starting epoch 1708.\n",
      "Starting epoch 1709.\n",
      "\tTraining accuracy at step 111100: 0.9740731716156006.\n",
      "Starting epoch 1710.\n",
      "\tTraining accuracy at step 111200: 0.9740754961967468.\n",
      "Starting epoch 1711.\n",
      "Starting epoch 1712.\n",
      "\tTraining accuracy at step 111300: 0.9740789532661438.\n",
      "Starting epoch 1713.\n",
      "\tTraining accuracy at step 111400: 0.9740806818008423.\n",
      "Starting epoch 1714.\n",
      "Starting epoch 1715.\n",
      "\tTraining accuracy at step 111500: 0.9740845561027527.\n",
      "Starting epoch 1716.\n",
      "\tTraining accuracy at step 111600: 0.9740852117538452.\n",
      "Starting epoch 1717.\n",
      "Starting epoch 1718.\n",
      "\tTraining accuracy at step 111700: 0.9740889668464661.\n",
      "Starting epoch 1719.\n",
      "\tTraining accuracy at step 111800: 0.9740926027297974.\n",
      "Starting epoch 1720.\n",
      "Starting epoch 1721.\n",
      "\tTraining accuracy at step 111900: 0.9740930795669556.\n",
      "Starting epoch 1722.\n",
      "Starting epoch 1723.\n",
      "\tTraining accuracy at step 112000: 0.9740908145904541.\n",
      "Starting epoch 1724.\n",
      "\tTraining accuracy at step 112100: 0.9740927219390869.\n",
      "Starting epoch 1725.\n",
      "Starting epoch 1726.\n",
      "\tTraining accuracy at step 112200: 0.9740933179855347.\n",
      "Starting epoch 1727.\n",
      "\tTraining accuracy at step 112300: 0.9740958213806152.\n",
      "Starting epoch 1728.\n",
      "Starting epoch 1729.\n",
      "\tTraining accuracy at step 112400: 0.9740976095199585.\n",
      "Starting epoch 1730.\n",
      "\tTraining accuracy at step 112500: 0.9740989804267883.\n",
      "Starting epoch 1731.\n",
      "Starting epoch 1732.\n",
      "\tTraining accuracy at step 112600: 0.9740965366363525.\n",
      "Starting epoch 1733.\n",
      "\tTraining accuracy at step 112700: 0.9740962982177734.\n",
      "Starting epoch 1734.\n",
      "Starting epoch 1735.\n",
      "\tTraining accuracy at step 112800: 0.9740962386131287.\n",
      "Starting epoch 1736.\n",
      "\tTraining accuracy at step 112900: 0.9740959405899048.\n",
      "Starting epoch 1737.\n",
      "Starting epoch 1738.\n",
      "\tTraining accuracy at step 113000: 0.9740966558456421.\n",
      "Starting epoch 1739.\n",
      "\tTraining accuracy at step 113100: 0.9740971922874451.\n",
      "Starting epoch 1740.\n",
      "Starting epoch 1741.\n",
      "\tTraining accuracy at step 113200: 0.9740986227989197.\n",
      "Starting epoch 1742.\n",
      "Starting epoch 1743.\n",
      "\tTraining accuracy at step 113300: 0.9741008877754211.\n",
      "Starting epoch 1744.\n",
      "\tTraining accuracy at step 113400: 0.9741029739379883.\n",
      "Starting epoch 1745.\n",
      "Starting epoch 1746.\n",
      "\tTraining accuracy at step 113500: 0.9741031527519226.\n",
      "Starting epoch 1747.\n",
      "\tTraining accuracy at step 113600: 0.9741053581237793.\n",
      "Starting epoch 1748.\n",
      "Starting epoch 1749.\n",
      "\tTraining accuracy at step 113700: 0.9741078615188599.\n",
      "Starting epoch 1750.\n",
      "\tTraining accuracy at step 113800: 0.9741088151931763.\n",
      "Starting epoch 1751.\n",
      "Starting epoch 1752.\n",
      "\tTraining accuracy at step 113900: 0.9741106629371643.\n",
      "Starting epoch 1753.\n",
      "\tTraining accuracy at step 114000: 0.9741132259368896.\n",
      "Starting epoch 1754.\n",
      "Starting epoch 1755.\n",
      "\tTraining accuracy at step 114100: 0.9741135239601135.\n",
      "Starting epoch 1756.\n",
      "\tTraining accuracy at step 114200: 0.9741132259368896.\n",
      "Starting epoch 1757.\n",
      "Starting epoch 1758.\n",
      "\tTraining accuracy at step 114300: 0.974117636680603.\n",
      "Starting epoch 1759.\n",
      "\tTraining accuracy at step 114400: 0.9741200804710388.\n",
      "Starting epoch 1760.\n",
      "Starting epoch 1761.\n",
      "\tTraining accuracy at step 114500: 0.9741219878196716.\n",
      "Starting epoch 1762.\n",
      "Starting epoch 1763.\n",
      "\tTraining accuracy at step 114600: 0.9741210341453552.\n",
      "Starting epoch 1764.\n",
      "\tTraining accuracy at step 114700: 0.9741217494010925.\n",
      "Starting epoch 1765.\n",
      "Starting epoch 1766.\n",
      "\tTraining accuracy at step 114800: 0.974124014377594.\n",
      "Starting epoch 1767.\n",
      "\tTraining accuracy at step 114900: 0.9741261005401611.\n",
      "Starting epoch 1768.\n",
      "Starting epoch 1769.\n",
      "\tTraining accuracy at step 115000: 0.9741247296333313.\n",
      "Starting epoch 1770.\n",
      "\tTraining accuracy at step 115100: 0.9741263389587402.\n",
      "Starting epoch 1771.\n",
      "Starting epoch 1772.\n",
      "\tTraining accuracy at step 115200: 0.9741272330284119.\n",
      "Starting epoch 1773.\n",
      "\tTraining accuracy at step 115300: 0.9741223454475403.\n",
      "Starting epoch 1774.\n",
      "Starting epoch 1775.\n",
      "\tTraining accuracy at step 115400: 0.9741222262382507.\n",
      "Starting epoch 1776.\n",
      "\tTraining accuracy at step 115500: 0.9741225242614746.\n",
      "Starting epoch 1777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1778.\n",
      "\tTraining accuracy at step 115600: 0.974125325679779.\n",
      "Starting epoch 1779.\n",
      "\tTraining accuracy at step 115700: 0.9741268157958984.\n",
      "Starting epoch 1780.\n",
      "Starting epoch 1781.\n",
      "\tTraining accuracy at step 115800: 0.974129319190979.\n",
      "Starting epoch 1782.\n",
      "Starting epoch 1783.\n",
      "\tTraining accuracy at step 115900: 0.9741320013999939.\n",
      "Starting epoch 1784.\n",
      "\tTraining accuracy at step 116000: 0.9741299152374268.\n",
      "Starting epoch 1785.\n",
      "Starting epoch 1786.\n",
      "\tTraining accuracy at step 116100: 0.9741283059120178.\n",
      "Starting epoch 1787.\n",
      "\tTraining accuracy at step 116200: 0.9741286635398865.\n",
      "Starting epoch 1788.\n",
      "Starting epoch 1789.\n",
      "\tTraining accuracy at step 116300: 0.9741288423538208.\n",
      "Starting epoch 1790.\n",
      "\tTraining accuracy at step 116400: 0.9741308093070984.\n",
      "Starting epoch 1791.\n",
      "Starting epoch 1792.\n",
      "\tTraining accuracy at step 116500: 0.9741332530975342.\n",
      "Starting epoch 1793.\n",
      "\tTraining accuracy at step 116600: 0.9741349220275879.\n",
      "Starting epoch 1794.\n",
      "Starting epoch 1795.\n",
      "\tTraining accuracy at step 116700: 0.9741367697715759.\n",
      "Starting epoch 1796.\n",
      "\tTraining accuracy at step 116800: 0.9741373658180237.\n",
      "Starting epoch 1797.\n",
      "Starting epoch 1798.\n",
      "\tTraining accuracy at step 116900: 0.9741369485855103.\n",
      "Starting epoch 1799.\n",
      "\tTraining accuracy at step 117000: 0.9741382002830505.\n",
      "Starting epoch 1800.\n",
      "Starting epoch 1801.\n",
      "\tTraining accuracy at step 117100: 0.9741395115852356.\n",
      "Starting epoch 1802.\n",
      "Starting epoch 1803.\n",
      "\tTraining accuracy at step 117200: 0.9741396307945251.\n",
      "Starting epoch 1804.\n",
      "\tTraining accuracy at step 117300: 0.9741406440734863.\n",
      "Starting epoch 1805.\n",
      "Starting epoch 1806.\n",
      "\tTraining accuracy at step 117400: 0.9741401076316833.\n",
      "Starting epoch 1807.\n",
      "\tTraining accuracy at step 117500: 0.9741404056549072.\n",
      "Starting epoch 1808.\n",
      "Starting epoch 1809.\n",
      "\tTraining accuracy at step 117600: 0.9741405844688416.\n",
      "Starting epoch 1810.\n",
      "\tTraining accuracy at step 117700: 0.9741393327713013.\n",
      "Starting epoch 1811.\n",
      "Starting epoch 1812.\n",
      "\tTraining accuracy at step 117800: 0.9741400480270386.\n",
      "Starting epoch 1813.\n",
      "\tTraining accuracy at step 117900: 0.9741385579109192.\n",
      "Starting epoch 1814.\n",
      "Starting epoch 1815.\n",
      "\tTraining accuracy at step 118000: 0.9741395711898804.\n",
      "Starting epoch 1816.\n",
      "\tTraining accuracy at step 118100: 0.97414231300354.\n",
      "Starting epoch 1817.\n",
      "Starting epoch 1818.\n",
      "\tTraining accuracy at step 118200: 0.9741447567939758.\n",
      "Starting epoch 1819.\n",
      "\tTraining accuracy at step 118300: 0.9741463661193848.\n",
      "Starting epoch 1820.\n",
      "Starting epoch 1821.\n",
      "\tTraining accuracy at step 118400: 0.9741470217704773.\n",
      "Starting epoch 1822.\n",
      "Starting epoch 1823.\n",
      "\tTraining accuracy at step 118500: 0.9741488099098206.\n",
      "Starting epoch 1824.\n",
      "\tTraining accuracy at step 118600: 0.9741460084915161.\n",
      "Starting epoch 1825.\n",
      "Starting epoch 1826.\n",
      "\tTraining accuracy at step 118700: 0.9741421341896057.\n",
      "Starting epoch 1827.\n",
      "\tTraining accuracy at step 118800: 0.9741377830505371.\n",
      "Starting epoch 1828.\n",
      "Starting epoch 1829.\n",
      "\tTraining accuracy at step 118900: 0.9741364121437073.\n",
      "Starting epoch 1830.\n",
      "\tTraining accuracy at step 119000: 0.9741359949111938.\n",
      "Starting epoch 1831.\n",
      "Starting epoch 1832.\n",
      "\tTraining accuracy at step 119100: 0.974136233329773.\n",
      "Starting epoch 1833.\n",
      "\tTraining accuracy at step 119200: 0.9741352796554565.\n",
      "Starting epoch 1834.\n",
      "Starting epoch 1835.\n",
      "\tTraining accuracy at step 119300: 0.9741364121437073.\n",
      "Starting epoch 1836.\n",
      "\tTraining accuracy at step 119400: 0.9741378426551819.\n",
      "Starting epoch 1837.\n",
      "Starting epoch 1838.\n",
      "\tTraining accuracy at step 119500: 0.9741404056549072.\n",
      "Starting epoch 1839.\n",
      "\tTraining accuracy at step 119600: 0.9741435647010803.\n",
      "Starting epoch 1840.\n",
      "Starting epoch 1841.\n",
      "\tTraining accuracy at step 119700: 0.974145770072937.\n",
      "Starting epoch 1842.\n",
      "Starting epoch 1843.\n",
      "\tTraining accuracy at step 119800: 0.9741482138633728.\n",
      "Starting epoch 1844.\n",
      "\tTraining accuracy at step 119900: 0.974152684211731.\n",
      "Starting epoch 1845.\n",
      "Starting epoch 1846.\n",
      "\tTraining accuracy at step 120000: 0.9741586446762085.\n",
      "Starting epoch 1847.\n",
      "\tTraining accuracy at step 120100: 0.9741620421409607.\n",
      "Starting epoch 1848.\n",
      "Starting epoch 1849.\n",
      "\tTraining accuracy at step 120200: 0.9741668105125427.\n",
      "Starting epoch 1850.\n",
      "\tTraining accuracy at step 120300: 0.9741727113723755.\n",
      "Starting epoch 1851.\n",
      "Starting epoch 1852.\n",
      "\tTraining accuracy at step 120400: 0.9741765856742859.\n",
      "Starting epoch 1853.\n",
      "\tTraining accuracy at step 120500: 0.9741755723953247.\n",
      "Starting epoch 1854.\n",
      "Starting epoch 1855.\n",
      "\tTraining accuracy at step 120600: 0.9741771221160889.\n",
      "Starting epoch 1856.\n",
      "\tTraining accuracy at step 120700: 0.9741770625114441.\n",
      "Starting epoch 1857.\n",
      "Starting epoch 1858.\n",
      "\tTraining accuracy at step 120800: 0.9741774201393127.\n",
      "Starting epoch 1859.\n",
      "\tTraining accuracy at step 120900: 0.9741799831390381.\n",
      "Starting epoch 1860.\n",
      "Starting epoch 1861.\n",
      "\tTraining accuracy at step 121000: 0.9741820096969604.\n",
      "Starting epoch 1862.\n",
      "Starting epoch 1863.\n",
      "\tTraining accuracy at step 121100: 0.9741842746734619.\n",
      "Starting epoch 1864.\n",
      "\tTraining accuracy at step 121200: 0.97418612241745.\n",
      "Starting epoch 1865.\n",
      "Starting epoch 1866.\n",
      "\tTraining accuracy at step 121300: 0.9741913676261902.\n",
      "Starting epoch 1867.\n",
      "\tTraining accuracy at step 121400: 0.9741936326026917.\n",
      "Starting epoch 1868.\n",
      "Starting epoch 1869.\n",
      "\tTraining accuracy at step 121500: 0.9741965532302856.\n",
      "Starting epoch 1870.\n",
      "\tTraining accuracy at step 121600: 0.9741994142532349.\n",
      "Starting epoch 1871.\n",
      "Starting epoch 1872.\n",
      "\tTraining accuracy at step 121700: 0.9742006659507751.\n",
      "Starting epoch 1873.\n",
      "\tTraining accuracy at step 121800: 0.9742012023925781.\n",
      "Starting epoch 1874.\n",
      "Starting epoch 1875.\n",
      "\tTraining accuracy at step 121900: 0.9742048382759094.\n",
      "Starting epoch 1876.\n",
      "\tTraining accuracy at step 122000: 0.9742092490196228.\n",
      "Starting epoch 1877.\n",
      "Starting epoch 1878.\n",
      "\tTraining accuracy at step 122100: 0.974209725856781.\n",
      "Starting epoch 1879.\n",
      "\tTraining accuracy at step 122200: 0.9742143750190735.\n",
      "Starting epoch 1880.\n",
      "Starting epoch 1881.\n",
      "\tTraining accuracy at step 122300: 0.9742178916931152.\n",
      "Starting epoch 1882.\n",
      "Starting epoch 1883.\n",
      "\tTraining accuracy at step 122400: 0.9742218852043152.\n",
      "Starting epoch 1884.\n",
      "\tTraining accuracy at step 122500: 0.9742241501808167.\n",
      "Starting epoch 1885.\n",
      "Starting epoch 1886.\n",
      "\tTraining accuracy at step 122600: 0.9742236137390137.\n",
      "Starting epoch 1887.\n",
      "\tTraining accuracy at step 122700: 0.9742242693901062.\n",
      "Starting epoch 1888.\n",
      "Starting epoch 1889.\n",
      "\tTraining accuracy at step 122800: 0.9742242097854614.\n",
      "Starting epoch 1890.\n",
      "\tTraining accuracy at step 122900: 0.974226176738739.\n",
      "Starting epoch 1891.\n",
      "Starting epoch 1892.\n",
      "\tTraining accuracy at step 123000: 0.9742282032966614.\n",
      "Starting epoch 1893.\n",
      "\tTraining accuracy at step 123100: 0.9742305278778076.\n",
      "Starting epoch 1894.\n",
      "Starting epoch 1895.\n",
      "\tTraining accuracy at step 123200: 0.9742312431335449.\n",
      "Starting epoch 1896.\n",
      "\tTraining accuracy at step 123300: 0.9742319583892822.\n",
      "Starting epoch 1897.\n",
      "Starting epoch 1898.\n",
      "\tTraining accuracy at step 123400: 0.9742332100868225.\n",
      "Starting epoch 1899.\n",
      "\tTraining accuracy at step 123500: 0.9742367267608643.\n",
      "Starting epoch 1900.\n",
      "Starting epoch 1901.\n",
      "\tTraining accuracy at step 123600: 0.9742410778999329.\n",
      "Starting epoch 1902.\n",
      "Starting epoch 1903.\n",
      "\tTraining accuracy at step 123700: 0.9742397665977478.\n",
      "Starting epoch 1904.\n",
      "\tTraining accuracy at step 123800: 0.9742383360862732.\n",
      "Starting epoch 1905.\n",
      "Starting epoch 1906.\n",
      "\tTraining accuracy at step 123900: 0.9742398858070374.\n",
      "Starting epoch 1907.\n",
      "\tTraining accuracy at step 124000: 0.9742403626441956.\n",
      "Starting epoch 1908.\n",
      "Starting epoch 1909.\n",
      "\tTraining accuracy at step 124100: 0.9742380976676941.\n",
      "Starting epoch 1910.\n",
      "\tTraining accuracy at step 124200: 0.9742380976676941.\n",
      "Starting epoch 1911.\n",
      "Starting epoch 1912.\n",
      "\tTraining accuracy at step 124300: 0.9742393493652344.\n",
      "Starting epoch 1913.\n",
      "\tTraining accuracy at step 124400: 0.9742411375045776.\n",
      "Starting epoch 1914.\n",
      "Starting epoch 1915.\n",
      "\tTraining accuracy at step 124500: 0.9742421507835388.\n",
      "Starting epoch 1916.\n",
      "\tTraining accuracy at step 124600: 0.9742449522018433.\n",
      "Starting epoch 1917.\n",
      "Starting epoch 1918.\n",
      "\tTraining accuracy at step 124700: 0.974246084690094.\n",
      "Starting epoch 1919.\n",
      "\tTraining accuracy at step 124800: 0.9742447733879089.\n",
      "Starting epoch 1920.\n",
      "Starting epoch 1921.\n",
      "\tTraining accuracy at step 124900: 0.9742441773414612.\n",
      "Starting epoch 1922.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1923.\n",
      "\tTraining accuracy at step 125000: 0.9742465019226074.\n",
      "Starting epoch 1924.\n",
      "\tTraining accuracy at step 125100: 0.9742493629455566.\n",
      "Starting epoch 1925.\n",
      "Starting epoch 1926.\n",
      "\tTraining accuracy at step 125200: 0.9742498993873596.\n",
      "Starting epoch 1927.\n",
      "\tTraining accuracy at step 125300: 0.9742515683174133.\n",
      "Starting epoch 1928.\n",
      "Starting epoch 1929.\n",
      "\tTraining accuracy at step 125400: 0.9742534756660461.\n",
      "Starting epoch 1930.\n",
      "\tTraining accuracy at step 125500: 0.9742525219917297.\n",
      "Starting epoch 1931.\n",
      "Starting epoch 1932.\n",
      "\tTraining accuracy at step 125600: 0.9742544889450073.\n",
      "Starting epoch 1933.\n",
      "\tTraining accuracy at step 125700: 0.9742565155029297.\n",
      "Starting epoch 1934.\n",
      "Starting epoch 1935.\n",
      "\tTraining accuracy at step 125800: 0.974259614944458.\n",
      "Starting epoch 1936.\n",
      "\tTraining accuracy at step 125900: 0.9742615222930908.\n",
      "Starting epoch 1937.\n",
      "Starting epoch 1938.\n",
      "\tTraining accuracy at step 126000: 0.9742631912231445.\n",
      "Starting epoch 1939.\n",
      "\tTraining accuracy at step 126100: 0.9742647409439087.\n",
      "Starting epoch 1940.\n",
      "Starting epoch 1941.\n",
      "\tTraining accuracy at step 126200: 0.9742677211761475.\n",
      "Starting epoch 1942.\n",
      "Starting epoch 1943.\n",
      "\tTraining accuracy at step 126300: 0.9742708802223206.\n",
      "Starting epoch 1944.\n",
      "\tTraining accuracy at step 126400: 0.9742721915245056.\n",
      "Starting epoch 1945.\n",
      "Starting epoch 1946.\n",
      "\tTraining accuracy at step 126500: 0.9742758274078369.\n",
      "Starting epoch 1947.\n",
      "\tTraining accuracy at step 126600: 0.9742785096168518.\n",
      "Starting epoch 1948.\n",
      "Starting epoch 1949.\n",
      "\tTraining accuracy at step 126700: 0.9742799401283264.\n",
      "Starting epoch 1950.\n",
      "\tTraining accuracy at step 126800: 0.9742771983146667.\n",
      "Starting epoch 1951.\n",
      "Starting epoch 1952.\n",
      "\tTraining accuracy at step 126900: 0.9742769002914429.\n",
      "Starting epoch 1953.\n",
      "\tTraining accuracy at step 127000: 0.9742779731750488.\n",
      "Starting epoch 1954.\n",
      "Starting epoch 1955.\n",
      "\tTraining accuracy at step 127100: 0.9742798805236816.\n",
      "Starting epoch 1956.\n",
      "\tTraining accuracy at step 127200: 0.9742809534072876.\n",
      "Starting epoch 1957.\n",
      "Starting epoch 1958.\n",
      "\tTraining accuracy at step 127300: 0.974281907081604.\n",
      "Starting epoch 1959.\n",
      "\tTraining accuracy at step 127400: 0.9742832183837891.\n",
      "Starting epoch 1960.\n",
      "Starting epoch 1961.\n",
      "\tTraining accuracy at step 127500: 0.9742851853370667.\n",
      "Starting epoch 1962.\n",
      "Starting epoch 1963.\n",
      "\tTraining accuracy at step 127600: 0.9742881059646606.\n",
      "Starting epoch 1964.\n",
      "\tTraining accuracy at step 127700: 0.9742914438247681.\n",
      "Starting epoch 1965.\n",
      "Starting epoch 1966.\n",
      "\tTraining accuracy at step 127800: 0.9742947816848755.\n",
      "Starting epoch 1967.\n",
      "\tTraining accuracy at step 127900: 0.9742966294288635.\n",
      "Starting epoch 1968.\n",
      "Starting epoch 1969.\n",
      "\tTraining accuracy at step 128000: 0.9742958545684814.\n",
      "Starting epoch 1970.\n",
      "\tTraining accuracy at step 128100: 0.974298357963562.\n",
      "Starting epoch 1971.\n",
      "Starting epoch 1972.\n",
      "\tTraining accuracy at step 128200: 0.974297821521759.\n",
      "Starting epoch 1973.\n",
      "\tTraining accuracy at step 128300: 0.9742997884750366.\n",
      "Starting epoch 1974.\n",
      "Starting epoch 1975.\n",
      "\tTraining accuracy at step 128400: 0.974301278591156.\n",
      "Starting epoch 1976.\n",
      "\tTraining accuracy at step 128500: 0.9743021130561829.\n",
      "Starting epoch 1977.\n",
      "Starting epoch 1978.\n",
      "\tTraining accuracy at step 128600: 0.9743057489395142.\n",
      "Starting epoch 1979.\n",
      "\tTraining accuracy at step 128700: 0.974306046962738.\n",
      "Starting epoch 1980.\n",
      "Starting epoch 1981.\n",
      "\tTraining accuracy at step 128800: 0.9743095636367798.\n",
      "Starting epoch 1982.\n",
      "Starting epoch 1983.\n",
      "\tTraining accuracy at step 128900: 0.9743108153343201.\n",
      "Starting epoch 1984.\n",
      "\tTraining accuracy at step 129000: 0.9743095636367798.\n",
      "Starting epoch 1985.\n",
      "Starting epoch 1986.\n",
      "\tTraining accuracy at step 129100: 0.9743108749389648.\n",
      "Starting epoch 1987.\n",
      "\tTraining accuracy at step 129200: 0.974312424659729.\n",
      "Starting epoch 1988.\n",
      "Starting epoch 1989.\n",
      "\tTraining accuracy at step 129300: 0.9743146300315857.\n",
      "Starting epoch 1990.\n",
      "\tTraining accuracy at step 129400: 0.9743177890777588.\n",
      "Starting epoch 1991.\n",
      "Starting epoch 1992.\n",
      "\tTraining accuracy at step 129500: 0.9743183255195618.\n",
      "Starting epoch 1993.\n",
      "\tTraining accuracy at step 129600: 0.9743198156356812.\n",
      "Starting epoch 1994.\n",
      "Starting epoch 1995.\n",
      "\tTraining accuracy at step 129700: 0.9743209481239319.\n",
      "Starting epoch 1996.\n",
      "\tTraining accuracy at step 129800: 0.9743199348449707.\n",
      "Starting epoch 1997.\n",
      "Starting epoch 1998.\n",
      "\tTraining accuracy at step 129900: 0.9743224382400513.\n",
      "Starting epoch 1999.\n",
      "\tTraining accuracy at step 130000: 0.9743255972862244.\n",
      "Optimization complete.\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = os.path.join(os.curdir, 'parkingSign_log')\n",
    "NUM_EPOCHS = 2000\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "# with tf.Session() as sess:\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "# Instantiate writers for TensorBoard (for saving serialized summaries to disk)\n",
    "train_summary_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'), sess.graph)\n",
    "test_summary_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'), sess.graph)\n",
    "# Run optimizer for multiple epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Starting epoch {}.\".format(epoch))\n",
    "    for X_batch, Y_batch in train_iterator:\n",
    "        # Run a training step\n",
    "        _, step = sess.run([train_op, global_step],\n",
    "                           feed_dict={X: X_batch, Y: Y_batch, training_mode: True})\n",
    "        # Every 100 batches compute the accuracy on the training set and save the filters in the first convolutional layer\n",
    "        if (step % 100 == 0 and step > 0):\n",
    "            train_accuracy, eval_s, filter_s = sess.run([acc_op, eval_summaries, filter_summary], \n",
    "                              feed_dict={X: images28, Y: labels, training_mode: False})\n",
    "            train_summary_writer.add_summary(eval_s, global_step=step)\n",
    "            train_summary_writer.add_summary(filter_s, global_step=step)\n",
    "            print(\"\\tTraining accuracy at step {}: {}.\".format(step, train_accuracy))\n",
    "        # Every 10 batches compute the accuracy on the test set.\n",
    "        if (step % 10 == 0):\n",
    "            test_accuracy, eval_s = sess.run([acc_op, eval_summaries], \n",
    "                             feed_dict={X: test_images28, Y: test_labels, training_mode: False})\n",
    "            test_summary_writer.add_summary(eval_s, global_step=step)\n",
    "print(\"Optimization complete.\")\n",
    "train_summary_writer.close()\n",
    "test_summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import `matplotlib`\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# Pick 10 random images\n",
    "sample_indexes = random.sample(range(len(images28)), 10) \n",
    "sample_images = [images28[i] for i in sample_indexes]\n",
    "sample_labels = [labels[i] for i in sample_indexes]\n",
    "\n",
    "\n",
    "# Run the \"correct_pred\" operation\n",
    "predicted = sess.run([predictions], feed_dict={X: sample_images, training_mode: False})[0]\n",
    "# Print the real and predicted labels\n",
    "print(sample_labels)\n",
    "print(predicted)\n",
    "\n",
    "# Display the predictions and the ground truth visually.\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(len(sample_images)):\n",
    "    truth = sample_labels[i]\n",
    "    prediction = predicted[i]\n",
    "    plt.subplot(5, 2, 1 + i)\n",
    "    plt.axis('off')\n",
    "    color = 'green' if int(truth) == prediction else 'red'\n",
    "    plt.text(40, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction),\n",
    "             fontsize=12, color=color)\n",
    "    plt.imshow(sample_images[i], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0\n",
      " 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0\n",
      " 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0]\n",
      "722\n"
     ]
    }
   ],
   "source": [
    "# Run predictions against the full test set.\n",
    "\n",
    "predicted = sess.run([predictions], feed_dict={X: test_images28, training_mode: False})[0]\n",
    "print(predicted)\n",
    "print(len(predicted))\n",
    "# # Calculate correct matches\n",
    "# match_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# accuracy = match_count / len(test_labels)\n",
    "\n",
    "# # Print the accuracy\n",
    "# print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(labels, predicted):\n",
    "    FP=0\n",
    "    TP=0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]=='1' and predicted[i]==1:\n",
    "            TP+=1\n",
    "        if labels[i]=='0' and predicted[i]==1:\n",
    "            FP+=1\n",
    "    print(TP)\n",
    "    print(FP)\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "#         scipy.misc.imsave(\"/Users/chenlingna/Desktop/output/\"+str(i)+\".JPG\", test_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(labels, predicted):\n",
    "    FN=0\n",
    "    TP=0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]=='1' and predicted[i]==1:\n",
    "            TP+=1\n",
    "        if labels[i]=='1' and predicted[i]==0:\n",
    "            FN+=1\n",
    "    print(\"FN:\")\n",
    "    print(FN)\n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695\n",
      "Accuracy: 0.963\n",
      "FN:\n",
      "14\n",
      "Recall: 0.950178\n",
      "267\n",
      "13\n",
      "Precision: 0.953571\n"
     ]
    }
   ],
   "source": [
    "# Calculate correct matches\n",
    "match_count = sum([int(int(y) == y_) for y, y_ in zip(test_labels, predicted)])\n",
    "print(match_count)\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "# Print the recall and precision\n",
    "print(\"Recall: {:3f}\".format(recall(test_labels, predicted)))\n",
    "print(\"Precision: {:3f}\".format(precision(test_labels, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.902\n",
      "FN:\n",
      "1567\n",
      "Recall: 0.170021\n",
      "321\n",
      "502\n",
      "Precision: 0.390036\n"
     ]
    }
   ],
   "source": [
    "#Load output\n",
    "output_data_directory=\"/Users/chenlingna/Desktop/Geelong_Stage1\"\n",
    "output_images, output_labels, output_names = load_data(output_data_directory)\n",
    "\n",
    "output_images28=[]\n",
    "for img in output_images:\n",
    "#     img[img>color]=1\n",
    "#     img[img<color]=0\n",
    "    output_images28.append(img)\n",
    "\n",
    "# Transform the images to 28 by 28 pixels\n",
    "output_images28 = [transform.resize(image, (28, 28)) for image in output_images28]\n",
    "output_images28 = np.array(output_images28)\n",
    "\n",
    "# Run predictions against the output set.\n",
    "predicted = sess.run([predictions], feed_dict={X: output_images28, training_mode: False})[0]\n",
    "\n",
    "\n",
    "# Calculate correct matches\n",
    "match_count = sum([int(int(y) == y_) for y, y_ in zip(output_labels, predicted)])\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(output_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "# Print the recall and precision\n",
    "print(\"Recall: {:3f}\".format(recall(output_labels, predicted)))\n",
    "print(\"Precision: {:3f}\".format(precision(output_labels, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "823"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#output the related images\n",
    "import scipy.misc\n",
    "for i in range(len(output_images28)):\n",
    "    if predicted[i]==1:\n",
    "        name=output_names[i].split('/')[-1]\n",
    "        scipy.misc.imsave(\"/Users/chenlingna/Desktop/output-F/\"+name, skimage.data.imread(output_names[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
