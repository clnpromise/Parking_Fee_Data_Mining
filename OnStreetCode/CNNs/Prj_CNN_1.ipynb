{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "import os                   \n",
    "import skimage              \n",
    "import numpy as np           \n",
    "from skimage import data,transform\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2gray     \n",
    "import matplotlib.pyplot as plt\n",
    "import random   \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_data(data_directory):\n",
    "    directories=[d for d in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory,d))]\n",
    "    #d is every classification file\n",
    "    labels=[]\n",
    "    images=[]\n",
    "    names=[]\n",
    "    for d in directories:\n",
    "        #get path of each class\n",
    "        label_directory=os.path.join(data_directory,d)\n",
    "        file_names=[os.path.join(label_directory,f) for f in os.listdir(label_directory) if f.endswith(\".jpeg\") or f.endswith('.JPG') ]\n",
    "        for f in file_names:\n",
    "\n",
    "            img=skimage.data.imread(f, as_grey='True')\n",
    "            images.append(img)              #read image\n",
    "            labels.append(d)                   #read label\n",
    "            names.append(f)\n",
    "    return images,labels,names\n",
    "\n",
    "#images and labels are list\n",
    "\n",
    "ROOT_PATH=\"/Users/chenlingna/Desktop\"\n",
    "color = 150/255\n",
    "data_directory=os.path.join(ROOT_PATH,\"Melbourne_Classification\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data Set\n",
    "images_Total,labels_Total,names_Total=load_data(data_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "images, test_images, labels, test_labels, names, test_names  = train_test_split(images_Total, labels_Total, names_Total, test_size=0.3, random_state=90051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Manage Training Set\n",
    "# images,labels,names=load_data(train_data_directory)\n",
    "\n",
    "images28=[]\n",
    "for img in images:\n",
    "\n",
    "    images28.append(img)\n",
    "    \n",
    "# Rescale the images in the `images` array\n",
    "images28 = [transform.resize(image, (28, 28)) for image in images28]\n",
    "# Convert `images28` to an array\n",
    "images28 = np.array(images28)\n",
    "# # Convert `images` to grayscale\n",
    "# images28 = rgb2gray(images28)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Load Testing Set\n",
    "# test_images, test_labels, test_names = load_data(test_data_directory)\n",
    "\n",
    "test_images28=[]\n",
    "for img in test_images:\n",
    "#     img[img>color]=1\n",
    "#     img[img<color]=0\n",
    "    test_images28.append(img)\n",
    "\n",
    "# Transform the images to 28 by 28 pixels\n",
    "test_images28 = [transform.resize(image, (28, 28)) for image in test_images28]\n",
    "test_images28 = np.array(test_images28)\n",
    "# # Convert to grayscale\n",
    "# from skimage.color import rgb2gray\n",
    "\n",
    "# test_images28 = rgb2gray(np.array(test_images28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterator:\n",
    "    \"\"\"\n",
    "    An iterator that returns randomized batches from a data set (with features and labels)\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels, batch_size):\n",
    "        assert(features.shape[0]==labels.shape[0])\n",
    "        assert(batch_size > 0 and batch_size <= features.shape[0])\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.num_instances = features.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.num_instances//self.batch_size\n",
    "        if (self.num_instances%self.batch_size!=0):\n",
    "            self.num_batches += 1\n",
    "        self._i = 0\n",
    "        self._rand_ids = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._i = 0\n",
    "        self._rand_ids = np.random.permutation(self.num_instances)\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        self.__next__(self)\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.num_instances - self._i >= self.batch_size:\n",
    "            this_rand_ids = self._rand_ids[self._i:self._i + self.batch_size]\n",
    "            self._i += self.batch_size\n",
    "            return self.features[this_rand_ids], self.labels[this_rand_ids]\n",
    "        elif self.num_instances - self._i > 0:\n",
    "            this_rand_ids = self._rand_ids[self._i::]\n",
    "            self._i = self.num_instances\n",
    "            return self.features[this_rand_ids], self.labels[this_rand_ids]\n",
    "        else:\n",
    "            raise StopIteration()\n",
    "            \n",
    "batch_size = 100\n",
    "labels=np.array(labels)\n",
    "train_iterator = DatasetIterator(images28, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import tensorflow as tf\n",
    "IM_WIDTH = images28.shape[1]      # width of an image in pixels\n",
    "IM_HEIGHT = images28.shape[2] \n",
    "NUM_CLASSES = 2\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='image')\n",
    "    Y = tf.placeholder(tf.int32, [None], name='label')\n",
    "    \n",
    "DEPTH_C1 = 8       # depth of convolutional layer #1\n",
    "DEPTH_C2 = 16      # depth of convolutional layer #2\n",
    "UNITS_D1 = 256     # number of neurons in dense layer #1\n",
    "with tf.variable_scope('cnn_model'):\n",
    "    # Boolean placeholder which is set to True for training, and False for inference.\n",
    "    # This is required to implement dropout. \n",
    "    training_mode = tf.placeholder(dtype=tf.bool, name='training_mode')\n",
    "    \n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(X, [-1, IM_WIDTH, IM_HEIGHT, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=DEPTH_C1, kernel_size=[5, 5], \n",
    "                             padding='same', activation=tf.nn.relu, use_bias=True, \n",
    "                             name='conv_layer_1')\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2, \n",
    "                                    name='pool_layer_1')\n",
    "\n",
    "    # Convolutional Layer #2 \n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=DEPTH_C2, kernel_size=[5, 5], \n",
    "                             padding='same', activation=tf.nn.relu, use_bias=True, \n",
    "                             name='conv_layer_2') # fill in\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2, \n",
    "                                    name='pool_layer_2') # fill in\n",
    "\n",
    "    # Dense Layer #1\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, 7*7*DEPTH_C2], name='pool_layer_2_flat')\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=UNITS_D1, activation=tf.nn.relu, \n",
    "                            name='dense_layer_1')\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.7, training=training_mode, name='dropout')\n",
    "\n",
    "    # Dense Layer #2 (Logits Layer)\n",
    "    logits = tf.layers.dense(inputs=dropout, units=NUM_CLASSES, use_bias=True,\n",
    "                             name='dense_layer_2')\n",
    "    \n",
    "    # Predicted labels\n",
    "    predictions = tf.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "with tf.variable_scope('train'):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_op = opt.minimize(loss=loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('evaluation'):\n",
    "    acc, acc_op = tf.metrics.accuracy(labels=Y, predictions=predictions, name='accuracy')\n",
    "    loss_summary = tf.summary.scalar('loss', loss)\n",
    "    acc_summary = tf.summary.scalar('accuracy', acc)\n",
    "    eval_summaries = tf.summary.merge([loss_summary, acc_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('cnn_model/conv_layer_1', reuse=True):\n",
    "    kernel = tf.get_variable('kernel')\n",
    "    with tf.variable_scope('visualization'):\n",
    "        # scale weights to [0 1]\n",
    "        x_min = tf.reduce_min(kernel)\n",
    "        x_max = tf.reduce_max(kernel)\n",
    "        kernel_0_to_1 = (kernel - x_min) / (x_max - x_min)\n",
    "\n",
    "        # to tf.summary.image format\n",
    "        kernel_transposed = tf.transpose(kernel_0_to_1, [3, 0, 1, 2])\n",
    "\n",
    "        # this will display 5 filters from the 8 in conv_layer_1\n",
    "        filter_summary = tf.summary.image('filters', kernel_transposed, max_outputs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0.\n",
      "Starting epoch 1.\n",
      "\tTraining accuracy at step 100: 0.9558823704719543.\n",
      "Starting epoch 2.\n",
      "\tTraining accuracy at step 200: 0.9559026956558228.\n",
      "Starting epoch 3.\n",
      "\tTraining accuracy at step 300: 0.9559090733528137.\n",
      "Starting epoch 4.\n",
      "Starting epoch 5.\n",
      "\tTraining accuracy at step 400: 0.9559122323989868.\n",
      "Starting epoch 6.\n",
      "\tTraining accuracy at step 500: 0.9559140801429749.\n",
      "Starting epoch 7.\n",
      "\tTraining accuracy at step 600: 0.9559153318405151.\n",
      "Starting epoch 8.\n",
      "Starting epoch 9.\n",
      "\tTraining accuracy at step 700: 0.9559339284896851.\n",
      "Starting epoch 10.\n",
      "\tTraining accuracy at step 800: 0.9559292793273926.\n",
      "Starting epoch 11.\n",
      "\tTraining accuracy at step 900: 0.9559669494628906.\n",
      "Starting epoch 12.\n",
      "\tTraining accuracy at step 1000: 0.9559747576713562.\n",
      "Starting epoch 13.\n",
      "Starting epoch 14.\n",
      "\tTraining accuracy at step 1100: 0.9559968709945679.\n",
      "Starting epoch 15.\n",
      "\tTraining accuracy at step 1200: 0.9561719298362732.\n",
      "Starting epoch 16.\n",
      "\tTraining accuracy at step 1300: 0.9564321041107178.\n",
      "Starting epoch 17.\n",
      "Starting epoch 18.\n",
      "\tTraining accuracy at step 1400: 0.9565737247467041.\n",
      "Starting epoch 19.\n",
      "\tTraining accuracy at step 1500: 0.9568297266960144.\n",
      "Starting epoch 20.\n",
      "\tTraining accuracy at step 1600: 0.9569841027259827.\n",
      "Starting epoch 21.\n",
      "Starting epoch 22.\n",
      "\tTraining accuracy at step 1700: 0.9570766687393188.\n",
      "Starting epoch 23.\n",
      "\tTraining accuracy at step 1800: 0.9572260975837708.\n",
      "Starting epoch 24.\n",
      "\tTraining accuracy at step 1900: 0.9571753144264221.\n",
      "Starting epoch 25.\n",
      "\tTraining accuracy at step 2000: 0.9573590755462646.\n",
      "Starting epoch 26.\n",
      "Starting epoch 27.\n",
      "\tTraining accuracy at step 2100: 0.9574618339538574.\n",
      "Starting epoch 28.\n",
      "\tTraining accuracy at step 2200: 0.9575002789497375.\n",
      "Starting epoch 29.\n",
      "\tTraining accuracy at step 2300: 0.9575803875923157.\n",
      "Starting epoch 30.\n",
      "Starting epoch 31.\n",
      "\tTraining accuracy at step 2400: 0.9576332569122314.\n",
      "Starting epoch 32.\n",
      "\tTraining accuracy at step 2500: 0.9576927423477173.\n",
      "Starting epoch 33.\n",
      "\tTraining accuracy at step 2600: 0.957766592502594.\n",
      "Starting epoch 34.\n",
      "Starting epoch 35.\n",
      "\tTraining accuracy at step 2700: 0.9578030109405518.\n",
      "Starting epoch 36.\n",
      "\tTraining accuracy at step 2800: 0.9578350782394409.\n",
      "Starting epoch 37.\n",
      "\tTraining accuracy at step 2900: 0.9578614830970764.\n",
      "Starting epoch 38.\n",
      "\tTraining accuracy at step 3000: 0.9579034447669983.\n",
      "Starting epoch 39.\n",
      "Starting epoch 40.\n",
      "\tTraining accuracy at step 3100: 0.9579362869262695.\n",
      "Starting epoch 41.\n",
      "\tTraining accuracy at step 3200: 0.9579347372055054.\n",
      "Starting epoch 42.\n",
      "\tTraining accuracy at step 3300: 0.9578907489776611.\n",
      "Starting epoch 43.\n",
      "Starting epoch 44.\n",
      "\tTraining accuracy at step 3400: 0.9579413533210754.\n",
      "Starting epoch 45.\n",
      "\tTraining accuracy at step 3500: 0.9579524397850037.\n",
      "Starting epoch 46.\n",
      "\tTraining accuracy at step 3600: 0.9579882621765137.\n",
      "Starting epoch 47.\n",
      "Starting epoch 48.\n",
      "\tTraining accuracy at step 3700: 0.957960844039917.\n",
      "Starting epoch 49.\n",
      "\tTraining accuracy at step 3800: 0.9579556584358215.\n",
      "Starting epoch 50.\n",
      "\tTraining accuracy at step 3900: 0.9579778909683228.\n",
      "Starting epoch 51.\n",
      "\tTraining accuracy at step 4000: 0.9580137729644775.\n",
      "Starting epoch 52.\n",
      "Starting epoch 53.\n",
      "\tTraining accuracy at step 4100: 0.9579885005950928.\n",
      "Starting epoch 54.\n",
      "\tTraining accuracy at step 4200: 0.9580194354057312.\n",
      "Starting epoch 55.\n",
      "\tTraining accuracy at step 4300: 0.9580146670341492.\n",
      "Starting epoch 56.\n",
      "Starting epoch 57.\n",
      "\tTraining accuracy at step 4400: 0.9580122828483582.\n",
      "Starting epoch 58.\n",
      "\tTraining accuracy at step 4500: 0.9580116868019104.\n",
      "Starting epoch 59.\n",
      "\tTraining accuracy at step 4600: 0.9580100774765015.\n",
      "Starting epoch 60.\n",
      "Starting epoch 61.\n",
      "\tTraining accuracy at step 4700: 0.9579843878746033.\n",
      "Starting epoch 62.\n",
      "\tTraining accuracy at step 4800: 0.95799720287323.\n",
      "Starting epoch 63.\n",
      "\tTraining accuracy at step 4900: 0.9579793810844421.\n",
      "Starting epoch 64.\n",
      "\tTraining accuracy at step 5000: 0.9579883813858032.\n",
      "Starting epoch 65.\n",
      "Starting epoch 66.\n",
      "\tTraining accuracy at step 5100: 0.9579501748085022.\n",
      "Starting epoch 67.\n",
      "\tTraining accuracy at step 5200: 0.9579712152481079.\n",
      "Starting epoch 68.\n",
      "\tTraining accuracy at step 5300: 0.9579682350158691.\n",
      "Starting epoch 69.\n",
      "Starting epoch 70.\n",
      "\tTraining accuracy at step 5400: 0.9579658508300781.\n",
      "Starting epoch 71.\n",
      "\tTraining accuracy at step 5500: 0.957966148853302.\n",
      "Starting epoch 72.\n",
      "\tTraining accuracy at step 5600: 0.9579577445983887.\n",
      "Starting epoch 73.\n",
      "Starting epoch 74.\n",
      "\tTraining accuracy at step 5700: 0.9579564929008484.\n",
      "Starting epoch 75.\n",
      "\tTraining accuracy at step 5800: 0.957954466342926.\n",
      "Starting epoch 76.\n",
      "\tTraining accuracy at step 5900: 0.9579328894615173.\n",
      "Starting epoch 77.\n",
      "\tTraining accuracy at step 6000: 0.9579095244407654.\n",
      "Starting epoch 78.\n",
      "Starting epoch 79.\n",
      "\tTraining accuracy at step 6100: 0.9578789472579956.\n",
      "Starting epoch 80.\n",
      "\tTraining accuracy at step 6200: 0.957859992980957.\n",
      "Starting epoch 81.\n",
      "\tTraining accuracy at step 6300: 0.9578479528427124.\n",
      "Starting epoch 82.\n",
      "Starting epoch 83.\n",
      "\tTraining accuracy at step 6400: 0.957854688167572.\n",
      "Starting epoch 84.\n",
      "\tTraining accuracy at step 6500: 0.957862377166748.\n",
      "Starting epoch 85.\n",
      "\tTraining accuracy at step 6600: 0.9578720927238464.\n",
      "Starting epoch 86.\n",
      "Starting epoch 87.\n",
      "\tTraining accuracy at step 6700: 0.9578961730003357.\n",
      "Starting epoch 88.\n",
      "\tTraining accuracy at step 6800: 0.9579184651374817.\n",
      "Starting epoch 89.\n",
      "\tTraining accuracy at step 6900: 0.9579472541809082.\n",
      "Starting epoch 90.\n",
      "\tTraining accuracy at step 7000: 0.9579752087593079.\n",
      "Starting epoch 91.\n",
      "Starting epoch 92.\n",
      "\tTraining accuracy at step 7100: 0.9579680562019348.\n",
      "Starting epoch 93.\n",
      "\tTraining accuracy at step 7200: 0.9579747915267944.\n",
      "Starting epoch 94.\n",
      "\tTraining accuracy at step 7300: 0.9579638242721558.\n",
      "Starting epoch 95.\n",
      "Starting epoch 96.\n",
      "\tTraining accuracy at step 7400: 0.9579660892486572.\n",
      "Starting epoch 97.\n",
      "\tTraining accuracy at step 7500: 0.9579676389694214.\n",
      "Starting epoch 98.\n",
      "\tTraining accuracy at step 7600: 0.9579501152038574.\n",
      "Starting epoch 99.\n",
      "\tTraining accuracy at step 7700: 0.9579511880874634.\n",
      "Starting epoch 100.\n",
      "Starting epoch 101.\n",
      "\tTraining accuracy at step 7800: 0.9579532146453857.\n",
      "Starting epoch 102.\n",
      "\tTraining accuracy at step 7900: 0.9579473733901978.\n",
      "Starting epoch 103.\n",
      "\tTraining accuracy at step 8000: 0.9579567909240723.\n",
      "Starting epoch 104.\n",
      "Starting epoch 105.\n",
      "\tTraining accuracy at step 8100: 0.9579261541366577.\n",
      "Starting epoch 106.\n",
      "\tTraining accuracy at step 8200: 0.9579340815544128.\n",
      "Starting epoch 107.\n",
      "\tTraining accuracy at step 8300: 0.9579216837882996.\n",
      "Starting epoch 108.\n",
      "Starting epoch 109.\n",
      "\tTraining accuracy at step 8400: 0.9579373598098755.\n",
      "Starting epoch 110.\n",
      "\tTraining accuracy at step 8500: 0.95793616771698.\n",
      "Starting epoch 111.\n",
      "\tTraining accuracy at step 8600: 0.9579115509986877.\n",
      "Starting epoch 112.\n",
      "\tTraining accuracy at step 8700: 0.9579095840454102.\n",
      "Starting epoch 113.\n",
      "Starting epoch 114.\n",
      "\tTraining accuracy at step 8800: 0.9579026103019714.\n",
      "Starting epoch 115.\n",
      "\tTraining accuracy at step 8900: 0.9579099416732788.\n",
      "Starting epoch 116.\n",
      "\tTraining accuracy at step 9000: 0.9578908085823059.\n",
      "Starting epoch 117.\n",
      "Starting epoch 118.\n",
      "\tTraining accuracy at step 9100: 0.9578859210014343.\n",
      "Starting epoch 119.\n",
      "\tTraining accuracy at step 9200: 0.9578840732574463.\n",
      "Starting epoch 120.\n",
      "\tTraining accuracy at step 9300: 0.9578787684440613.\n",
      "Starting epoch 121.\n",
      "Starting epoch 122.\n",
      "\tTraining accuracy at step 9400: 0.9578561186790466.\n",
      "Starting epoch 123.\n",
      "\tTraining accuracy at step 9500: 0.9578163027763367.\n",
      "Starting epoch 124.\n",
      "\tTraining accuracy at step 9600: 0.9577978253364563.\n",
      "Starting epoch 125.\n",
      "\tTraining accuracy at step 9700: 0.957794725894928.\n",
      "Starting epoch 126.\n",
      "Starting epoch 127.\n",
      "\tTraining accuracy at step 9800: 0.957760751247406.\n",
      "Starting epoch 128.\n",
      "\tTraining accuracy at step 9900: 0.9577590823173523.\n",
      "Starting epoch 129.\n",
      "\tTraining accuracy at step 10000: 0.957768440246582.\n",
      "Starting epoch 130.\n",
      "Starting epoch 131.\n",
      "\tTraining accuracy at step 10100: 0.9577783942222595.\n",
      "Starting epoch 132.\n",
      "\tTraining accuracy at step 10200: 0.9577845335006714.\n",
      "Starting epoch 133.\n",
      "\tTraining accuracy at step 10300: 0.9578000903129578.\n",
      "Starting epoch 134.\n",
      "Starting epoch 135.\n",
      "\tTraining accuracy at step 10400: 0.9577992558479309.\n",
      "Starting epoch 136.\n",
      "\tTraining accuracy at step 10500: 0.9577867388725281.\n",
      "Starting epoch 137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining accuracy at step 10600: 0.9577951431274414.\n",
      "Starting epoch 138.\n",
      "\tTraining accuracy at step 10700: 0.9578129649162292.\n",
      "Starting epoch 139.\n",
      "Starting epoch 140.\n",
      "\tTraining accuracy at step 10800: 0.957796573638916.\n",
      "Starting epoch 141.\n",
      "\tTraining accuracy at step 10900: 0.9577940702438354.\n",
      "Starting epoch 142.\n",
      "\tTraining accuracy at step 11000: 0.9578118920326233.\n",
      "Starting epoch 143.\n",
      "Starting epoch 144.\n",
      "\tTraining accuracy at step 11100: 0.9578264951705933.\n",
      "Starting epoch 145.\n",
      "\tTraining accuracy at step 11200: 0.9578276872634888.\n",
      "Starting epoch 146.\n",
      "\tTraining accuracy at step 11300: 0.9578378200531006.\n",
      "Starting epoch 147.\n",
      "Starting epoch 148.\n",
      "\tTraining accuracy at step 11400: 0.9578518271446228.\n",
      "Starting epoch 149.\n",
      "\tTraining accuracy at step 11500: 0.9578602313995361.\n",
      "Starting epoch 150.\n",
      "\tTraining accuracy at step 11600: 0.957869827747345.\n",
      "Starting epoch 151.\n",
      "\tTraining accuracy at step 11700: 0.957878589630127.\n",
      "Starting epoch 152.\n",
      "Starting epoch 153.\n",
      "\tTraining accuracy at step 11800: 0.9578903317451477.\n",
      "Starting epoch 154.\n",
      "\tTraining accuracy at step 11900: 0.9578973054885864.\n",
      "Starting epoch 155.\n",
      "\tTraining accuracy at step 12000: 0.9578953981399536.\n",
      "Starting epoch 156.\n",
      "Starting epoch 157.\n",
      "\tTraining accuracy at step 12100: 0.9578951001167297.\n",
      "Starting epoch 158.\n",
      "\tTraining accuracy at step 12200: 0.9578829407691956.\n",
      "Starting epoch 159.\n",
      "\tTraining accuracy at step 12300: 0.957878589630127.\n",
      "Starting epoch 160.\n",
      "Starting epoch 161.\n",
      "\tTraining accuracy at step 12400: 0.9578812122344971.\n",
      "Starting epoch 162.\n",
      "\tTraining accuracy at step 12500: 0.9578853845596313.\n",
      "Starting epoch 163.\n",
      "\tTraining accuracy at step 12600: 0.9579008221626282.\n",
      "Starting epoch 164.\n",
      "\tTraining accuracy at step 12700: 0.9579067230224609.\n",
      "Starting epoch 165.\n",
      "Starting epoch 166.\n",
      "\tTraining accuracy at step 12800: 0.9579107761383057.\n",
      "Starting epoch 167.\n",
      "\tTraining accuracy at step 12900: 0.9579229950904846.\n",
      "Starting epoch 168.\n",
      "\tTraining accuracy at step 13000: 0.957938015460968.\n",
      "Starting epoch 169.\n",
      "Starting epoch 170.\n",
      "\tTraining accuracy at step 13100: 0.9579442143440247.\n",
      "Starting epoch 171.\n",
      "\tTraining accuracy at step 13200: 0.957949161529541.\n",
      "Starting epoch 172.\n",
      "\tTraining accuracy at step 13300: 0.9579440951347351.\n",
      "Starting epoch 173.\n",
      "Starting epoch 174.\n",
      "\tTraining accuracy at step 13400: 0.95794677734375.\n",
      "Starting epoch 175.\n",
      "\tTraining accuracy at step 13500: 0.9579601883888245.\n",
      "Starting epoch 176.\n",
      "\tTraining accuracy at step 13600: 0.9579500555992126.\n",
      "Starting epoch 177.\n",
      "\tTraining accuracy at step 13700: 0.9579368829727173.\n",
      "Starting epoch 178.\n",
      "Starting epoch 179.\n",
      "\tTraining accuracy at step 13800: 0.9579302668571472.\n",
      "Starting epoch 180.\n",
      "\tTraining accuracy at step 13900: 0.9579448103904724.\n",
      "Starting epoch 181.\n",
      "\tTraining accuracy at step 14000: 0.9579321146011353.\n",
      "Starting epoch 182.\n",
      "Starting epoch 183.\n",
      "\tTraining accuracy at step 14100: 0.9579339027404785.\n",
      "Starting epoch 184.\n",
      "\tTraining accuracy at step 14200: 0.9579370021820068.\n",
      "Starting epoch 185.\n",
      "\tTraining accuracy at step 14300: 0.9579634666442871.\n",
      "Starting epoch 186.\n",
      "Starting epoch 187.\n",
      "\tTraining accuracy at step 14400: 0.957977294921875.\n",
      "Starting epoch 188.\n",
      "\tTraining accuracy at step 14500: 0.9579916000366211.\n",
      "Starting epoch 189.\n",
      "\tTraining accuracy at step 14600: 0.9580085277557373.\n",
      "Starting epoch 190.\n",
      "\tTraining accuracy at step 14700: 0.9580241441726685.\n",
      "Starting epoch 191.\n",
      "Starting epoch 192.\n",
      "\tTraining accuracy at step 14800: 0.9580289721488953.\n",
      "Starting epoch 193.\n",
      "\tTraining accuracy at step 14900: 0.9580436944961548.\n",
      "Starting epoch 194.\n",
      "\tTraining accuracy at step 15000: 0.958059549331665.\n",
      "Starting epoch 195.\n",
      "Starting epoch 196.\n",
      "\tTraining accuracy at step 15100: 0.9580769538879395.\n",
      "Starting epoch 197.\n",
      "\tTraining accuracy at step 15200: 0.9580807089805603.\n",
      "Starting epoch 198.\n",
      "\tTraining accuracy at step 15300: 0.9580830335617065.\n",
      "Starting epoch 199.\n",
      "\tTraining accuracy at step 15400: 0.9580734372138977.\n",
      "Starting epoch 200.\n",
      "Starting epoch 201.\n",
      "\tTraining accuracy at step 15500: 0.9580647945404053.\n",
      "Starting epoch 202.\n",
      "\tTraining accuracy at step 15600: 0.9580803513526917.\n",
      "Starting epoch 203.\n",
      "\tTraining accuracy at step 15700: 0.9580841064453125.\n",
      "Starting epoch 204.\n",
      "Starting epoch 205.\n",
      "\tTraining accuracy at step 15800: 0.9581003189086914.\n",
      "Starting epoch 206.\n",
      "\tTraining accuracy at step 15900: 0.9580987691879272.\n",
      "Starting epoch 207.\n",
      "\tTraining accuracy at step 16000: 0.9580994844436646.\n",
      "Starting epoch 208.\n",
      "Starting epoch 209.\n",
      "\tTraining accuracy at step 16100: 0.9581048488616943.\n",
      "Starting epoch 210.\n",
      "\tTraining accuracy at step 16200: 0.9581038355827332.\n",
      "Starting epoch 211.\n",
      "\tTraining accuracy at step 16300: 0.9581020474433899.\n",
      "Starting epoch 212.\n",
      "\tTraining accuracy at step 16400: 0.9581014513969421.\n",
      "Starting epoch 213.\n",
      "Starting epoch 214.\n",
      "\tTraining accuracy at step 16500: 0.9580990076065063.\n",
      "Starting epoch 215.\n",
      "\tTraining accuracy at step 16600: 0.958096981048584.\n",
      "Starting epoch 216.\n",
      "\tTraining accuracy at step 16700: 0.9581027626991272.\n",
      "Starting epoch 217.\n",
      "Starting epoch 218.\n",
      "\tTraining accuracy at step 16800: 0.9581022262573242.\n",
      "Starting epoch 219.\n",
      "\tTraining accuracy at step 16900: 0.9580987691879272.\n",
      "Starting epoch 220.\n",
      "\tTraining accuracy at step 17000: 0.9580947756767273.\n",
      "Starting epoch 221.\n",
      "Starting epoch 222.\n",
      "\tTraining accuracy at step 17100: 0.9581001400947571.\n",
      "Starting epoch 223.\n",
      "\tTraining accuracy at step 17200: 0.9581093788146973.\n",
      "Starting epoch 224.\n",
      "\tTraining accuracy at step 17300: 0.9581106305122375.\n",
      "Starting epoch 225.\n",
      "\tTraining accuracy at step 17400: 0.9581071138381958.\n",
      "Starting epoch 226.\n",
      "Starting epoch 227.\n",
      "\tTraining accuracy at step 17500: 0.958099365234375.\n",
      "Starting epoch 228.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f387b1ebcc4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             test_accuracy, eval_s = sess.run([acc_op, eval_summaries], \n\u001b[0;32m---> 27\u001b[0;31m                              feed_dict={X: test_images28, Y: test_labels, training_mode: False})\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mtest_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machine learning/week5/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machine learning/week5/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machine learning/week5/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machine learning/week5/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machine learning/week5/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/machine learning/week5/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LOG_DIR = os.path.join(os.curdir, 'parkingSign_log')\n",
    "NUM_EPOCHS = 400\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "# with tf.Session() as sess:\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "# Instantiate writers for TensorBoard (for saving serialized summaries to disk)\n",
    "train_summary_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'), sess.graph)\n",
    "test_summary_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'), sess.graph)\n",
    "# Run optimizer for multiple epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Starting epoch {}.\".format(epoch))\n",
    "    for X_batch, Y_batch in train_iterator:\n",
    "        # Run a training step\n",
    "        _, step = sess.run([train_op, global_step],\n",
    "                           feed_dict={X: X_batch, Y: Y_batch, training_mode: True})\n",
    "        # Every 100 batches compute the accuracy on the training set and save the filters in the first convolutional layer\n",
    "        if (step % 100 == 0 and step > 0):\n",
    "            train_accuracy, eval_s, filter_s = sess.run([acc_op, eval_summaries, filter_summary], \n",
    "                              feed_dict={X: images28, Y: labels, training_mode: False})\n",
    "            train_summary_writer.add_summary(eval_s, global_step=step)\n",
    "            train_summary_writer.add_summary(filter_s, global_step=step)\n",
    "            print(\"\\tTraining accuracy at step {}: {}.\".format(step, train_accuracy))\n",
    "        # Every 10 batches compute the accuracy on the test set.\n",
    "        if (step % 10 == 0):\n",
    "            test_accuracy, eval_s = sess.run([acc_op, eval_summaries], \n",
    "                             feed_dict={X: test_images28, Y: test_labels, training_mode: False})\n",
    "            test_summary_writer.add_summary(eval_s, global_step=step)\n",
    "print(\"Optimization complete.\")\n",
    "train_summary_writer.close()\n",
    "test_summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "# Run predictions against the full test set.\n",
    "\n",
    "predicted = sess.run([predictions], feed_dict={X: test_images28, training_mode: False})[0]\n",
    "print(predicted)\n",
    "print(len(predicted))\n",
    "# # Calculate correct matches\n",
    "# match_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# accuracy = match_count / len(test_labels)\n",
    "\n",
    "# # Print the accuracy\n",
    "# print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(labels, predicted):\n",
    "    FP=0\n",
    "    TP=0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]=='1' and predicted[i]==1:\n",
    "            TP+=1\n",
    "        if labels[i]=='0' and predicted[i]==1:\n",
    "            FP+=1\n",
    "    print(TP)\n",
    "    print(FP)\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "#         scipy.misc.imsave(\"/Users/chenlingna/Desktop/output/\"+str(i)+\".JPG\", test_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(labels, predicted):\n",
    "    FN=0\n",
    "    TP=0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]=='1' and predicted[i]==1:\n",
    "            TP+=1\n",
    "        if labels[i]=='1' and predicted[i]==0:\n",
    "            FN+=1\n",
    "    print(\"FN:\")\n",
    "    print(FN)\n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134\n",
      "Accuracy: 0.950\n",
      "FN:\n",
      "113\n",
      "Recall: 0.215278\n",
      "31\n",
      "53\n",
      "Precision: 0.369048\n"
     ]
    }
   ],
   "source": [
    "# Calculate correct matches\n",
    "match_count = sum([int(int(y) == y_) for y, y_ in zip(test_labels, predicted)])\n",
    "print(match_count)\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "# Print the recall and precision\n",
    "print(\"Recall: {:3f}\".format(recall(test_labels, predicted)))\n",
    "print(\"Precision: {:3f}\".format(precision(test_labels, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
